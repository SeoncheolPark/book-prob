[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Biggner’s Guide to Probability and Extremes",
    "section": "",
    "text": "Preface\n확률론은 통계학을 공부하는 데 있어 굉장히 중요한 과목이다. 여기에서는 통계에 필요한 부분만 적었다.\n덤으로 극단값 이론의 기초도 수록하였다.\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "Intro",
      "Preface"
    ]
  },
  {
    "objectID": "measure.html",
    "href": "measure.html",
    "title": "1  Measure and Integration",
    "section": "",
    "text": "1.1 Limit of sets\n우리는 \\(\\sigma\\)-field 에만 관심을 갖고 있지만 이를 설명하는 데 유용한 더 작은 하위 클래스들이 있다.\n다음은 PROBABILITY THEORY - PART 1 MEASURE THEORETICAL FRAMEWORK 에서 가져온 몇 가지 예이다.\n위 표를 보면, \\(\\pi\\)-system이나 이 \\(\\pi\\)-system으로 만든 algebra는 명시적으로 표사되어 있으나, \\(\\sigma\\)-algebra를 이해하기는 쉽지 않다. 이는 Borel set은 countable number of operations on intervals로 표현하기 쉽지 않기 때문이라고 한다.\n이렇게 원소를 파악하기 어려운 \\(\\sigma\\)-algebra에 대해 말해주는 보조정리 뒤 개가 있다. 이들이 말하고자 하는 바는 동일하고 많은 경우에 둘을 바꿔서 사용할 수 있다고 한다.\nQ. (Unique extension of measures) \\((\\mathbb{R}, \\mathcal{B})\\)에서의 두 확률측도가 모든 구간에서 일치한다면, 이들은 같은가?\n다음 예를 통해 거짓이라는 것을 확인할 수 있다.\n다만 다음 따름정리와 같이 긍정적인 결과도 있다.\n다시 Example 1.1 를 살펴보면, \\(S\\)가 \\(\\pi\\)-system이 아니라는 것을 알 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#limit-of-sets",
    "href": "measure.html#limit-of-sets",
    "title": "1  Measure and Integration",
    "section": "",
    "text": "Definition 1.1  \n\n\\(S\\): a collection of subsets of \\(\\Omega\\). We say that \\(S\\) is a\n\n\n\\(\\pi\\)-system: if \\(A, B \\in S \\Longrightarrow A\\cap B \\in S\\)\n\\(\\lambda\\)-system: if\n\n\\(\\Omega \\in S\\)\n\\(A, B \\in S\\) and \\(A \\subseteq B \\Longrightarrow B \\backslash A \\in S\\)\n\\(A_n \\uparrow A\\) and \\(A_n \\in S \\Longrightarrow A \\in S\\)\n\nAlgebra (field) if\n\n\\(\\emptyset , \\Omega \\in S\\)\n\\(A \\in S \\Longrightarrow A^c \\in S\\)\n\\(A, B \\in S \\Longrightarrow A\\cup B \\in S\\)\n\nMonotone class if\n\n\\(A_n \\in S\\) and \\(A_n \\uparrow A \\Longrightarrow A \\in S\\)\n\\(A_n \\in S\\) and \\(A_n \\downarrow A \\Longrightarrow A \\in S\\)\nRecall that \\(A_n \\uparrow A\\) means that \\(A_1 \\subseteq A_2 \\subseteq \\ldots\\) and \\(\\cup_n A_n = A\\) and \\(A_n \\downarrow A\\) means that \\(A_n \\supseteq A_2 \\supseteq \\ldots\\) and \\(\\cap_n A_n = A\\)\n\n\\(\\sigma\\)-algebra (field) if\n\n\\(\\emptyset, \\Omega \\in S\\)\n\\(A \\in S \\Longrightarrow A^c \\in S\\)\n\\(A_n \\in S \\Longrightarrow \\cup A_n \\in S\\)\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\\(\\sigma\\)-algebra는 \\(\\pi\\)-system, \\(\\lambda\\)-system, monotone class 그리고 algebra이다.\nArbitrary intersections of \\(\\sigma\\)-algebra, algebra, \\(\\pi\\)-system, \\(\\lambda\\)-system은 각각 \\(\\sigma\\)-algebra, algebra, \\(\\pi\\)-system, \\(\\lambda\\)-system이다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\Omega\\)\n\\(S(\\pi\\)-system)\n\\(\\mathcal{A}(S)\\) (algebra generated by \\(S\\))\n\\(\\sigma(S)\\)\n\n\n\n\n\\((0,1]\\)\n\\(\\{(a,b]: 0&lt;a\\leq b \\leq 1\\}\\)\n\\(\\{ \\cup_{k=1}^N I_k: I_k \\in S \\text{ are pairwise disjoint}\\}\\)\n\\(\\mathcal{B}(0,1]\\)\n\n\n\\([0,1]\\)\n\\(\\{(a,b]\\cap [0,1]: a \\leq b\\}\\)\n\\(\\{\\cup_{k=1}^N R_k: R_k \\in S \\text{ are pairwise disjoint}\\}\\)\n\\(\\mathcal{B}[0,1]\\)\n\n\n\\(\\mathbb{R}^d\\)\n\\(\\{\\prod_{i=1}^d (a_i, b_i]: a_i \\leq b_i\\}\\)\n\\(\\{\\cup_{k=1}^N R_k: R_k \\in S \\text{ are pairwise disjoint}\\}\\)\n\\(\\mathcal{B}_{\\mathbb{R}^d}\\)\n\n\n\\(\\{0,1\\}^{\\mathbb{N}}\\)\nCollection of all cylinder sets\nFinite disjoint unions of cylinders\n\\(\\mathcal{B}(\\{0,1\\}^{\\mathbb{N}})\\)\n\n\n\n\n\n\nLemma 1.1 (\\(\\pi-\\lambda\\) theorem)  \n\nLet \\(\\Omega\\) be a set and \\(\\mathcal{F}\\) be a set of subsets of \\(\\Omega\\).\n\n\n\\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra \\(\\Longleftrightarrow\\) it is a \\(\\pi\\)-system as well as a \\(\\lambda\\)-system.\nIf \\(S\\) is a \\(\\pi\\)-system, then \\(\\lambda (S) = \\sigma(S)\\). 이때 \\(\\lambda (S)\\)는 \\(S\\)를 포함하는 모든 \\(\\lambda\\)-system들의 intersection이다.\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n한쪽 방향은 분명하다. \\(\\mathcal{F}\\)가 \\(\\pi\\)-system이면서 \\(\\lambda\\)-system이라고 하자. 그러면 \\(\\Omega \\in \\mathcal{F}\\)이고 만약 \\(A\\in \\mathcal{F}\\)이면, \\(A^c = \\Omega \\backslash A \\in \\mathcal{F}\\)이다. 만약 \\(A_n \\in \\mathcal{F}\\)이면, 이것의 finite unions \\(B_n := \\cup_{k=1}^n A_k = (\\cap_{k=1}^n A_k^c)^c \\in \\mathcal{F}\\)이다. (intersection에서는 \\(\\mathcal{F}\\)가 \\(\\pi\\)-system이라는 것을 이용) 또한 countable union \\(\\cup A_n\\) 또한 \\(B_n\\)의 increasing limit이고 \\(\\mathcal{F}\\) 안에 들어가기에 \\(\\lambda\\)-property를 만족\n\\(\\lambda (S)\\) 자체도 \\(S\\)를 포함하는 가장 작은 \\(\\lambda\\)-system이다. 이에 \\(\\lambda (S) = \\sigma (S)\\)를 보이려면 \\(\\mathcal{F}:=\\lambda (S)\\)가 \\(\\pi\\)-system임을 보이면 된다. 즉 \\(A, B \\in \\mathcal{F}\\)이면 \\(A\\cap B \\in \\mathcal{F}\\)임을 보이면 된다. \\(A\\in S\\)를 고정하고 \\(\\mathcal{F}_A := \\{ B \\in \\mathcal{F}: B \\cap A \\in \\mathcal{F}\\}\\)라 하자. \\(S\\)가 \\(\\pi\\)-system이므로 \\(\\mathcal{F}_A \\supset S\\)이다. 여기서 \\(\\mathcal{F}_A\\)가 \\(\\lambda\\)-system임을 보이고자 한다. \\(\\Omega \\in \\mathcal{F}_A\\)이다. 만약 \\(B, C \\in \\mathcal{F}_A\\)이고 \\(B\\subseteq C\\)이면, \\(\\mathcal{F}\\)가 \\(C\\cap A\\)와 \\(B\\cap A\\)를 포함하는 \\(\\lambda\\)-system이기 때문에 \\((C\\backslash B) \\cap A = (C \\cap A) \\backslash (B \\cap A) \\in \\mathcal{F}\\)이다. 따라서 \\((C\\backslash B) \\in \\mathcal{F}_A\\)이다. 마지막으로 만약 \\(B_n \\in \\mathcal{F}_A\\)이고 \\(B_n \\uparrow B\\)이면, \\(B_n \\cap A \\in \\mathcal{F}_A\\)이고 \\(B_n \\cap A \\uparrow B \\cap A\\)이다. 따라서 \\(B \\in \\mathcal{F}_A\\)이다. 이것은 \\(\\mathcal{F}_A\\)가 \\(S\\)를 포함하는 \\(\\lambda\\)-system임을 의미하며 따라서 \\(\\mathcal{F}_A \\supset \\mathcal{F}\\)이다. 다른 말로, 모든 \\(A \\in S\\)와 \\(B \\in \\mathcal{F}\\)에 대해 \\(A \\cap B \\in \\mathcal{F}\\)이다. 이제 \\(A\\in\\mathcal{F}\\)를 고정하자. 다시 \\(\\mathcal{F}_A := \\{ B\\in \\mathcal{F}: B\\cap A \\in \\mathcal{F}\\}\\)라고 정의하자. 앞에서 보인대로 하면 \\(\\mathcal{F}_A \\supset S\\)임을 보일 수 있다. 이를 바탕으로 \\(\\mathcal{F}_A\\)가 \\(\\lambda\\)-system이며 모든 \\(A \\in \\mathcal{F}\\)에서 \\(\\mathcal{F}_A = \\mathcal{F}\\)임을 보일 수 있다. 즉 \\(\\mathcal{F}\\)는 \\(\\pi\\)-system이다.\n\n\n\n\n\nLemma 1.2 (Monotone class theorem)  \n\nLet \\(\\Omega\\) be a set and let \\(S\\) be a collection of \\(\\Omega\\). If \\(S\\) is an algebra, then the monotone class generated by \\(S\\) is a \\(\\sigma\\)-algebra. That is, \\(\\mathcal{M}(S) = \\sigma(S)\\).\n\n\n\n\n\n\nExample 1.1 (\\(\\pi-\\lambda\\) theorem)  \n\n\\(\\Omega = \\{1,2,3,4\\}\\)이고 \\(S = \\{\\{1,2\\},\\{2,3\\},\\{3,4\\}\\}\\)라고 하자. 그러면 \\(\\sigma (S) = 2^{\\Omega}\\) (power set)이라는 것을 보일 수 있다.\n\\(\\Omega\\)에서 두 확률측도 \\(\\mu, \\nu\\)를 각각\n\n\\(\\mu_i = \\frac{1}{4}, \\forall i\\)\n\\(\\nu_1 = \\nu_3 =\\frac{1}{2}\\), \\(\\nu_2 = \\nu_4 = 0\\) 이라고 하자. 그러면 \\(\\mu(A)=\\frac{1}{2}=\\nu (A)\\) for all \\(A \\in S\\)이나, \\(\\mu \\neq \\nu\\) on \\(\\sigma (S)\\)이다.\n\n\n\n\n\nLemma 1.3 \\(S\\)가 \\(\\Omega\\)의 부분집합의 \\(\\pi\\)-system이고 \\(\\mathcal{F} = \\sigma (S)\\)라 하자. 만약 \\(\\mathbb{P} = \\mathbb{Q}\\)가 \\(\\mathcal{F}\\)에서의 확률측도이며 모든 \\(A \\in S\\)에서 \\(\\mathbb{P}(A) =\\mathbb{Q}(A)\\)라 하자. 그러면 모든 \\(A\\in \\mathcal{F}\\)에서 \\(\\mathbb{P}(A) =\\mathbb{Q}(A)\\)이다.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n\\(\\mathcal{G} =\\{A \\in \\mathcal{F}: \\mathbb{P}(A) = \\mathbb{Q}(A)\\}\\)라 하자. 가정에 의해 \\(\\mathcal{G} \\supseteq S\\)이다.\n여기서 \\(\\mathcal{G}\\)가 \\(\\lambda\\)-system임을 밝히고자 한다. 분명히 \\(\\Omega \\in \\mathcal{G}\\)이;다. 만약 \\(A, B \\in \\mathcal{G}\\)이고 \\(A \\supseteq B\\)이면, \\(\\mathbb{P}(A\\backslash B) = \\mathbb{P}(A) - \\mathbb{P}(B) = \\mathbb{Q}(A) - \\mathbb{Q}(B) = \\mathbb{Q}(A\\backslash B)\\)이다. 이는 즉 \\(A \\backslash B \\in \\mathcal{G}\\)임을 내포한다. 마지막으로 만약 \\(A_n \\in \\mathcal{G}\\)이고 \\(A_n \\uparrow A\\)이면, \\(\\mathbb{P}(A) = \\lim_{n\\rightarrow \\infty} \\mathbb{P}(A_n) = \\lim_{n\\rightarrow \\infty}\\mathbb{Q}(A_n) = \\mathbb{Q}(A)\\)이다. (이는 measure의 countable additivity로부터 옴)\n따라서 \\(\\mathcal{G} \\supseteq \\lambda (S)\\)이고 이는 Lemma 1.1 에 의해 \\(\\sigma (S)\\)와 같음을 보일 수 있다. 따라서 \\(\\mathcal{F}\\)에서 \\(\\mathbb{P}= \\mathbb{Q}\\)이다.\n\n\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\\(\\sigma\\)-algebra의 집합, 특히 Borel 집합은 항상 어떤 interval의 가산 합집합이 아니기 때문에, \\(\\sigma\\)-algebra의 모든 요소에 대해 어떤 성질이 성립함을 보이기 위해, 우리는 그 성질을 가진 모든 집합의 collection을 고려하고, 이 collection이 \\(\\sigma\\)-algebra임을 보여준다. 이 과정에서 그것이 \\(\\lambda\\)-system이거나 monotone class (\\(\\pi\\)-system과 algebra를 포함하는) 임을 보여주는 것이 더 쉬울 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#measures",
    "href": "measure.html#measures",
    "title": "1  Measure and Integration",
    "section": "1.2 Measures",
    "text": "1.2 Measures\n\n\nDefinition 1.2 (\\(\\sigma\\)-additive)  \n\n\\(\\mathcal{A}\\): a collection of subsets of \\(\\Omega\\) containing the empty set \\(\\emptyset\\)\nA set function on \\(\\mathcal{A}\\): \\(\\mu : \\mathcal{A} \\rightarrow [0,\\infty]\\) with \\(\\mu (\\emptyset) = 0\\)\nWe say that \\(\\mu\\) is countably additive, or \\(\\sigma\\)-additive, if for all sequences \\((A_n)\\) of disjoint sets in \\(\\mathcal{A}\\) with \\(\\cup_{n=1}^{\\infty}A_n \\in \\mathcal{A}\\) \\[\n\\mu \\Big( \\bigcup_{n=1}^{\\infty} A_n \\Big) = \\sum_{n=1}^{\\infty}\\mu (A_n).\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\nRecall that a measurable space is a pair \\((\\Omega, \\mathcal{F})\\), where \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(\\Omega\\).\n\n\n\n\nDefinition 1.3 (Measure space)  \n\nA measure space is a triple \\((\\Omega, \\mathcal{F}, \\mu)\\), where\n\n\\(\\Omega\\): set\n\\(\\mathcal{F}\\): \\(\\sigma\\)-algebra on \\(\\Omega\\)\n\\(\\mu\\): \\(\\mathcal{F} \\rightarrow [0,\\infty]\\) is a countably additive set function.\nThen \\(\\mu\\) is a measure on \\((\\Omega, \\mathcal{F})\\).\n\n\n\n\n이산 측도를 생각하는 것은 그냥 power set에서 생각하면 되기에 쉽다. 그러나 일반적인 상황에서는 \\(\\Omega\\)의 모든 subset을 잴 수 있는 measure를 정의할 수 없다. 그래서 “충분히 큰” collection of sets에서 정의되는 측도의 존재를 보이는 것은 쉽지 않다. 한 가지 방법으로 \\(\\Omega\\)의 smaller class of subsets에서의 측도를 만들고 \\(\\sigma\\)-algebra를 generate하는 방법이 있다. 이를 위해 두 가지 문제를 해결해야 한다.\n\n(Construction) 우리가 특정한 measure를 whole \\(\\sigma\\)-algebra에 확장할 수 있을까? (Caratheodory’s Extension Theorem)\n(Uniqueness) \\(\\sigma\\)-algebra에서 우리가 만들고자 하는 측도가 단 한개만 존재하는가? (\\(\\pi-\\lambda\\) systems Lemma)\n\n\n1.2.1 Lebesgue measure\n\n\nDefinition 1.4 (Existence and uniqueness of Lebesgue measure)  \n\nThere exists a unique Borel measure \\(\\lambda\\) on \\([0,1]\\) such that \\(\\lambda (I) = \\vert I \\vert\\) for any interval \\(I\\).\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n\\(S = \\{ (a,b] \\cap [0,1]\\}\\)은 \\(\\mathcal{B}\\)를 생성하는 \\(\\pi\\)-system이다. 따라서 Lemma 1.3 에 의해 uniqueness가 증명된다.\nExistence는 증명이 길고 복잡한데, 몇 가지 개요만을 아래에서 서술한다. 좀 더 자세한 사항은 PROBABILITY THEORY - PART 1 MEASURE THEORETICAL FRAMEWORK 를 보길 바란다. 여기서는 \\(\\Omega = [0,1]\\)로 둔다.\n\n\n\n\n\nOuter measure \\(\\lambda_{*}\\)를 정의한다. \\[\n\\lambda_{*}(A) = \\inf \\{ \\sum \\vert I_k \\vert : \\text{ each }I_k \\text{ is an open interval and } \\{I_k\\} \\text{ a countable cover for } A \\}.\n\\] 참고로 outer measure의 성질은 다음과 같다.\n\n모든 subset \\(A\\subseteq \\Omega\\)에 대해 \\(0\\leq \\lambda_{*}(A) \\leq 1\\)\n\\(\\lambda_{*}(A\\cup B) \\leq \\lambda_{*}(A) + \\lambda_{*}(B)\\), for any \\(A, B \\subseteq \\Omega\\)\n\\(\\lambda_{*}(\\Omega)=1\\)\n\n\\(\\lambda_{*}\\)가 측도가 되도록 하는 \\(\\sigma\\)-field를 잡는다. \\(\\lambda_{*}\\)를 a set \\(\\Omega\\)에서의 outer measure라고 하자. Caratheodary의 정의에 의해 \\[\n\\mathcal{F}:= \\{ A\\subseteq \\Omega : \\lambda_{*}(E) = \\lambda_{*}(A\\cap E) + \\lambda_{*}(A^c \\cap E) \\text{ for any } E\\}.\n\\] 이때 \\(\\mathcal{F}\\)가 \\(\\sigma\\)-algebra이고 \\(\\lambda_{*}\\) restricted to \\(\\mathcal{F}\\)가 확률측도임을 보일 수 있다.\n\\(A= (a,b]\\subseteq [0,1]\\)일 때 \\(A\\in \\mathcal{F}\\)임을 보여 \\(\\mathcal{F}\\)가 모든 보렐 집합을 포함함을 보인다. 즉 \\(\\mathcal{F}\\)가 충분히 큼을 보인다.\n\n\n\n1.2.2 Construction of Lebesgue measure\n\nLebesgue 측도의 구축은 충분히 풍부한 집합 class에서 시작하여 흥미로운 측도를 구성하는 일반적인 절차로 발전할 수 있다.\n\n주어진 algebra \\(\\mathcal{A}\\) (이 경우 유한 개의 \\((a,b]\\)의 합집합) 와 \\(\\mathcal{A}\\) 위의 countably additive probability measure \\(P\\) on \\(\\mathcal{A}\\)에 대해, 모든 부분집합에 대해 outer measure \\(P^{*}\\)를 \\(\\mathcal{A}\\)의 집합들로 구성된 countable cover에 대한 최솟값을 취함으로써 구성한다. 구체적으로, 임의의 부분집합 \\(E\\)에 대해 \\[\nP^{*}(E) = \\inf \\{\\sum_{i=1}^{\\infty} P(A_i): E \\supseteq \\cup_{i=1}^{\\infty}A_i, A_i \\in \\mathcal{A} \\}.\n\\]\n\\(\\mathcal{F}\\)를 위에서와 같이 정의하고, \\(\\mathcal{F}\\supset \\mathcal{A}\\)가 \\(\\sigma\\)-algebra이고 \\(P^{*}\\)가 \\(\\mathcal{A}\\)에서의 확률측도임을 보인다.\n\\(P^{*}=P\\) on \\(\\mathcal{A}\\)임을 보인다.\n\n\n\n1.2.3 Push-forward (image) measure\n\nMeasure를 정의하는 방법\n\nCaratheodory Extension Theorem\nTransportation between spaces via functions.\n\n\n\nDefinition 1.5 (Push-forward measure)  \n\n\\((\\Omega, \\mathcal{F}, \\mathbb{P})\\)를 확률공간이라 하고, \\(X\\)를 \\((\\Omega, \\mathcal{F})\\)에서 \\((E, \\mathcal{E})\\)로 보내는 확률변수라 하자. 그러면 \\[\n\\mathbb{Q}(A) = \\mathbb{P}(X^{-1}(A)), \\quad{} A\\in \\mathcal{E}\n\\] 는 \\((E,\\mathcal{E})\\)에서 측도를 정의한다 (push-forward measure).\n이때 \\(\\mathbb{Q} = \\mathbb{P}\\circ X^{-1}\\)이라고 쓰고 law of the distribution of \\(X\\)라고 부른다.\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n집합 \\(E\\)의 측도로 먼저 이를 \\(X^{-1}\\)을 이용해 \\(\\Omega\\)로 보내고 \\(\\mathbb{P}\\)를 이용해 잰다.\nPush-forward measure는 change-of-variables formula 등 적분이론에서 많이 쓰임\n\\(\\mathbb{Q}\\)가 측도인 이유는 만약 \\(A_n\\)이 pairwise disjoint이면 \\(X^{-1}(A_n)\\) 또한 pairwise disjoint이기 때문이다. 그러나 \\(B_n\\)이 \\(\\Omega\\)에서 pairwise disjoint라고 해서, \\(X(B_n)\\)이 disjoint하지는 않다. 그래서 일반적으로 pull-back measure는 없다. 그러나 \\(X\\)가 일대일함수면 \\(X^{-1}\\)을 pull-back으로 생각할 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#integration",
    "href": "measure.html#integration",
    "title": "1  Measure and Integration",
    "section": "1.3 Integration",
    "text": "1.3 Integration\n\n1.3.1 Integration notations\n\n\n\n\n\n\nRemark\n\n\n\n적분이론에서 굉장히 다양한 적분 notation을 쓰는데 알아두면 좋을 듯\n\n\n\n\n\\((E,\\mathcal{E},\\mu)\\): measure space, \\(f: E \\rightarrow\\mathbb{R}\\): a real-valued transformation\n다음의 세 개의 기호는 같은 것임\n\n\\(\\int_E f(x) d\\mu (x)\\)\n\\(\\int_E f d\\mu\\) (적분하려는 변수가 분명한 경우 생략)\n\\(\\int_E f(x) \\mu (dx)\\)\n\n\n\n\n1.3.2 리만-스틸체스 적분\n종종 헷갈리는 표현이 기댓값을 다음과 같이 분포함수를 이용해 표현하는 경우가 있다.\n\\[\nE(X) = \\int x dF(x).\n\\]\n우리가 알고 있는 정적분은 \\(x\\)축을 따라가며 함수값 f(x)가 만드는 면적을 계산한다.\n\\[\n\\int_a^b f(x) dx.\n\\]\n위 식을 더 확장하면 \\(x\\) 대신 임의의 곡선 \\(g(x)\\)를 적분 변수로 두고 \\(f(x)\\) 를 단순하게 정적분 할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x).\n\\]\n여기서 \\(dg(x)\\)는 \\(g(x)\\)의 미분소(differential)로, \\(g(x)\\)의 움직임을 결정하는 \\(x\\)는 단조 증가하거나 감소한다. 위와 같이 리만 적분을 일반화한 정적분을 리만-스틸체스 적분(Riemann-Stieltjes Integral)이라 한다. 리만 적분의 정의를 이용해 리만-스틸체스의 적분을 표현할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x) = \\lim_{N\\rightarrow \\infty} \\sum_{n=0}^{N-1} f(t_n) [g(x_{n+1}) - g(x_n)].\n\\]\n여기서 \\(x_n\\)은 정적분을 위해 구간 \\([a,b]\\)를 나눈 점, \\(t_n\\)은 닫힌 세부공간 \\([x_n, x_{n+1} ]\\)사이에 있는 임의점이다.\n\nExample 1.2 (리만-스틸체스 적분을 이용한 기댓값의 계산)  \n\n\n\\(X\\): random variable with support \\(R_X = [0,1]\\) and distribution function \\[\nF_X(x) = \\begin{cases}\n0, &\\text{if } x &lt;0\\\\\n\\frac{1}{2}x, &\\text{if } 0 \\leq x &lt; 1\\\\\n1, &\\text{if } x \\geq 1.\n\\end{cases}\n\\]\n이때의 기댓값은 \\[\n\\begin{aligned}\nE[X] &= \\int_{-\\infty}^{\\infty} x dF_X(x)\\\\\n&= \\int_0^1 xdF_{X}(x) + 1\\cdot \\Big[ F_X(1) -\\lim_{x\\rightarrow 1, x &lt; 1}F_X(x) \\Big]\\\\\n&= \\int_0^1 x \\frac{d}{dx} \\Big(\\frac{1}{2}x \\Big) dx  + 1 \\cdot \\Big[ 1- \\frac{1}{2} \\Big]\\\\\n&= \\Big[\\frac{1}{4}x^2 \\Big]_{0}^1 + \\frac{1}{2} = \\frac{1}{4}+\\frac{1}{2}=\\frac{3}{4}.\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#리만-적분과-르베그-적분",
    "href": "measure.html#리만-적분과-르베그-적분",
    "title": "1  Measure and Integration",
    "section": "1.4 리만 적분과 르베그 적분",
    "text": "1.4 리만 적분과 르베그 적분\n여기는 Confused when changing from Lebesgue Integral to Riemann Integral 에 올라왔던 내용을 살펴보기로 한다. 여기서 질문자는 리만 적분을 어떻게 르베그 적분으로 바꾸는지에 대해 관심이 있다.\n다음과 같이 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서 정의된 음이 아닌 확률변수 \\(X\\)가 지수분포를 따른다고 하자. \\[\nP(X&lt;x) = 1-e^{-\\lambda x}.\n\\] 한편, 르베그 적분으로 \\(X\\)의 기댓값을 쓰면 다음과 같다. \\[\nE[X] = \\int_{\\{\\omega | X(\\omega) \\geq 0 \\}} X(\\omega) dP(\\omega).\n\\] 여기서 질문자는 이것을 리만 적분으로 어떻게 바꾸냐 \\[\nE[X] = \\int_0^\\infty x \\lambda e^{-\\lambda x}dx\n\\] 를 물어보고 있다.\n답변은 이것이 적분의 문제가 아닌 변수변환의 문제라고 한다.\nBy definition, given \\(X: \\Omega \\rightarrow \\mathbb{R}\\) a random variable, \\(E[X] = \\int_{\\Omega} X\\). \\(X\\) defines a measure \\(\\tilde{m}\\) in \\(\\mathbb{R}\\), called the push-forward, by \\(\\tilde{m}(A) = P(X^{-1}(A))\\). By definition, this measure is invariant under \\(X\\), and hence \\[\n\\int_{\\mathbb{R}} f d\\tilde{m} = \\int_{\\Omega} f \\circ X dP.\n\\] The equality follows from the usual arguments (prove for characteristics, simple functions, then use convergence. Recall that \\(1_A \\circ X = 1_{X^{-1}(A)}\\)).\nLet \\(h\\) be the density of \\(X\\). We then have, by definition of density, that \\(\\tilde{m}(A) = P(X^{-1}(A)) = \\int_A h dm\\) for any \\(A \\in \\mathcal{B}(\\mathbb{R})\\), where \\(m\\) is the Lebesgue measure. By change of variables, we have \\[\n\\int_{\\mathbb{R}}f d\\tilde{m} = \\int_{\\mathbb{R}} f\\cdot h dm.\n\\] Combining these equations, \\[\n\\int_{\\mathbb{R}} f \\cdot h dm =\\int_{\\Omega} f \\circ X dP.\n\\] Taking \\(f=\\text{Id}\\) yields \\[\n\\int_{\\mathbb{R}}xh(x)dx = \\int_{\\Omega} X dP = E[X].\n\\] Taking \\(f = \\text{Id} \\cdot \\mathbf{1}_{I}\\), where \\(I\\) is some interval (for example, \\((0, +\\infty)\\) as in your case), we have \\[\n\\int_{I}xh(x)dx = \\int_{X^{-1}}XdP,\n\\] recalling again that \\(\\mathbf{1}_A \\circ X = \\mathbf{1}_{X^{-1}(A)}\\). Since \\(P(X&lt;0)\\) in your case is \\(0\\), this last integral is actually equal to the integral over the whole space, and hence to \\(E[X]\\), which gives your equality.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "2  Probability",
    "section": "",
    "text": "2.1 Probability Triples\n다음은 콜모고로프 가 정리한 수리적 기반의 확률론이다.\nQ. 왜 probability triple이 필요한가? Single도 아니고 double도 아니고 왜 triple이어야 하는가?",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "prob.html#probability-triples",
    "href": "prob.html#probability-triples",
    "title": "2  Probability",
    "section": "",
    "text": "Sample space \\(\\Omega\\) (표본공간): 이것은 any non-empty set이면 된다. 예를 들어 uniform distribution일 때 \\(\\Omega = [0,1]\\)이 있다.\n\\(\\mathcal{F}\\): \\(\\sigma\\)-algebra 또는 \\(\\sigma\\)-field: 이것은 \\(\\Omega\\)의 subset들의 collection으로 \\(\\emptyset\\), \\(\\Omega\\) 등을 포함한다.\nProbability \\(P\\): a mapping from \\(\\mathcal{F}\\) to \\([0,1]\\) with\n\n\\(P(\\emptyset)=0\\)\n\\(P(\\Omega)=1\\)\n\\(P\\) is countably additive, \\(P(A_1 \\cup A_2 \\cup \\cdots) = P(A_1) + P(A_2) + \\cdots\\)\n\n\n\n\n\n\nRecall that the elements of any field or \\(\\sigma\\)-field (Definition 1.1 참고) are called random events (or simply events).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "prob.html#probabilities",
    "href": "prob.html#probabilities",
    "title": "2  Probability",
    "section": "2.2 Probabilities",
    "text": "2.2 Probabilities\n\n\nDefinition 2.1 (Probability)  \n\nLet \\(\\Omega\\) be any set and \\(\\mathcal{A}\\) be a field of its subsets. We say that \\(P\\) is a probability on the measurable space \\((\\Omega, \\mathcal{A})\\) if \\(P\\) is defined for all events \\(A\\in\\mathcal{A}\\) and satisfies the following axioms.\n\n\n\\(P(A)\\geq 0\\) for each \\(A\\in \\mathcal{A}\\); \\(P(\\Omega)=1\\)\n\\(P\\) is finitely additive. That is, for any finite number of pairwise disjoint events \\(A_1, \\ldots, A_n \\in \\mathcal{A}\\) we have \\[\nP\\Big( \\cup_{i=1}^n A_i \\Big) = \\sum_{i=1}^n P(A_i).\n\\]\n\\(P\\) is continuous at \\(\\emptyset\\). That is, for any events \\(A_1, A_2, \\ldots, \\mathcal{A}\\) such that \\(A_{n+1} \\subset A_n\\) and \\(\\cap_{n=1}^{\\infty}A_n = \\emptyset\\), it is true that \\[\n\\lim_{n\\rightarrow \\infty}P(A_n) = 0.\n\\]\n\nNote that conditions 2 and 3 are equivalent to the next one 4.\n\n\\(P\\) is \\(\\sigma\\)-additive (countably additive), that is \\[\nP\\Big( \\cup_{n=1}^{\\infty} A_n\\Big) = \\sum_{n=1}^{\\infty}P(A_n)\n\\] for any events \\(A_1, A_2, \\ldots \\in \\mathcal{A}\\) which are pairwise disjoint.\n\n\n\nExample 2.1 (A probability measure which is additive but not \\(\\sigma\\)-additive) Let \\(\\Omega\\) be the set of all rational numbers \\(r\\) of the unit interval \\([0,1]\\) and \\(\\mathcal{F}_1\\) the class of the subsets of \\(\\Omega\\) of the form \\([a,b]\\), \\((a,b]\\), \\((a,b)\\) or \\([a,b)\\) where \\(a\\) and \\(b\\) are rational numbers. Denote by \\(\\mathcal{F}_2\\) the class of all finite sums of disjoint sets of \\(\\mathcal{F}_1\\). Then \\(\\mathcal{F}_2\\) is a field. Let us define the probability measure \\(P\\) as follows: \\[\n\\begin{aligned}\nP(A) &= b-a, \\quad{} \\text{if } A \\in \\mathcal{F}_1,\\\\\nP(B) &= \\sum_{i=1}^n P(A_i), \\quad{} \\text{if } B\\in \\mathcal{F}_2, \\text{ that is, } B=\\sum_{i=1}^n A_i, A_i \\in \\mathcal{F}_1.\n\\end{aligned}\n\\]\nConsider two disjoint sets of \\(\\mathcal{F}_2\\) say \\[\nB=\\sum_{i=1}^n A_i \\quad{} \\text{ and } B' = \\sum_{j=1}^m A_j',\n\\] where \\(A_i, A_j' \\in \\mathcal{F}_1\\) and all \\(A_i, A_j'\\) are disjoint. Then \\(B+B' = \\sum_{k=1}^{m+n}C_k\\) where either \\(C_k = A_i\\) for some \\(i=1, \\ldots, n\\), or \\(C_k = A_j'\\) for some \\(j=1, \\ldots, m\\). Moreover, \\[\n\\begin{aligned}\nP(B+B')&= P\\Big( \\sum_k C_k \\Big) = \\sum_k P(C_k) = \\sum_{i,j}(P(A_i) + P(A_j'))\\\\\n&= P(A_i) + \\sum_{j} P(A_j') = P(B) + P(B').\n\\end{aligned}\n\\]\nand hence \\(P\\) is an additive measure.\nObviously every one-point set \\(\\{r\\}\\in\\mathcal{F}_2\\) and \\(P(\\{r\\}) = 0\\). Since \\(\\Omega\\) is a countable set and \\(\\Omega = \\sum_{i=1}^{\\infty}\\{r_i\\}\\), we get \\[\nP(\\Omega) = 1\\neq 0 = \\sum_{i=1}^{\\infty} P(\\{r_i\\}).\n\\] This contradiction shows that \\(P\\) is not \\(\\sigma\\)-additive.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "rvs.html",
    "href": "rvs.html",
    "title": "3  Random Variables",
    "section": "",
    "text": "3.1 Random Variables\nQ. Random variable을 정의하는데 왜 inverse image를 쓰는가?\nCommonly a probability measure \\(P\\) is added to \\((\\Omega, \\mathcal{F})\\). Then sets like \\(\\{X \\in A\\}:= \\{\\omega \\in \\Omega | X(\\omega) \\in A\\}\\) can \\(=X^{-1}(A)\\) be measured if they belong to \\(\\mathcal{F}\\). 예를 들면 \\(X: \\Omega \\rightarrow \\mathbb{R}\\)이 확률변수일 때 \\(X&lt;1\\)일 확률을 구하려면 \\(X^{-1}(-\\infty, 1)\\)이 가측이어야 할 것이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#random-variables",
    "href": "rvs.html#random-variables",
    "title": "3  Random Variables",
    "section": "",
    "text": "Definition 3.1 (잴 수 있는 함수 (가측함수))  \n\n확률공간: \\((\\Omega, \\mathcal{F}, P)\\), \\(f: \\Omega \\rightarrow \\mathbb{R}\\) \\[\nB \\in \\mathcal{B}(\\mathbb{R}) \\Longrightarrow f^{-1}(B) \\in \\mathcal{F}\n\\] 이면 함수 \\(f\\)를 잴 수 있는 함수(measurable function)라 부름\n\n\n\nExample 3.1 (잴 수 없는 함수의 예)  \n\n표본공간 \\(\\Omega =\\{1,2,3\\}\\), 사건공간 \\(\\mathcal{F} =\\{ \\Omega, \\emptyset, \\{1,2\\},\\{3\\} \\}\\)\n이때 \\(f(1)=1, f(2)=2, f(3)=3\\)인 함수 \\(f: (\\Omega,\\mathcal{F}) \\rightarrow (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\)인 함수\n그런데 \\(\\{1\\} \\in \\mathcal{B}(\\mathbb{R})\\)이지만 \\(f^{-1}(\\{1\\}) = \\{1\\}\\notin \\mathcal{F}\\)이므로 \\(f\\)는 가측이 아니며, 따라서 확률변수가 아님\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n확률변수는 확률공간 위에서 잴 수 있는 함수임\n\n\n\n\nDefinition 3.2 (Random Variables) Given a probability triple \\((\\Omega, \\mathcal{F}, P)\\), a random variable is a function \\(X\\) from \\(\\Omega\\) to \\(\\mathbb{R}\\), such that \\[\n\\{ \\omega \\in \\Omega; X(\\omega) \\leq x  \\} \\in \\mathcal{F} ,\\quad{} x \\in \\mathbb{R}.\n\\]\n\n\n\n\n\nExample 3.2 (확률변수의 inverse image) Proschan (2016) 예제 4.2이다.\n\n\\((\\Omega, \\mathcal{F}, P) = ((0,1),\\mathbb{B}_{(0,1)}, \\mu_L)\\)에서의 확률변수 \\[\nX(\\omega) = \\frac{1}{\\omega (1-\\omega)}\n\\] 를 생각하자.\nBorel set \\(B\\)를 \\(\\{ (6.25, \\infty) \\cup \\{4\\}\\}\\)\n역상: \\(X^{-1}(B) = \\{ (0,0.2) \\cup (0.8,1) \\cup \\{0.5\\} \\} \\in \\mathcal{B}_{(0,1)}\\)\n\n\n\n\n\n\nFigure: 확률변수 \\(X\\)의 그림.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#radon-nikodym-derivative",
    "href": "rvs.html#radon-nikodym-derivative",
    "title": "3  Random Variables",
    "section": "3.2 Radon-nikodym derivative",
    "text": "3.2 Radon-nikodym derivative\n\n\n\n\n\n\nChange of measures.\n\n\n\n\n확률측도는 volume element의 일반화라고 볼 수 있다.\n\n\\(\\mu(x)\\): probability measure, interval이나 set of points들을 인풋으로 받고 area/volume에 해당하는 확률(양수)을 아웃풋으로 주는 함수다.\n\\(\\lambda (x)\\): reference measure. We often take \\(\\lambda (x)\\) as the Lebesgue measure which is essentially just a uniform function over the sample space.\n\nThe reference measure \\(\\lambda (x)\\) is essentially just a meter-stick that allows us to express the probability measure as a simple function \\(f(x)\\). That is, we represent the probability measure \\(\\mu(x)\\) as \\(f(x)\\) by comparing the probability measure to some specified reference measure \\(\\lambda (x)\\). This is essentially the intuition that is given by the Radon-Nikodym derivative \\[\nf(x) = \\frac{d\\mu (x)}{d\\lambda (x)}\n\\] or equivalently \\[\n\\text{height = area / width.}\n\\] Note that we can also represent the same idea by \\[\n\\mu (A) = \\int_{A\\in X} f(x) d\\lambda (x),\n\\] where \\(\\mu(A)\\) is the sum of the probability of events in the set \\(A\\) which is itself a subset of the entire sample space \\(X\\). Note that when \\(A=X\\) then the integral must equal \\(1\\) by definition of probability.\n라돈-니코딤 정리는 조건부 확률에 응용된다고 함.\n\nDefinition 3.3 (Integrable Random Variable) Gut (2014) 의 53쪽에 따르면, \\(E|X|&lt;\\infty\\)인 경우 random variable \\(X\\)가 integrable 하다고 부른다.\n\n\n\nExample 3.3 Given a probability measure \\(P\\) and sample space \\(\\Omega\\), it is true that \\[\n\\int_{\\Omega} dP = 1.\n\\] Because \\[\n\\int_{\\Omega} dP = P(\\Omega) = 1.\n\\] More generally \\[\n\\int_A dP = \\int_{\\Omega} 1_A dP = P(A), \\quad{} A \\in \\mathcal{F}.\n\\]\n\n\nDefinition 3.4 (\\(\\mathcal{L}^p\\)) 다음과 같은 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)를 생각하자. \\(p&gt;1\\)에 대해, 확률변수 \\(X\\)가 \\(E|X|^p &lt; \\infty\\)이면 \\(X\\in \\mathcal{L}^p\\)라고 하며 다음과 같은 놈 \\(\\|X_p\\| = (E|X|^p)^{\\frac{1}{p}}\\)를 정의할 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#distribution",
    "href": "rvs.html#distribution",
    "title": "3  Random Variables",
    "section": "3.3 Distribution",
    "text": "3.3 Distribution\n\n\n확률변수의 정의는 임의의 measurable subset of possible outcomes (points, bounded/unbounded intervals 등)에 measure (확률)를 부여할 수 있어야 함\nSemi-infinite interval \\((-\\infty, x]\\) 또한 이러한 measurable subset이므로 \\(\\mathbb{R}\\)에서 정의된 모든 확률변수는 CDF를 갖음\nPDF는 CDF의 도함수 개념이므로 CDF가 미분가능해야 전역적으로 PDF도 존재",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#expectation",
    "href": "rvs.html#expectation",
    "title": "3  Random Variables",
    "section": "3.4 Expectation",
    "text": "3.4 Expectation\n\n\nExpectation: integral with respect to the probability measure\n\n\nDefinition 3.5 (Expectation)  \n\n\\((\\Omega, \\mathcal{A}, \\mathbb{P})\\): Probability space\n\n\\(\\Omega\\): set (sample space)\n\\(\\mathcal{A}\\): \\(\\sigma\\)-algebra on \\(\\Omega\\)\n\\(\\mathbb{P}\\): Probability measure\n\n\\(X: \\Omega \\rightarrow \\mathbb{R}\\): Random variable (a measurable fct)\nExpectation: The concept of integral of \\(X\\) w.r.t. \\(\\mathbb{P}\\) \\[\nE[X] \\stackrel{\\Delta}{=}\\int_{\\Omega} X(\\omega) d\\mathbb{P}[\\omega]\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n다음의 notation들은 모두 \\(X\\)의 기댓값을 의미\n\n\\(\\int_{\\Omega} X(\\omega) d\\mathbb{P}[\\omega]\\)\n\\(\\int_{\\Omega} X d\\mathbb{P}\\) (적분하려는 변수가 분명한 경우 생략)\n\\(\\int_{\\Omega} X(\\omega) \\mathbb{P}[d\\omega]\\)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#cantor-random-variable",
    "href": "rvs.html#cantor-random-variable",
    "title": "3  Random Variables",
    "section": "3.5 Cantor Random Variable",
    "text": "3.5 Cantor Random Variable\n\nCantor distribution: 누적분포함수가 Cantor function인 probability distribution\nCantor distribution은 PDF나 PMF가 존재하지 않음\n동전던지기를 할 때, \\(n\\)번째 던지기에서 앞면이 나왔을 때 \\(\\frac{2}{3^n}\\)을 갖는 실험을 하면, 최종적으로 \\(X\\) 달러를 받는다고 할 때, \\(X\\)는 확률변수이며 Cantor distribution의 예가 됨\n특별히 \\(\\{\\xi_n\\}\\)을 i.i.d. Bernoulli라 할 때 칸토르 확률변수 \\(X\\)를 \\(X=\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\xi_n\\)과 같이 놓을 수 있음 (위의 예제 참고)\n\n\n\n칸토를 집합을 \\(C\\)라 하고, \\(X\\in C\\)라 할 때, 칸트로 집합이 Lebesgue measure 0 임을 알고 있으며, \\(P(X\\in C)=1&gt;0\\)이므로 \\(X\\)는 not absolutely continuous with respect to the Lebesgue measure임\n\n\nExample 3.4 (Cantor distribution의 적률 계산)  \n\n\nPDF나 PMF가 존재하지 않더라도 Cantor distribution 같이 음이 아닌 확률변수에서는 \\(F(x) = P(X&gt;x)\\)를 계산할 수 있고, 이를 이용해 \\[\n\\begin{align*}\nE(X) &= \\int_0^{\\infty} F(x) dx\\\\\n\\text{Var} (X) &= \\int_0^{\\infty} 2x F(x) dx - \\Big( \\int_0^{\\infty}F(x) dx \\Big)^2\n\\end{align*}\n\\] 와 같이 기댓값과 분산을 구할 수 있음\n특별히 \\(\\{\\xi_n\\}\\)을 i.i.d. Bernoulli라 할 때 칸토르 확률변수 \\(X\\)를 \\(X=\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\xi_n\\)과 같이 놓을 수 있고 (앞선 동전던지기 참고) \\(E(\\xi_n)=\\frac{1}{2}\\), \\(\\text{Var}(\\xi_n) = \\frac{1}{4}\\)라는 점을 이용해 다음과 같이 구할 수 있음 \\[\n\\begin{align*}\nE(X) &= \\sum_{n=1}^{\\infty} E\\Big( \\frac{2}{3^n} \\xi_n \\Big)= \\sum_{n=1}^{\\infty}  \\frac{2}{3^n} E(\\xi_n)\\\\&= \\sum_{n=1}^{\\infty} \\frac{2}{3^n }\\cdot \\frac{1}{2}= \\sum_{n=1}^{\\infty} \\frac{1}{3^n} = \\frac{1}{2}\\\\\n\\text{Var}(X) &= \\sum_{n=1}^{\\infty} \\text{Var}\\Big( \\frac{2}{3^n} \\xi_n \\Big)= \\sum_{n=1}^{\\infty}  \\Big(\\frac{2}{3^n}\\Big)^2 \\text{Var}(\\xi_n)\\\\&= \\sum_{n=1}^{\\infty} \\frac{4}{9^n }\\cdot \\frac{1}{4}= \\sum_{n=1}^{\\infty} \\frac{1}{9^n} = \\frac{1}{8}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#borel-cantelli-lemmas",
    "href": "rvs.html#borel-cantelli-lemmas",
    "title": "3  Random Variables",
    "section": "3.6 Borel-Cantelli Lemmas",
    "text": "3.6 Borel-Cantelli Lemmas\n\nAlmost sure convergence Definition 6.2 와 관련된 툴\n\n\nTheorem 3.1 (The first Borel-Cantelli lemma) Let \\(\\{A_n, n \\geq 1\\}\\) be arbitrary events. Then \\[\n\\sum_{n=1}^{\\infty}P(A_n) &lt; \\infty \\Longrightarrow P(A_n \\text{ i.o.})=0.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\nP(A_n \\text{ i.o.}) &= P(\\lim\\sup_{n\\rightarrow\\infty}A_n) = P \\Big (\\bigcap_{n=1}^{\\infty}\\bigcup_{m=n}^{\\infty}A_m\\Big)\\\\\n&\\leq P\\Big( \\bigcup_{m=n}^{\\infty}A_m \\Big) \\leq \\sum_{m=n}^{\\infty}P(A_m) \\stackrel{n\\rightarrow\\infty}{\\longrightarrow}0.\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\nThe first Borel-Cantelli lemma의 역은 성립하지 않는다. 그러나 독립 조건을 넣으면 다음과 같은 second Borel-Cantelli lemma를 얻을 수 있다.\n\n\n\n\nTheorem 3.2 (The second Borel-Cantelli lemma) Let \\(\\{A_n, n \\geq 1\\}\\) be independent events. Then \\[\n\\sum_{n=1}^{\\infty}P(A_n) = \\infty \\Longrightarrow P(A_n \\text{ i.o.})=1.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy independence \\[\n\\begin{align*}\nP(A_n \\text{ i.o.}) &= P(\\lim\\sup_{n\\rightarrow\\infty}A_n) = P \\Big (\\bigcap_{n=1}^{\\infty}\\bigcup_{m=n}^{\\infty}A_m\\Big)=1-P \\Big (\\bigcup_{n=1}^{\\infty}\\bigcap_{m=n}^{\\infty}A_m^c\\Big)\\\\\n&=1 - \\lim_{n\\rightarrow\\infty}P\\Big( \\bigcap_{m=n}^{\\infty}A_m^c\\Big) = 1-\\lim_{n\\rightarrow\\infty}\\prod_{m=n}^{\\infty}P(A_m^c)\\\\\n&=1 - \\lim_{n\\rightarrow\\infty}\\prod_{m=n}^{\\infty}(1-P(A_m)) = 1-0 = 1.\n\\end{align*}\n\\]\n\n\n\n\n\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.\n\n\nProschan, Michael A. 2016. Essentials of Probability Theory for Statisticians. CRC Press.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "ineq.html",
    "href": "ineq.html",
    "title": "4  Inequalities",
    "section": "",
    "text": "4.1 왜 concentration inequality가 필요한가?\nFigure: CLT 묘사.\nQ. \\(N\\)번 시행 시 \\(\\frac{3}{4}\\)이상 앞면이 나올 확률을 구하고 싶다.\nFigure: Berry-Essen bound와 empirical difference.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#왜-concentration-inequality가-필요한가",
    "href": "ineq.html#왜-concentration-inequality가-필요한가",
    "title": "4  Inequalities",
    "section": "",
    "text": "출처: Concentration Inequalities\n\n\n\nHigh-Dimensional Probability 책에 있는 동전 던지기 예제 생각\n\\(i\\)번째 동전던지기: 앞면이 나오면 1, 뒷면이 나오면 0인 Bernoulli random variable로 간주 가능\n\\(N\\)번 던졌을 때 나온 앞면의 수: \\(S_N = \\sum_i X_i\\)\nde Moivre-Laplace theorem (Binomial의 CLT) \\[\nZ_N \\stackrel{D}{\\rightarrow}\\mathcal{N}(0,1)\n\\] 이때 \\[\nZ_N  = \\frac{S_N - N_p}{\\sqrt{Np (1-p)}}\n\\]\n\n\n\n\nGaussian density는 exponential decay하는데, \\(Z_N\\)이 분포수렴하는 속도는 훨씬 느림\nCLT의 quantitative version인 Berry-Essen CLT를 보면 \\[\n|P\\{Z_n \\geq t\\} - P\\{Z \\geq t\\} | \\leq \\frac{C}{\\sqrt{N}}\n\\] 이때 \\(C\\)는 상수이며, convergence의 order가 \\(\\frac{1}{\\sqrt{N}}\\)임을 (아래 그림에 녹색으로 표시) 확인 가능",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#markov-inequality",
    "href": "ineq.html#markov-inequality",
    "title": "4  Inequalities",
    "section": "4.2 Markov inequality",
    "text": "4.2 Markov inequality\n\nTheorem 4.1 (Markov inequality) 음이 아는 확률변수 \\(X\\)에 대해 \\[\nP\\{ X\\geq t\\} \\leq \\frac{E[X]}{t}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n확률공간 \\((\\Omega, \\Sigma, P)\\)을 생각하자. \\[\nEX = \\int X dP \\geq \\int_{\\{X\\geq t\\}} X dP \\geq t \\int_{\\{X\\geq t \\}}dP \\geq t\\cdot P\\{ X\\geq t\\}\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n마르코프 bound는 매우 약한 (즉 true probabilty로의 수렴이 느린) bound\n그러나 \\(X\\)에 대한 제약조건이 없음 (기댓값 계산 필요, 음이 아닌 확률변수)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#chebyshev-inequality",
    "href": "ineq.html#chebyshev-inequality",
    "title": "4  Inequalities",
    "section": "4.3 Chebyshev inequality",
    "text": "4.3 Chebyshev inequality\n\nTheorem 4.2 (Chebyshev inequality) 어떤 확률변수 \\(X\\)에 대해 \\[\nP\\{|X-E(X)|\\geq t \\}\\leq \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(|X-E(X)|\\geq t\\)를 제곱한 후 마르코프 부등식을 적용 \\[\nP\\{ |X-E(X)|^2 \\geq t^2\\} \\leq \\frac{E[(X-E(X))]^2}{t^2} = \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n체비세프 부등식을 쓰려면 분산이 정의되어야 함",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#hoeffdings-inequality",
    "href": "ineq.html#hoeffdings-inequality",
    "title": "4  Inequalities",
    "section": "4.4 Hoeffding’s Inequality",
    "text": "4.4 Hoeffding’s Inequality\n\n(드디어) \\(\\sum_i X_i\\)에 대한 exponential bound를 줌\n그러나 독립 가정이 필요\n단순한 케이스로 먼저 \\(X_1, \\ldots, X_N\\)이 symmetric Bernoulli라고 하자. 이는 즉 반반의 확률로 1 또는 -1을 갖는 확률변수\n\n\nTheorem 4.3 (Symmetric Bernoulli에서의 Hoeffding’s inequality) \\(X_1, \\ldots, X_N\\)이 symmetric Bernoulli 확률변수라고 하자. 어떤 \\(t\\geq 0\\)에 대해 \\(a \\in \\mathbb{R}^n\\)이 존재해 \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq \\exp \\Big( - \\frac{t^2}{2\\|a\\|^2} \\Big)\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n마르코프 부등식을 적용하면 다음과 같다. \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} = P \\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\geq e^{\\lambda t} \\} \\leq e^{-\\lambda t}E\\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\}\n\\] 독립성에 의해 다음과 같다. \\[\nE\\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\} = E \\{ \\prod_{i=1}^N \\exp (\\lambda a_i X_i)  \\} = \\prod_{i=1}^N E\\{ \\exp (\\lambda a_i X_i)\\}\n\\] \\(X_i\\)를 \\(1/2\\)의 확률로 -1과 1을 갖는 확률변수라고 제한했으므로, 위의 기댓값을 쉽게 구할 수 있다. \\[\nE\\{ \\exp (\\lambda a_i X_i)\\} = \\frac{e^{\\lambda a_i }+ e^{-\\lambda a_i}}{2}\\leq e^{\\lambda^2 a_i^2 / 2}\n\\] 지수함수의 테일러 급수 전개를 이용하면 \\[\ne^{x}=\\sum_{k=0}^{\\infty}\\frac{x^k}{k!},\\quad{} \\frac{e^{x}+e^{-x}}{2} =\\sum_{k=0}^{\\infty}\\frac{x^{2k}}{(2k)!}, \\quad{} e^{x^2/2}=\\sum_{k=0}^{\\infty}\\frac{x^{2k}}{2^k k!},\\quad{} \\Longrightarrow\\quad{} \\frac{e^{x}+e^{-x}}{2} \\leq e^{x^2/2}.\n\\] \\(\\|a\\|^2=1\\)이라 두고 위의 결과를 대입해보자. \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq e^{-\\lambda t}(\\prod_{i=1}^N e^{\\lambda^2 a_i^2/2})\\leq e^{-\\lambda t}(e^{\\lambda^2 \\sum_{i=1}^N a_i^2/2}) = e^{-\\lambda t}(e^{\\lambda^2/2}) = e^{\\lambda^2/2 - \\lambda t}.\n\\] 위의 부등식은 모든 \\(\\lambda\\)에 대해 성립하고, \\(\\lambda=t\\)일 때 최소화된다. 따라서 \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq e^{-t^2/2}.\n\\] 따라서, homogeneity에 의해 \\(\\|a\\|=1\\)을 가정하면 다음과 같다. \\[\nP \\{ \\sum_{i=1}^N \\frac{a_i}{\\| a\\|}X_i \\geq \\frac{t}{\\|a\\|} \\} \\leq e^{-\\frac{t^2}{2\\|a\\|^2}}.\n\\]\n\n\n\n\\(X_i\\)가 1 또는 0을 갖는 베르누이 확률변수라고 할 때, \\(Y_i = 2(X_i - \\frac{1}{2})\\)로 놓으면 \\(Y_i\\)는 symmetric Bernoulli 확률변수임 \\[\nP\\{ \\sum_i X_i &gt; t\\} = P \\{ \\sum_i (\\frac{Y_i}{2}+ \\frac{1}{2}) &gt; t \\} = P\\{\\sum_i Y_i &gt; 2t - N \\} \\leq \\exp (-\\frac{(2t-N)^2}{2N})\n\\] 여기서 \\(a=\\begin{bmatrix} 1,1,\\ldots, 1 \\end{bmatrix}\\)로 두면 \\(\\|a\\|_2^2=N\\)이 된다. 따라서 \\[\nP\\{\\sum_i X_i &gt; \\frac{3N}{4} \\}\\leq \\exp (- \\frac{(\\frac{3N}{2}-N)^2}{2N}) = \\exp (-\\frac{N}{8})\n\\]\n\n\n\n\n\nFigure: Chebyshev와 Hoeffding bound의 비교.\n\n\n\n\n\nTheorem 4.4 (Hoeffding’s inequality) \\(X_1, \\ldots, X_N\\)이 독립인 확률변수이고, \\(X_i \\in [m_i, M_i]\\) almost surely라고 하자. 그러면 어떤 \\(t&gt;0\\)에 대해 \\[\nP \\{\\sum_{i=1}^N (X_i - E(X_i))\\geq t \\} \\leq \\exp (- \\frac{2t^2}{\\sum_{i=1}^N (M_i - m_i)^2})\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n앞에서처럼 \\(\\lambda\\)를 곱하고 제곱근을 취한 다음 마르코프 부등식을 이용한다 \\[\n\\begin{align*}\nP\\{\\sum (X_i - E(X_i)) \\geq t \\} &= P \\{\\exp (\\lambda \\sum (X_i - E(X_i)))\\geq e^{\\lambda t} \\}\\\\\n&\\leq E \\{\\exp (\\lambda \\sum (X_i - E(X_i)))\\} e^{-\\lambda t}\\\\\n&= \\prod_i E\\{\\exp (\\lambda (X_i - E(X_i))) \\}e^{-\\lambda t}.\n\\end{align*}\n\\] 그러면 기댓값의 bound만 찾아주면 된다. 여기서는 \\(X_i\\)와 독립인 copy인 \\(X_i'\\)를 생각하는 symmetrization 기법을 이용한다. \\[\n\\begin{align*}\nE\\{\\exp (\\lambda \\sum (X_i - E(X_i)) ) \\} &= E\\{\\exp (\\lambda \\sum (X_i - E(X_i')) ) \\} \\\\\n&= E_{X_i} \\{ \\exp (E_{X_i'} \\lambda \\sum (X_i - X_i')) \\}\\\\\n&\\leq E_{X_i} E_{X_i'} \\{ \\exp (\\lambda \\sum (X_i - X_i')) \\}\\\\\n&= E\\{ \\exp (\\lambda \\sum (X_i - X_i')) \\}.\n\\end{align*}\n\\] 여기서 exponential이 convex이므로 Jensen의 부등식을 적용하였다. 여기서 \\(X_i - X_i'\\)는 0 근처에서 symmetric이고 이것의 분포는 \\(S(X_i - X_i')\\)와 같다. 이때 \\(S\\)는 -1, 1을 동일한 확률로 갖는 Rademacher variable이다. \\[\n\\begin{align*}\nE\\{\\exp (\\lambda \\sum (X_i - E(X_i)) ) \\} &\\leq E_{X_i,X_i'} \\{ E_S \\exp (\\lambda \\sum S(X_i - X_i')) \\}\\\\\n&\\leq E_{X_i,X_i'} \\{ \\exp (\\lambda^2 (X_i - X_i')^2/2) \\}\\\\\n&\\leq \\exp (\\lambda^2 (M_i - m_i)^2/2).\n\\end{align*}\n\\] 이때 첫 번째 부등식은 exponential의 테일러 전개를, 두 번째 부등식은 \\(X_i\\)의 boundedness를 이용하였다. \\[\n\\begin{align*}\nP\\{\\sum (X_i - E(X_i)) \\geq t \\} &=  \\prod_i E\\{\\exp (\\lambda (X_i - E(X_i))) \\}e^{-\\lambda t}\\\\\n&= \\prod_i \\exp (\\lambda^2 (M_i - m_i)^2/2)e^{-\\lambda t}\\\\\n&= \\exp (\\lambda^2 \\sum_i (M_i - m_i)^2/2 -\\lambda t)\\\\\n&\\leq \\exp (\\frac{2t^2}{\\sum_i (M_i -m_i)^2}).\n\\end{align*}\n\\] 여기서 마지막 부등식은 exponent를 최소화하는 \\(\\lambda\\)를 잡았다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#chernoff-bounds",
    "href": "ineq.html#chernoff-bounds",
    "title": "4  Inequalities",
    "section": "4.5 Chernoff Bounds",
    "text": "4.5 Chernoff Bounds\n\n베르누이 확률변수에 대한 Hoeffding bound는 \\(p=0.5\\)일 때에는 잘 작동하지만, 작거나 큰 \\(p\\)에 대해서는 잘 작동하지 않음\n\\(X_i \\sim \\text{Bernoulli}(p)\\)라고 하고 \\(S_N = \\sum_{i=1}^N X_i\\)라고 두자. 그리고 Hoeffding의 부등식을 이용하여 \\(S_N &gt; 10pN\\)의 bound를 구해보자. \\[\nP \\{ \\sum_i X_i &gt; 10pN \\} = P\\{ \\sum_i X_i - pN &gt; 9pN \\}\\leq \\exp (-\\frac{2(9pN)^2}{N}) = \\exp (-182p^2 N).\n\\] 식을 보면 Binomial random variable이 평균보다 9배 클 확률의 bound를 계산함\n\n\n\nTheorem 4.5 (Chernoff inequality) \\(X_1, \\ldots, X_N\\)이 모수 \\(p_i\\)를 갖는 독립인 베르누이 확률변수라 하자. \\(S_N = \\sum_i X_i\\)이고 \\(\\mu = E(S_N)\\)이라고 하자. 그러면 \\(t&gt;\\mu\\)에 대해 \\[\nP \\{ S_N \\geq t \\} \\leq \\exp (-\\mu) \\Big( \\frac{e\\mu}{t} \\Big)^t.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n다시 \\(\\lambda\\)를 곱하고 마르코프 부등식을 적용하자. \\[\nP\\{ S_N \\geq t \\} \\leq E\\{ \\exp (\\lambda \\sum_{i} X_i) \\}e^{-\\lambda t} = \\prod_i E\\{ \\exp (\\lambda X_i) \\}e^{-\\lambda t}.\n\\] \\(1+x \\leq e^{x}\\)라는 부등식을 이용하면 다음과 같다. \\[\nP\\{ S_N \\geq t \\} \\leq  e^{\\lambda}p_i + (1-p_i) = 1 + (e^{\\lambda} - 1)p_i \\leq \\exp (p_i (e^\\lambda - 1)).\n\\] 이것을 정리하면 다음과 같다. \\[\n\\begin{align*}\nP\\{ S_N \\geq t \\} &\\leq \\prod_i \\exp (p_i (e^\\lambda -1))e^{-\\lambda t}\\\\\n&\\leq \\exp \\Big( (e^\\lambda - 1)\\sum_i p_i \\Big) e^{-\\lambda t}\\\\\n&\\leq \\exp ((e^{\\lambda}-1)\\mu) e^{-\\lambda t}.\n\\end{align*}\n\\] 여기서 \\(\\lambda\\)를 고를 수 있는데, \\(\\lambda = \\log (t/mu)\\)로 잡으면 다음과 같다. \\[\n\\begin{align*}\nP\\{ S_N \\geq t \\} &\\leq \\exp \\Big( (\\frac{t}{\\mu}-1)\\mu \\Big) \\Big( \\frac{\\mu}{t} \\Big)^t\\\\\n&= \\exp (t-\\mu) \\Big( \\frac{\\mu}{t} \\Big)^t\\\\\n&=\\exp (-\\mu) \\Big( \\frac{e\\mu}{t} \\Big)^t.\n\\end{align*}\n\\]\n\n\n\n\n다시 앞 예제에 Chernoff 부등식을 적용하면 \\[\nP \\{\\sum_i X_i &gt; 10pN \\} \\leq \\exp (-p N) \\Big( \\frac{epN}{10pN}\\Big)^{10pN} = \\exp (-p N) \\Big( \\frac{e}{10}\\Big)^{10pN}.\n\\]\n\n\n\n\n\n\nFigure: Hoeffding과 Chernoff bound의 비교.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#gaussian-tails-and-mgf",
    "href": "ineq.html#gaussian-tails-and-mgf",
    "title": "4  Inequalities",
    "section": "4.6 Gaussian tails and MGF",
    "text": "4.6 Gaussian tails and MGF\n\n출처: High-Dimensional Statistics Lecture Notes\n\\(X\\)가 Gaussian일 때 pdf \\[\np(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\Big( - \\frac{(x-\\mu)^2}{2\\sigma^2} \\Big), \\quad{} x \\in \\mathbb{R}\n\\]\n특별히 standard normal의 pdf를 다음과 같이 두기로 함 \\[\n\\phi (x) = \\frac{1}{\\sqrt{2\\pi}}\\exp \\Big( -\\frac{x^2}{2} \\Big)\n\\]\nBounded support: \\(P(|X-\\mu|\\leq 3\\sigma)\\) 등의 확률 구할 때 사용\n\n\n\nProposition 4.1 (Mills inequality) Gaussian density tail의 decay 속도를 알려줌\n\n\\(X\\sim \\mathcal{N}(\\mu, \\sigma^2)\\)일 때 \\(t&gt;0\\)에 대해 \\[\nP(|X-\\mu | &gt;t) \\leq \\sqrt{\\frac{2}{\\pi}}\\frac{e^{-\\frac{t^2}{2\\sigma^2}}}{t}.\n\\tag{4.1}\\]\n특별히 \\(X\\sim \\mathcal{N}(0,1)\\)일 때 \\(t&gt;0\\)에 대해 \\[\nP(|X | &gt;t) \\leq \\frac{2\\phi (t)}{t}\n\\]\n\\(\\phi(x)\\)를 이용해 특별히 \\(X\\sim \\mathcal{N}(0,\\sigma^2)\\)일 때 \\(t&gt;0\\)에 대해 \\[\nP(|X | &gt;t) \\leq 2\\frac{\\sigma}{t}\\phi \\Big(\\frac{t}{\\sigma} \\Big) = \\sqrt{\\frac{2}{\\pi}}\\frac{\\sigma}{t}\\exp \\Big( - \\frac{t^2}{2\\sigma^2}\\Big).\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n우선 unit variance일 경우, \\(X\\)가 symmetric around origin임을 이용하여 \\[\nP(|X|&gt;t) = 2P(X&gt;t).\n\\] 마르코프 부등식의 증명과 비슷하게 \\[\n\\begin{align*}\nt\\cdot P(|X|&gt;t) &= t \\int_t^{\\infty} \\phi (x) dx\\\\\n&\\leq \\int_t^{\\infty} x \\phi(x)dx\\\\\n&= \\int_t^{\\infty} \\frac{1}{\\sqrt{2\\pi}}x \\exp \\Big( -\\frac{x^2}{2}\\Big) dx\\\\\n&= \\frac{1}{\\sqrt{2\\pi}}\\int_{t}^{\\infty}-\\frac{\\partial}{\\partial x}\\exp \\Big( -\\frac{x^2}{2}\\Big)dx\\\\\n&= \\frac{1}{\\sqrt{2\\pi}}\\exp \\Big( - \\frac{t^2}{2} \\Big).\n\\end{align*}\n\\]\n일반적인 케이스의 경우 \\(X/\\sigma \\sim \\mathcal{N}(0,1)\\)이고 \\[\nP(|X|&gt;t) = P \\Big( \\Big\\vert\\frac{X}{\\sigma}\\Big\\vert &gt; \\frac{t}{\\sigma} \\Big)\n\\] 로부터 유도됨\n\n\n\n\n\n\nProposition 4.2 (Gaussian의 concentration inequality)  \n\nMills inequality의 application\n\n\\(X_i \\sim\\mathcal{N}(0,\\sigma^2)\\) (이때 확률변수들은 독립이 아니어도 됨)일 때, \\(t&gt;0\\)에 대해 \\[\nP(\\max_{1\\leq i \\leq n} |X_i | &gt;t) \\leq 2n \\frac{\\sigma}{t}\\phi \\Big( \\frac{t}{\\sigma} \\Big).\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nMills 부등식에 union bound를 쓰면 된다고 함\n\n\n\n\nProposition 4.3 (Max of Gaussian random variables의 upper bound)  \n\nMills inequality의 application, lower bound도 같은 rate로 유도 가능\n\n\\(X_i \\sim\\mathcal{N}(0,\\sigma^2)\\) (이때 확률변수들은 독립이 아니어도 됨)일 때, \\[\nE[\\max_{1\\leq i \\leq n}X_i] \\leq \\sigma \\sqrt{2\\log n}\n\\] 이고 \\[\nE[\\max_{1\\leq i \\leq n} |X_i|] \\leq \\sigma \\sqrt{2\\log 2n}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n\\(s&gt;0\\)에 대해 \\[\n\\begin{align*}\nE[\\max_{1\\leq i \\leq n}X_i] &= \\frac{1}{s}E[\\log (\\exp (s \\max_{1\\leq i \\leq n} X_i))]\\\\\n&\\stackrel{(a)}{\\leq} \\frac{1}{s} \\log (E[\\exp (s\\max_{1\\leq i \\leq n}X_i)])\\\\\n&\\stackrel{(b)}{=} \\frac{1}{s}\\log(E[\\max_{1\\leq i \\leq n}\\exp (sX_i)])\\\\\n&\\stackrel{(c)}{\\leq} \\frac{1}{s}\\log (\\sum_{i=1}^n E[\\exp (s X_i)])\\\\\n&\\stackrel{(d)}{=}  \\log \\Big(\\sum_{i=1}^n \\exp \\Big( \\frac{s^2\\sigma^2}{2} \\Big) \\Big)\\\\\n&= \\frac{\\log n}{s} + \\frac{s^2 \\sigma^2}{2}.\n\\end{align*}\n\\] 여기서\n\n(a): Jensen 부등식\n(b): \\(\\exp (\\cdot)\\) 함수의 monotonicity\n(c): \\(\\max\\)의 정의로부터\n(d): Gaussian r.v.의 MGF로부터\n\n\n\\(s=\\sqrt{2\\log n}/\\sigma\\)로 놓아 upper bound를 minimize한다고 함",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#sub-gaussian",
    "href": "ineq.html#sub-gaussian",
    "title": "4  Inequalities",
    "section": "4.7 Sub-Gaussian",
    "text": "4.7 Sub-Gaussian\n\n출처: Concentration Inequalities\n앞서 Chernoff appraoch로 얻어지는 tail bound의 form은 MGF의 growth rate에 depend됨을 암\n따라서 tail bound study에서는 확률변수들을 MGF에 따라 분류하는 것이 자연스러운 생각\n또한 Proposition 4.3 의 증명을 보면, (d)를 제외한 나머지 부분에서는 Gaussian의 성질이 쓰이지 않고 있음. 즉 \\(E[\\exp (s X_i)]\\leq \\exp ( \\frac{1}{2}s^2 \\sigma^2)\\)을 만족하는 확률변수 \\(X_i\\)들에 대해서는 Proposition 4.3 의 결과가 성립할 것임\n\n\nDefinition 4.1 (Sub-Gaussian) 어떤 확률변수 \\(X\\in \\mathbb{R}\\)이 \\(E(X)=0\\)이고 이것의 MGF가 \\[\nE[\\exp (sX)] \\leq \\exp \\Big( \\frac{\\sigma^2 s^2}{2} \\Big), \\forall s \\in \\mathbb{R}\n\\] 일 때 \\(X \\sim \\text{subG}(\\sigma^2)\\)이라고 한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\nSub-Gaussian random variable은 클래스가 큼\n\n\n\n\nExample 4.1 (Sub-Gaussian ditributions의 예시)  \n\n\\(X\\)가 equal prob로 \\(\\pm 1\\)을 갖는 Rademacher random variable이라 하면 \\[\nE[\\exp (sX)] = \\frac{1}{2}e^{-s} + \\frac{1}{2}e^s = \\cosh s \\leq \\exp (\\frac{1}{2}s^2)\n\\] \\(X \\sim \\text{subG}(1)\\)\n\\(X \\sim \\text{Unif}[-a,a]\\)라 하면 \\(s\\neq 0\\)에 대해 (출처) \\[\n\\begin{align*}\nE[\\exp (sX)] &= \\frac{1}{2as}[e^{as} - e^{-as}]\\\\\n&= \\sum_{n=0}^{\\infty} \\frac{(as)^{2n}}{(2n+1)!} \\leq \\sum_{n=0}^{\\infty} \\frac{(as)^{2n}}{n!2^n}\n\\end{align*}\n\\] \\(X\\sim \\text{subG}(a)\\)라고 함\n\\(X\\)가 \\(E[X]=0\\), \\(|X|&lt;1\\) a.s인 확률변수라 하면 \\[\nE[\\exp (sX)] \\leq \\cosh s, \\quad{} \\forall s \\in \\mathbb{R}\n\\] 이므로 \\(X\\sim \\text{subG}(1)\\)\n위의 따름정리로부터 \\(X\\)가 \\(E[X]=0\\), \\(|X|&lt;b\\) a.s인 확률변수라 하면 \\(X\\sim \\text{subG}(b)\\)\n\\(X\\)가 구간 \\([a,b]\\)에서 zero mean을 갖는 확률변수이면, \\(X\\sim \\text{subG}(\\frac{b-a}{2})\\)\n\\(X\\sim \\text{subG}(\\sigma^2)\\)이면 \\(\\alpha \\in \\mathbb{R}\\)에 대해 \\(\\alpha X \\sim \\text{subG}(|\\alpha|\\sigma)\\)\n\\(X_1, X_2\\)가 각각 \\(X_1\\sim \\text{subG}(\\sigma_1)\\), \\(X_2\\sim \\text{subG}(\\sigma_2)\\)이면 \\(X_1 + X_2\\sim \\text{subG}(\\sqrt{\\sigma_1^2+\\sigma_2^2})\\)\n\n\n\n4.7.1 Lipschitz functions of Gaussian variables\n\nDefinition 4.2 (Lipschitz function) 어떤 함수 \\(f:\\mathbb{R}^d \\rightarrow \\mathbb{R}\\)이 \\[\n|f(x)-f(y)|\\leq L \\| x-y\\|_2 ,\\quad{} \\forall x,y\\in\\mathbb{R}^d\n\\] 를 만족하면 L-Lipshitz with respect to the Euclidean norm이라 한다.\n\n다음 정리는 any Lipschitz function of a Gaussian random variable은 \\(L\\)-sub-Gaussian임을 보여준다.\n\nTheorem 4.6 \\(X=(X_1, \\ldots, X_n)\\)이 i.i.d. standard Gaussian random variables의 벡터이고 \\(f:\\mathbb{R}^n \\rightarrow \\mathbb{R}\\)가 \\(L\\)-Lipshitz with respect to the Euclidean norm이라고 하자. 그러면 변수 \\(f(X) - E[f(X)]\\)는 \\(L\\)-sub-Gaussian이며 그러므로 \\[\nP[|f(X)-E[f(X)]|\\geq t] \\leq 2\\exp \\Big( -\\frac{t^2}{2L^2}\\Big).\n\\]\n\n이 정리는 굉장히 의미가 있는 것이, standard Gaussian random vector의 \\(L\\)-Lipschitz function은 variance \\(L^2\\)을 가진 scalar Gaussian random variable과 비슷한 concentration을 보여준다는 것이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#sub-exponential",
    "href": "ineq.html#sub-exponential",
    "title": "4  Inequalities",
    "section": "4.8 Sub-Exponential",
    "text": "4.8 Sub-Exponential\n\n\\(X\\sim \\text{Lap}(1)\\)과 같이 \\[\nP(|X|&gt;t)=e^{-t},\\quad{} t\\geq 0\n\\] Gaussian보다 꼬리가 두꺼운 경우는 어떻할 것인가?\nLaplace의 MGF: \\[\nE[e^{sX}] = \\frac{1}{1-s^2},\\quad{} \\text{if } |s|&lt;1.\n\\]\n\n\nDefinition 4.3 (Sub-Exponential) 어떤 확률변수 \\(X\\in \\mathbb{R}\\)이 \\(E(X)=0\\)이고 이것의 MGF가 \\[\nE[e^{sX}] \\leq e^{s^2 \\lambda^2 / 2}, \\quad{} \\forall |s| \\leq \\frac{1}{\\lambda}\n\\] 일 때 \\(X \\sim \\text{subE}(\\lambda)\\)라고 한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#bernsteins-inequality",
    "href": "ineq.html#bernsteins-inequality",
    "title": "4  Inequalities",
    "section": "4.9 Bernstein’s inequality",
    "text": "4.9 Bernstein’s inequality\n\nTheorem 4.7 (Berstein’s inequality) 어떤 확률변수 \\(X_1, \\ldots, X_n\\)이 독립이고 \\(E(X_i) = 0\\)이며 \\(X_i \\sim \\text{subE}(\\lambda)\\)인 확률변수라고 하자. 그러면 \\(t&gt;0\\)에 대해 \\[\nP(\\overline{X} &gt;t) \\vee P(\\overline{X} &lt; -t) \\leq \\exp \\Big[ - \\frac{n}{2}\\Big(\\frac{t^2}{\\lambda^2}\\wedge \\frac{t}{\\lambda} \\Big) \\Big] .\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inequalities</span>"
    ]
  },
  {
    "objectID": "char.html",
    "href": "char.html",
    "title": "5  Characteristic Functions",
    "section": "",
    "text": "5.1 Fourier transform",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Characteristic Functions</span>"
    ]
  },
  {
    "objectID": "char.html#fourier-transform",
    "href": "char.html#fourier-transform",
    "title": "5  Characteristic Functions",
    "section": "",
    "text": "Fourier transform: exists for any real function \\(f(x)\\) for which the integral \\[\n\\int_{-\\infty}^{\\infty} f(x) e^{i\\omega x} dx\n\\] exists (the same as \\(E[e^{i\\omega x}])\\).\nFourier transform은 기저 \\(\\Omega = \\{ e^{i\\omega x} \\vert \\omega \\in [0,\\infty) \\}\\)와 이것의 계수를 이용해 표현한 것으로 볼 수 있음\nIf we were to write it this way, we would need some function \\(\\tilde{f}(\\cdot)\\) so that \\(F(\\omega)\\) would return the coefficient of \\(e^{i\\omega t}\\) for any \\(\\omega \\in [0,\\infty)\\). In other words, we would have \\[\nf(x) = \\sum_{\\omega [0,\\infty)}\\tilde{f}(\\omega)e^{i\\omega x},\n\\] which is for all practical purposes the same as \\[\nf(x) = \\int_0^{\\infty}\\tilde{f}(\\omega) e^{i\\omega x} d\\omega.\n\\]\nWhat we now have is technically known as a Fredholm integral equation of \\(\\tilde{f}(\\omega)\\), and one which has the solution \\[\n\\tilde{f}(\\omega) = \\int_{-\\infty}^{\\infty}f(x) e^{-i\\omega x}dx,\n\\] which is the same as the Fourier transform. 이 적분을 하는 상황, 즉 푸리에 변환을 취하는 상황을 \\(\\tilde{f} = \\mathcal{F}[f]\\)로 쓸 수 있다.\n\n\n5.1.1 Fourier transform과 convolution\n\n푸리에 변환에는 몇 가지 성질이 있다. \\(c_1, c_2 \\in \\mathbb{C}\\), 적분가능 함수 \\(f,g\\)에 대해\n\n(푸리에 변환은 선형) \\(\\mathcal{F}[c_1 f + c_2 g] = c_1 \\mathcal{F}[f] + c_2 \\mathcal{F}[g]\\)\n(translation) \\(\\mathcal{F}[f(x-a)] = e^{-i\\omega a}\\tilde{f}(\\omega)\\)\n(re-phasing) \\(\\mathcal{F}[e^{i \\ell x} f(x)] = \\tilde{f}(\\omega - \\ell)\\)\n(scaling) \\(\\mathcal{F}[f(cx)] = \\frac{1}{|c|}\\tilde{f}(k/c)\\)\n\n다음과 같이 convolution \\(f*g\\)를 \\[\nf*g(x) = \\int_{-\\infty}^{\\infty}f(x-y)g(y)dy,\n\\] then, provided \\(f\\) and \\(g\\) are sufficiently well-behaved for us to change the order of integration, the Fourier transform is \\[\n\\begin{align*}\n\\mathcal{F}[f*g(x)] &= \\int_{-\\infty}^{\\infty}e^{-i\\omega x}\\Big[\\int_{-\\infty}^{\\infty} f(x-y) g(y) dy \\Big] dx = \\int_{\\mathbb{R}^2} e^{-i \\omega (x-y)}\\\\\n&= \\int_{\\mathbb{R}^2}e^{-i\\omega (x-y)}f(x-y)e^{-i\\omega y}g(y)dx dy\\\\\n&= \\int_{-\\infty}^{\\infty}e^{-i\\omega u}f(u)du \\int_{-\\infty}^{\\infty}e^{-i\\omega y}g(y)dy = \\mathcal{F}[f]\\mathcal{F}[g].\n\\end{align*}\n\\] 즉 두 함수의 convolution의 푸리에 변환은 각각의 함수의 푸리에 변환의 곱으로 표현할 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Characteristic Functions</span>"
    ]
  },
  {
    "objectID": "char.html#characteristic-function-basics",
    "href": "char.html#characteristic-function-basics",
    "title": "5  Characteristic Functions",
    "section": "5.2 Characteristic function: basics",
    "text": "5.2 Characteristic function: basics\n\nDefinition 5.1 (Characteristic function) 확률변수 \\(X\\)의 characteristic function은 \\[\n\\varphi_X (t) = E[e^{i tX}] = \\int_{-\\infty}^{\\infty} e^{itx} d F_X(x).\n\\]\n\n\n\n\n\n\n\nRemark\n\n\n\n앞선 푸리에 변환의 정의와 부호 등이 다르지만, Characteristic function and Fourier transform 를 보면 characteristic function도 pdf의 Fourier transform으로 이해할 수 있다.\n\n\n\nQ. 왜 characteristic function을 생각하는가?\nCharacteristic function과 비슷한 역할을 하는 것으로 MGF가 있다. \\[\n\\begin{align*}\nM_X &: \\mathbb{R} \\rightarrow \\mathbb{R}\\\\\nM_X(t) &= E[e^{tX}].\n\\end{align*}\n\\] MGF를 이용하면 \\(E[X^n]\\)은 \\(M_X^{(n)}(0)\\)으로 계산하면 된다. 또한 두 개의 독립인 확률변수 \\(X\\), \\(Y\\)에 대해 \\[\n\\begin{align*}\nM_{X+Y}(t) &= E[e^{t(X+Y)}]\\\\\n&= E[e^{tX}e^{tY}]\\\\\n&= E[e^{tX}]E[e^{tY}]\\\\\n&= M_X(t) M_Y(t).\n\\end{align*}\n\\] 그러나 MGF는 항상 존재하지 않는다고 한다.\n한편, characteristic function은 \\[\n\\begin{align*}\n\\varphi_X &: \\mathbb{R} \\rightarrow \\mathbb{C}\\\\\n\\varphi_X (t) &= E[e^{itX}].\n\\end{align*}\n\\] 그리고\n\nthe \\(n\\)-th moment of \\(X\\) 가 존재한다면 \\((-i)^{(n)}\\varphi_X^{(n)}(0)\\)\n두 개의 확률변수가 같은 chracteristic function을 갖는다면 same distribution을 갖음\n\\(\\varphi_{X+Y}(t) = \\varphi_X (t) \\varphi_Y (t)\\) for independent random varialbe \\(X,Y\\)\n\n이며, 무엇보다도 MGF와는 달리, 적어도 실수값을 갖는 확률변수에서는 characteristic function이 항상 존재한다고 한다.\n\nTheorem 5.1 \\(X\\)가 확률변수라고 하자. 그러면\n\n\\(\\vert \\varphi_X(t) \\vert \\leq \\varphi_X(0)=1\\)\n\\(\\varphi_X(t) =\\varphi_X(-t)=\\varphi_{-X}(t)\\)\n\\(\\varphi_X(t)\\) is uniformly continuous\n\n\n\n5.2.1 Uniqueness and inversion\n\nTheorem 5.2 (Uniqueness of the chracteristic function) Let \\(X\\) and \\(Y\\) be random variables. If \\(\\varphi_X = \\varphi_Y\\), then \\(X\\stackrel{d}{=}Y\\) and conversely.\n\n\nTheorem 5.3 (Inversion formula) Let \\(X\\) be a random variable with distribution function \\(F\\) and characteristic function \\(\\varphi\\).\n\nFor \\(a&lt;b\\), \\[\nF(b) - F(a) + \\frac{1}{2}P(X=a)-\\frac{1}{2}P(X=b) = \\lim_{T\\rightarrow\\infty}\\frac{1}{2\\pi} \\int_{-T}^T \\frac{e^{-itb} - e^{-ita}}{-it}\\cdot \\varphi(t) dt.\n\\]\nIn particular, if \\(a,b\\in C(F)\\), then \\[\nF(b) - F(a) = \\lim_{T\\rightarrow\\infty}\\frac{1}{2\\pi} \\int_{-T}^T \\frac{e^{-itb} - e^{-ita}}{-it}\\cdot \\varphi(t) dt.\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Characteristic Functions</span>"
    ]
  },
  {
    "objectID": "conv.html",
    "href": "conv.html",
    "title": "6  Convergence",
    "section": "",
    "text": "6.1 Definitions\n다음의 정의들은 확률론에서 많이 등장하는 정의들이다. \\(X_1,X_2,\\ldots\\)를 확률변수열이라 하자.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#complete-convergence",
    "href": "conv.html#complete-convergence",
    "title": "6  Convergence",
    "section": "6.2 Complete Convergence",
    "text": "6.2 Complete Convergence\nGut (2014) 에 나오는 내용으로 Borel-Cantelli lemma와 밀접한 관련이 있다고 한다.\n\nDefinition 6.1 (Complete convergence) \\(X_n\\) converges completely to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\) iff \\[\n\\sum_{n=1}^{\\infty} P(\\vert X_n - X \\vert &gt; \\varepsilon) &lt; \\infty, \\quad{} \\forall \\varepsilon&gt;0.\n\\]\n\n여기서는 \\(n\\rightarrow \\infty\\)일 때 \\(X_n \\stackrel{\\text{c.c.}}{\\rightarrow}X\\)로 표기하기로 한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#almost-sure-convergence",
    "href": "conv.html#almost-sure-convergence",
    "title": "6  Convergence",
    "section": "6.3 Almost Sure Convergence",
    "text": "6.3 Almost Sure Convergence\n\n\nDefinition 6.2 (Sure convergence (틀림없는 수렴)) 확률변수열 \\(X_n\\)이 표본공간 안에 어떤 점 \\(\\omega\\)를 잡아도 \\[\n\\lim_{n\\rightarrow\\infty} X_n (\\omega) = X(\\omega)\n\\] 을 만족하면 \\(X_n\\) converges surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{s}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 6.3 (Almost sure convergence (거의 틀림없는 수렴)) 확률변수열 \\(X_n\\)은 \\[\nP\\{ \\omega: X_n (\\omega)\\rightarrow X(\\omega) \\text{ as } n\\rightarrow \\infty\\})=1\n\\] 을 만족하면 \\(X_n\\) converges almost surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n거의 틀림없이 수렴하는 확률변수 \\(\\{ X_n (\\omega)\\}\\)에서는 \\(P(\\tilde{\\Omega})=1\\)이고 \\(\\tilde{\\Omega} \\subseteq \\Omega\\)일 때 \\(\\omega \\in \\tilde{\\Omega}\\)를 어떻게 고르더라도 \\(\\lim_{n\\rightarrow \\infty} X_n (\\omega) = X(\\omega)\\)임\n다만, \\(\\omega \\notin \\tilde{\\Omega}\\)인 수열 \\(\\{ X_n (\\omega)\\}\\)는 수렴하지 않을 수는 있지만, \\(P\\{ \\omega: \\omega \\notin \\tilde{\\Omega}, \\omega \\in \\Omega\\} = 0\\)임\n\\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}0\\)은 \\(0\\)보다 큰 수 \\(\\varepsilon\\)을 어떻게 잡더라도 \\(P\\{ |X_n| \\geq \\varepsilon\\} =0\\)이라는 것과 필요충분조건임\n\n\n\n\nExample 6.1 (거의 틀림없는 수렴 예제)  \n\n구간 \\([0,1]\\)에서 아무렇게나 한 점을 골라서 \\(\\omega\\)라 하고, \\(\\omega\\)가 \\([0,1]\\)의 어느 부분 구간에 들어갈 확률은 그 부분 구간의 길이와 같다고 가정\n\n\n\n\n\n\n\n\n\n\n\n\\(A_n(\\omega)\\)\n\\(B_n(\\omega)\\)\n\\(C_n(\\omega)\\)\n\\(D_n(\\omega)\\)\n\\(H_n(\\omega)\\)\n\n\n\n\n\\(\\frac{\\omega}{n}\\)\n\\(\\omega (1-\\frac{1}{n})\\)\n\\(\\omega e^n\\)\n\\(\\cos 2\\pi n \\omega\\)\n\\(\\exp \\{ -n (n\\omega -1) \\}\\)\n\n\n\n\n\\(A_n(\\omega)\\)는 \\(\\omega\\)가 어떤 값이더라도 늘 0에 수렴하므로 틀림없이 0에 수렴\n\\(B_n(\\omega)\\)는 \\(\\omega\\)가 어떤 값이더라도 \\(\\omega\\)에 수렴하므로 틀림없이 \\(\\omega\\)에 수렴하며, 그 극한 분포는 \\(U[0,1]\\)\n\\(C_n (\\omega)\\)는 \\(\\omega =0\\)이면 0에 수렴하고, \\(\\omega \\in (0,1]\\)이면 발산, 즉 \\(C_n (\\omega)\\)는 수렴하지 않음\n\\(D_n (\\omega)\\)는 \\(\\omega \\in \\{0,1\\}\\)이면 1에 수렴하고, \\(\\omega \\in (0,1)\\)이면 -1과 1 사이에서 진동, 즉 \\(D_n (\\omega)\\)는 수렴하지 않음\n\\(\\omega=0\\)이면 \\(H_n (0) = e^n \\rightarrow \\infty\\)이고 \\(\\omega \\in (0,1]\\)이면 \\(H_n  (\\omega) \\rightarrow 0\\)이므로 \\(H_n (\\omega)\\)는 틀림없이 수렴하지는 않지만, \\(P\\{\\omega &gt;0\\}=1\\)이므로 \\(H_n (\\omega)\\)는 거의 틀림 없이 0으로 수렴\n\n\n\nExample 6.2 (보렐-칸텔리 정리와 거의 어디서나 수렴)  \n\n(\\(\\Longrightarrow\\)) 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)는 \\(\\varepsilon&gt;0\\)일 때 \\[\n\\sum_{n=1}^\\infty P\\{ |X_n | &gt; \\varepsilon\\} &lt; \\infty\n\\] 이면 보렐-칸텔리 정리 Theorem 3.1 를 써서 \\(n\\rightarrow \\infty\\)일 때 \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow} 0\\)이라는 것을 알 수 있음\n(\\(\\Longleftarrow\\)) \\(\\omega\\)의 분포가 \\([0,1]\\)에서 고르고 \\[\nX_n (\\omega)=\n\\begin{cases}\n0, & 0 \\leq \\omega \\leq 1-\\frac{1}{n},\\\\\n1, & 1- \\frac{1}{n}&lt; \\omega \\leq 1\n\\end{cases}\n\\] 인 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)는 \\(n\\rightarrow \\infty\\)일 때, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}0\\)이다. 그러나 \\(\\varepsilon_n \\downarrow 0\\)인 \\(\\varepsilon_n\\)을 어떻게 잡더라도 \\(n\\)이 충분히 크면 \\(P\\{ |X_n| &gt; \\varepsilon_n \\} = P\\{ X_n = 1\\}= \\frac{1}{n}\\)이므로 \\(\\sum_{n=1}^{\\infty}P\\{ |X_n| &gt; \\varepsilon_n\\}\\rightarrow \\infty\\)이다. 그러므로 앞서 조건은 거의 틀림없이 수렴하는 충분조건이나 필요조건은 아니다.\n\n\n\nTheorem 6.1 (Almost sure convergence와 동치조건) 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)가 \\(X_n \\stackrel{\\text{a.s}}{\\rightarrow}X\\)이면 0보다 큰 수 \\(\\varepsilon\\)을 어떻게 고르더라도 \\[\n\\lim_{n\\rightarrow\\infty} P \\{ \\sup_{m\\geq n} |X_m - X| &gt; \\varepsilon \\} = 0\n\\] 이고, 그 역도 성립한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n확률변수 열이 거의 틀림없이 수렴하는지를 보이려면, \\(\\omega\\)의 분포와 \\(\\omega\\)와 확률변수 사이의 관계를 알든지, 아니면 수렴을 손쉽게 보일 수 있을 만큼 확률변수가 간단해야 함",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-mean",
    "href": "conv.html#convergence-in-mean",
    "title": "6  Convergence",
    "section": "6.4 Convergence in Mean",
    "text": "6.4 Convergence in Mean\nQ. 거의 틀림없는 수렴보다 조금 더 느슨한 수렴은 없을까?\n\nDefinition 6.4 (Converge in \\(r\\)-mean) 확률변수열 \\(X_n\\)가 \\[\nE|X_n - X|^r \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in \\(r-\\)mean to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\) 또는 \\(X_n \\stackrel{L^\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n특별히 \\(r=2\\)일 때를 제곱 평균 수렴이라 부르며, 해석이 쉽고 공학적인 응용에서도 많이 쓰임\n제곱 평균 수렴은 어떤 시점 \\(n\\)에서 \\(E\\{ (X_n-X)^2\\}\\)이 작다는 관점에서 대부분의 수열 \\(X_n\\)이 \\(X\\)에 가깝기만 바라는 것임\n이런 수렴은 시간에 중점을 두는 것인데, 거의 틀림없는 수렴과는 달리 수열 모두의 수렴을 생각하는 것이 아니고, 수렴하는지 아닌지 보이기도 더 쉬움\n\n\n\n\n코쉬 기준: 극한 확률변수 \\(X\\)를 모를 때에서 확률변수 열이 제곱 평균 수렴하는지 알아볼 수 있음\n\n\nTheorem 6.2 (Cauchy condition) 확률변수 열 \\(\\{X_n\\}\\)이 제곱 평균 수렴할 필요충분조건은 \\[\n\\lim_{n,m\\rightarrow\\infty} E \\{ (X_n - X_m)^2 \\} = 0\n\\] 이다.\n\n\nExample 6.3  \n\nExample 6.2 의 \\(B_n(\\omega) = (1-\\frac{1}{n})\\omega\\)는 Theorem 6.2 를 이용해보면 \\[\n\\begin{align*}\n\\lim_{n,m\\rightarrow\\infty}E\\{(B_n - B_m)^2 \\}&= \\lim_{n,m\\rightarrow\\infty}E\\{(\\frac{1}{n}-\\frac{1}{m} )^2 \\omega^2 \\}\\\\ &= E\\{\\omega^2\\}\\lim_{n,m\\rightarrow\\infty} (\\frac{1}{n}-\\frac{1}{m})^2 =0\n\\end{align*}\n\\] 이므로 코쉬 기준을 만족함을 알 수 있고, 따라서 제곱 평균 수렴할 것임을 알 수 있음\n또한 다음을 알고 있으므로 \\[\n\\begin{align*}\n\\lim_{n\\rightarrow\\infty} E[\\{ B_n(\\omega) - \\omega\\}^2] &= \\lim_{n\\rightarrow\\infty}E\\{ (\\frac{\\omega}{n})^2 \\} \\\\\n&= \\lim_{n\\rightarrow\\infty}\\frac{1}{3n^2}=0\n\\end{align*}\n\\] \\(B_n(\\omega)\\)는 \\(\\omega\\)에 제곱 평균 수렴\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n제곱 평균 수렴은 \\(n\\)이 커질 때 점점 더 많은 수열들이 \\(X\\)에 가까이 간다는 것을 의미하나, 거의 틀림없는 수렴과 달리 한 번 \\(X\\)에 가까이 간 수열이 그 뒤로도 늘 \\(X\\) 가까이에 머물러 있는 것은 아님\n\n\n\n\n\nExample 6.2 의 \\(H_n(\\omega)=\\exp \\{-n (n\\omega - 1) \\}\\)은 거의 틀림없이 0으로 수렴하나 \\[\n\\begin{align*}\n\\lim_{n\\rightarrow\\infty}E[\\{ H_n (\\omega) - 0 \\}^2] &= \\lim_{n\\rightarrow\\infty} e^{2n} \\int_{0}^1 \\exp (-2n^2 \\omega) d\\omega\\\\ &= \\lim_{n\\rightarrow\\infty}\\frac{e^{2n}}{2n^2}\\{ 1-\\exp(-2n^2)\\}\\rightarrow\\infty\n\\end{align*}\n\\] 이므로 \\(\\{H_n(\\omega)\\}\\)은 0으로 제곱 평균 수렴하지는 않음",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-probability",
    "href": "conv.html#convergence-in-probability",
    "title": "6  Convergence",
    "section": "6.5 Convergence in Probability",
    "text": "6.5 Convergence in Probability\n\n\nDefinition 6.5 (Converge in Probability) 확률변수열 \\(X_n\\)이 임의의 \\(\\varepsilon&gt;0\\)에 대해 \\[\nP\\{ |X_n-X| &gt;\\varepsilon) \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in probability to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{p}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\nDefinition 6.5 에 적혀 있는 식은 어떤 순간에는 거의 모든 수열이 \\(2\\varepsilon\\)이라는 범위 안에 들어가 있지만 그 수열들이 그 안에 꼭 머물러 있는 것은 아니라는 것을 뜻함\n따라서 한 번 \\(2\\varepsilon\\)이라는 범위 안에 들어가면 그 안에 꼭 머문다는 것을 뜻하는 Theorem 6.1 의 식과 다름\n이 사실은 \\(\\{|X_n - X|&gt; \\varepsilon\\}\\)과 \\(\\{\\sup_{m\\geq n} |X_m-X|&gt;\\varepsilon \\}\\)의 뜻의 차이로부터 옴\n\n\n\n다음 내용은 두 확률변수열 \\(\\{X_n\\}\\), \\(\\{Y_n\\}\\)이 \\(X_n \\stackrel{p}{\\rightarrow} X\\), \\(Y_n \\stackrel{p}{\\rightarrow} Y\\)라고 할 때 \\(X_n + Y_n \\stackrel{p}{\\rightarrow} X+Y\\)일지에 대한 내용이다.\n\n\nTheorem 6.3 (합과 곱의 확률수렴)  \n\n\\(\\{X_n\\}\\), \\(\\{Y_n\\}\\)이 \\(X_n \\stackrel{p}{\\rightarrow} X\\), \\(Y_n \\stackrel{p}{\\rightarrow} Y\\)일 때 \\(X_n + Y_n \\stackrel{p}{\\rightarrow} X+Y\\)이다.\n\\(\\{X_n\\}\\), \\(\\{Y_n\\}\\)이 \\(X_n \\stackrel{p}{\\rightarrow} X\\), \\(Y_n \\stackrel{p}{\\rightarrow} Y\\)일 때 \\(X_n  Y_n \\stackrel{p}{\\rightarrow} XY\\)이다.\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n\\(\\{ |X_n + Y_n - (X+Y) | &gt; \\varepsilon\\} \\subset \\{ |X_n - X| &gt; \\frac{\\varepsilon}{2} \\} \\cup  \\{ |Y_n - Y| &gt; \\frac{\\varepsilon}{2} \\}\\) 라는 사실을 이용하면 된다.\n\\(|X_n Y_n - XY | \\leq |Y| \\cdot |X_n - X| + |X_n | \\cdot |Y_n - Y|\\)가 성립한다. Triangle inequality에 의해 \\[\nP(|X_n Y_n - XY | \\geq \\varepsilon) \\leq P(|Y| \\cdot |X_n - X| \\geq \\frac{\\varepsilon}{2}) + \\leq P(|X_n| \\cdot |Y_n - Y| \\geq \\frac{\\varepsilon}{2})\n\\] 이다. 첫 펀째 파트는 어떤 \\(M&gt;0\\)에 대해 \\[\nP(|Y| \\cdot |X_n - X| \\geq \\frac{\\varepsilon}{2})  \\leq P(|X_n - X| \\geq \\frac{\\varepsilon}{2M}) + P(|Y| \\geq M)\n\\] 이다. \\(n\\rightarrow \\infty\\)로 두면 \\[\n\\text{limsup}_{n\\rightarrow \\infty} P(|Y| \\cdot |X_n - X| \\geq \\frac{\\varepsilon}{2}) \\leq P(|Y| \\geq M).\n\\] 이것은 임의의 \\(M&gt;0\\)에 대해 성립하므로 \\(M\\rightarrow\\infty\\)로 놓고 DCT에 의해 \\(\\lim_{n\\rightarrow\\infty} P(|Y| \\cdot |X_n - X| \\geq \\frac{\\varepsilon}{2})\\)기 존재하고 0이다. 두 번째 파트는 다음으로부터 시작한다. 어떤 \\(M&gt;0\\)에 대해 \\[\nP(|X_n| \\cdot |Y_n - Y| \\geq \\frac{\\varepsilon}{2})  \\leq P(|Y_n - Y| \\geq \\frac{\\varepsilon}{2M}) + P(|X_n| \\geq M).\n\\] Triangle inequality에 의해 \\[\nP(|X_n| \\geq M) \\leq P(|X_n - X| \\geq \\frac{M}{2}) + P(|X| \\geq \\frac{M}{2})\n\\] 이다. 이제 두 번쨰 식에서 첫 번째 씩을 빼면 \\[\nP(|X_n | \\cdot |Y_n - Y| \\geq \\frac{\\varepsilon}{2}) \\leq P(|Y_n - Y|\\geq \\frac{\\varepsilon}{2M}) + P(|X_n - X| \\geq \\frac{M}{2}) + P(|X| \\geq \\frac{M}{2}).\n\\] 우변의 처음 두 개의 항은 \\(X_n \\stackrel{p}{\\rightarrow} X\\), \\(Y_n \\stackrel{p}{\\rightarrow} Y\\)이므로 \\(n\\rightarrow\\infty\\)일 때 0으로 수렴한다. \\(n\\rightarrow\\infty\\)로 놓은 후에는 \\(M\\rightarrow\\infty\\)로 놓아 \\[\n\\lim_{n\\rightarrow \\infty} P(|X_n | \\cdot |Y_n - Y| \\geq \\frac{\\varepsilon}{2})=0\n\\] 이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-distribution",
    "href": "conv.html#convergence-in-distribution",
    "title": "6  Convergence",
    "section": "6.6 Convergence in Distribution",
    "text": "6.6 Convergence in Distribution\n\n\nDefinition 6.6 (Converge in Distribution) \\(C(F_X)=\\{x : F_X(x) \\text{ is continuous at }x\\}=\\text{the continuity set of }F_X\\)라 하자. 확률변수열 \\(X_n\\)가 \\[\nF_{X_n}(x) \\rightarrow F_X(x) \\text{as} \\quad{} n\\rightarrow \\infty, \\quad{} \\forall x \\in C(F_X).\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{d}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n다음과 같이 정의할 수도 있다고 한다. 확률변수열 \\(X_n\\)가 모든 \\(h\\in C_{B}\\)에 대해 \\[\nE h(X_n) \\rightarrow E h(X) \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 한다.\n이 두개의 정의가 동치라는 증명이 Gut (2014) 의 Theorem 5.6.1에 있다.\n\n때때로 \\(X_n \\stackrel{\\text{d}}{\\rightarrow} \\mathcal{N}(0,1)\\)처럼 쓰기도 한다.\n\nExample 6.4  \n\n확률변수 \\(X_n\\)의 누적분포함수를 \\(F_n (x) = \\int_{-\\infty}^x \\frac{\\sqrt{n}}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{nt^2}{2\\sigma^2}}dt\\)처럼 두면 \\[\n\\lim_{n\\rightarrow\\infty} F_n (x)\n=\n\\begin{cases}\n0, & x&lt;0,\\\\\n\\frac{1}{2}, & x=0,\\\\\n1, & x &gt;0.\n\\end{cases}\n\\] 따라서, \\(\\{X_n\\}\\)은 누적분포함수가 \\[\nF(x) =\n\\begin{cases}\n0, & x&lt; 0,\\\\\n1, & x \\geq 0\n\\end{cases}\n\\] 인 확률변수 \\(X\\)로 분포에서 수렴한다.\n\\(\\lim_{n\\rightarrow\\infty}F_n (0) \\neq F(0)\\)이지만, 분포수렴은 누적분포함수의 불연속 점에서 수렴을 따지지 않기 때문에 \\(F(x)\\)의 불연속점인 \\(x=0\\)에서 \\(F_n(x)\\)가 수렴하는지 따지지 않아도 된다.\n\n\n\n6.6.1 Weak convergence\nDistributional convergence is often called weak convergence in these more general settings. (Gut 2014)\n\nDefinition 6.7 (Converge Weakly) 이는 Durrett (2019) 의 3.2에 나온다. A sequence of distribution functions is said to converge weakly to a limit \\(F\\) (written \\(F_n \\Rightarrow F\\)) if \\(F_n(y) \\rightarrow F(y)\\) for all \\(y\\) that are continuity points of \\(F\\). A sequence of random variables \\(X_n\\) is said to converge weakly or converge in distribution to a limit \\(X_{\\infty}\\) (written \\(X_n \\Rightarrow X_{\\infty})\\) if their distribution functions \\(F_n (x) = P(X_n \\leq x)\\) converges weakly.\n\n\n\n\n\n\n\nRemark\n\n\n\nPolansky (2011) 의 4장에서는 converges weakly를 converge in distribution을 정의할 때 쓴 random variable의 sequence를 생략한 채 \\(\\{F_n\\}_{n=1}^{\\infty}\\)와 \\(F\\)로만 정의한 것으로 보았다. 또한 converges weakly를 \\(F_n \\rightsquigarrow F\\)로 표기하기도 하였다.\n\n\n\n\n6.6.2 Vague convergence\n다음은 Gut (2014) 의 5.8.1에 나오는 vague convergence이다. Vague convergence의 limiting random variable이 proper하지 않아도 된다는 점이 distributional convergence와의 차이점이다.\n\n\n\n\n\n\nRemark\n\n\n\nProper하지 않은 random variable이라는 것은 probability mass가 escape to infinity할 수도 있음을 의미\n\n\n\nDefinition 6.8 (Converge Vaguely) A sequence of distribution functions \\(\\{F_n, n\\geq 1\\}\\) converges vaguely to the pseudo-distribution function \\(H\\) if, for every finite interval \\(I=(a,b] \\subset \\mathbb{R}\\), where \\(a,b\\in C(H)\\), \\[\nF_n(I) \\rightarrow H(I) \\quad{} \\text{as} \\quad{} n \\rightarrow \\infty.\n\\] Notation: \\(F_n \\stackrel{\\text{v}}{\\rightarrow}H\\) as \\(n\\rightarrow \\infty\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#relationship-among-convergences",
    "href": "conv.html#relationship-among-convergences",
    "title": "6  Convergence",
    "section": "6.7 Relationship Among Convergences",
    "text": "6.7 Relationship Among Convergences\n\nTheorem 6.4 (수렴 사이의 관계) \\(X, X_1, X_2,\\ldots\\)를 확률변수라고 하자. 그러면 \\(n\\rightarrow\\infty\\)일 때 수렴 사이에 다음과 같은 관계가 성립한다. \\[\n\\begin{align*}\nX_n \\stackrel{\\text{c.c.}}{\\rightarrow} X \\Longrightarrow X_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\Longrightarrow X_n &\\stackrel{p}{\\rightarrow} X \\Longrightarrow X_n \\stackrel{d}{\\rightarrow} X\\\\\n&\\Uparrow\\\\\nX_n &\\stackrel{r}{\\rightarrow} X.\n\\end{align*}\n\\]\n\n\nExample 6.5 (분포수렴하나 확률수렴하지 않는 확률변수열)  \n\n확률변수 \\(X\\)의 확률밀도함수가 대칭이라고 하고 \\(X_n = - X\\)라고 두자. 그러면 \\[\nX_n \\stackrel{d}{=}X\n\\] 이므로 \\(X_n \\stackrel{d}{\\rightarrow}X\\)이다.\n그러나 \\(n\\rightarrow\\infty\\)일 때 \\(P \\{ |X_n - X| &gt; \\varepsilon \\} = P \\{ |X| &gt; \\frac{\\varepsilon}{2} \\} \\not\\rightarrow 0\\)이므로 \\(X_n \\stackrel{p}{\\not\\rightarrow}X\\)이다.\n\n\n\nExample 6.6 (확률수렴하나 거의 틀림없이 수렴하지는 않는 확률변수열)  \n\n독립인 확률변수열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)에서 \\(P\\{X_n=1\\}=\\frac{1}{n}\\)이고 \\(P\\{X_n =0\\}=1-\\frac{1}{n}\\)이라고 두자. 그러면 \\(\\varepsilon \\in (0,1)\\)을 어떻게 고르더라도 \\(n\\rightarrow\\infty\\)일 떄 \\(P\\{ |X_n - 0| &gt; \\varepsilon\\}= P\\{X_n = 1\\} =\\frac{1}{n}\\rightarrow 0\\)이므로 \\(X_n \\stackrel{p}{\\rightarrow}0\\)이다.\n그러나 \\(A_n (\\varepsilon) = \\{|X_n - 0|&gt;\\varepsilon\\}\\)이라고 두고 \\(B_m (\\varepsilon) = \\cup_{n=m}^{\\infty}A_n (\\varepsilon)\\)이라고 두면 \\[\nP\\{B_m (\\varepsilon)\\} = 1- \\lim_{M\\rightarrow \\infty}P\\{ X_n =0, \\forall n \\text{ s.t. } m\\leq n \\leq M\\}\n\\] 이다. \\(X_n\\)이 독립이므로 자연수 \\(m\\)에 대해 \\(\\prod_{k=m}^{\\infty}(1-\\frac{1}{k})=0\\)이라는 것을 쓰면 \\[\n\\begin{align*}\nP\\{B_m (\\varepsilon)\\} &= 1- \\lim_{M\\rightarrow \\infty} \\Big(1-\\frac{1}{m} \\Big) \\Big(1-\\frac{1}{m+1} \\Big)\\cdots  \\Big(1-\\frac{1}{M} \\Big)\\\\\n&=1.\n\\end{align*}\n\\] 따라서 \\(\\lim_{m\\rightarrow\\infty} P\\{B_m (\\varepsilon) \\} \\neq 0\\)이고 Theorem 6.1 에서 \\(X_n \\stackrel{\\text{a.s.}}{\\not\\rightarrow}0\\)이다.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n이는 즉 \\(m\\leq n\\)인 모든 \\(n\\)에 대해 \\(X_n\\)이 전부 0이 나올 확률이 0이기 때문에 거의 어디서나 수렴하지 않는 것으로 생각할 수 있다. 그러나 분명 \\(P\\{X_n&gt;0\\}=P\\{X_n=1\\} \\stackrel{n\\rightarrow\\infty}{\\longrightarrow}0\\)이므로 이 확률변수열은 0으로 확률수렴한다.\n\n\n\nExample 6.7 (확률수렴하나 평균수렴하지 않는 확률변수열)  \n\n확률변수열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)에서 \\[\nP\\{ X_n = x\\} =\n\\begin{cases}\n\\frac{1}{n}, &  x= e^n\\\\\n1-\\frac{1}{n}, & x=0\n\\end{cases}\n\\] 이면 \\(\\varepsilon&gt;0\\)이고 \\(n\\rightarrow\\infty\\)일 때 \\(P\\{ |X_n| &lt; \\varepsilon\\}= P\\{X_n =0\\} = 1-\\frac{1}{n} \\rightarrow 1\\)이므로 \\(X_n \\stackrel{p}{\\rightarrow}0\\)이다.\n그러나 \\(E\\{X_n^r\\}=\\frac{e^{rn}}{n}\\rightarrow\\infty\\)이므로 \\(X_n \\stackrel{L^r}{\\not\\rightarrow} 0\\)이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#bounded-in-probability",
    "href": "conv.html#bounded-in-probability",
    "title": "6  Convergence",
    "section": "6.8 Bounded in Probability",
    "text": "6.8 Bounded in Probability\n(Polansky 2011) Convergence of distribution과 관련된 중요한 질문 중 하나는 limiting distribution이 valid distribution function이냐는 것이다. 이 말인 즉슨 sequence of distribution functions \\(\\{ F_n \\}_{n=1}^{\\infty}\\)가 \\[\n\\lim_{n\\rightarrow\\infty} F_n (x) = F(x), \\quad{} \\forall x \\in C(F) \\quad{} \\text{for some fct } F(x)\n\\] 일 때 \\(F(x)\\)가 distribution functions여야 할 필요가 있는가? 여기에서 \\(F(x) \\in [0,1]\\), \\(F(x)\\)가 non-decreasing, right continuity 등은 미적분학 등의 내용을 이용해 보일 수 있으므로 \\[\n\\lim_{x\\rightarrow \\infty} F(x) = 1, \\quad{} \\lim_{x\\rightarrow -\\infty} F(x) = 0\n\\] 을 만족하면 \\(F\\)가 valid distribution function이 될 것이다.\n\nDefinition 6.9 (Bounded in Probability (확률유계)) Let \\(\\{X_n\\}_{n=1}^{\\infty}\\) be a sequence of random variables. The sequence is bounded in probability if for every \\(\\varepsilon&gt;0\\), \\(\\exists x_{\\varepsilon} \\in \\mathbb{R}\\) and \\(n_{\\varepsilon} \\in \\mathbb{N}\\) such that \\(P(|X_n| \\leq x_{\\varepsilon})&gt;1-\\varepsilon\\) for all \\(n &gt; n_{\\varepsilon}\\).\n\n\nExample 6.8 (Bounded in Probability가 아닌 확률변수열) Consider the situation that \\(\\{X_n\\}_{n=1}^{\\infty}\\) is a sequence of random variables such that the distribution function of \\(X_n\\) is given by \\[\nF_n(x) =\n\\begin{cases}\n0, & x&lt;0\\\\\n1-p_n, & 0 \\leq x &lt; n\\\\\n1, & x\\geq n\n\\end{cases},\n\\] where \\(\\{p_n\\}_{n=1}^{\\infty}\\) is a sequence of real numbers such that \\[\n\\lim_{n\\rightarrow \\infty} p_n = p.\n\\]\n\n\\(p=0\\)이면 bounded in probability\n그러나 \\(p&gt;0\\)이면 we set a value of \\(\\varepsilon\\) such that \\(0&lt; \\varepsilon &lt; p\\). Let \\(x\\) be a positive real value. For any \\(n&gt;x\\) we have the property that \\(P(|X_m|\\leq x) = 1-p \\leq 1- \\varepsilon\\) for all \\(m&gt;n\\). Therefore, it is not possible to find the value of \\(x\\) required in the definition of bounded in probability.\n\n\n\nTheorem 6.5 (Bounded in Probability는 Limiting distribution이 valid인 것과 동치) Let \\(\\{X_n\\}_{n=1}^{\\infty}\\) be a sequence of random variables where \\(X_n\\) has distribution function \\(F_n\\) for all \\(n\\in \\mathbb{N}\\). Suppose that \\(F_n \\rightsquigarrow F\\) as \\(n\\rightarrow \\infty\\) where \\(F\\) may or may not be a vaild distribution function. Then, \\[\n\\lim_{x\\rightarrow \\infty} F(x) = 1, \\quad{} \\lim_{x\\rightarrow -\\infty} F(x) = 0\n\\] if and only if the sequence \\(\\{X_n \\}_{n=1}^{\\infty}\\) is bounded in probability.\n\n\n6.8.1 Bounded in probability와 converge in distribution\n\n\nTheorem 6.6 (분포수렴이면 확률유계) \\(\\{X_n\\}\\)이 확률변수 열이고 \\(X\\)가 확률변수라고 하자. \\(X_n \\rightarrow X\\)로 분포수렴하면 \\(\\{X_n\\}\\)은 확률유계이다.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\varepsilon&gt;0\\)일 때 \\(X\\)에 대해 \\(P(|X|\\leq x_{\\varepsilon})\\geq 1-\\varepsilon\\)이 성립하는 \\(x_{\\varepsilon}\\)을 선택하자. \\(x_{\\varepsilon}\\)와 \\(-x_{\\varepsilon}\\)가 \\(F\\)의 연속인 점이 되도록 항상 \\(x_{\\varepsilon}\\)를 선택할 수 있다. 그러면 다음을 얻는다.\n\\[\\begin{align*}\n\\lim_{n\\rightarrow \\infty}P(|X_n|&\\leq x_{\\varepsilon})\\geq \\lim_{n\\rightarrow\\infty}F_{X_n}(x_{\\varepsilon}) - \\lim_{n\\rightarrow\\infty}F_{X_n}(-x_{\\varepsilon}-0)\\\\\n&= F_{X}(x_{\\varepsilon})-F_X(-x_{\\varepsilon})\\geq 1-\\varepsilon.\n\\end{align*}\\]\n정확하게 하기 위해 \\(n\\geq N\\)에 대해 \\(P(|X_n| \\leq x_{\\varepsilon})\\geq 1-\\varepsilon\\)이 성립하도록 충분히 큰 \\(N\\)을 선택할 수 있다.\n\n\n\n그러나 앞선 정리의 역은 성립하지 않는다.\n\nExample 6.9 (확률유계이나 분포수렴하지 않는 예) \\(\\{X_n\\}\\)이 짝수 \\(n=2m\\)에 대해 \\(X_{2m}=2+ \\frac{1}{2m}\\)일 확률이 1이고, 홀수 \\(n=2m-1\\)에 대해 \\(X_{2m-1}=1+\\frac{1}{2m}\\)일 확률이 1인 퇴화확률변수열이라고 하자. 그러면 열 \\(\\{X_2,X_4,X_6,\\ldots\\}\\)은 퇴화확률변수 \\(Y=2\\)에 분포수렴하고, 열 \\(\\{X_1,X_3,X_5,\\ldots\\}\\)은 퇴화확률변수 \\(W=1\\)에 분포수렴한다. \\(Y\\)와 \\(W\\)의 분포가 동일하지 않으므로 열 \\(\\{X_n\\}\\)은 분포수렴하지 않는다. 그러나 열 \\(\\{X_n\\}\\)의 모든 값이 구간 \\([1,\\frac{5}{2}]\\)안에 있으므로 열 \\(\\{X_n\\}\\)은 확률유계이다.\n\n확률유계인 열(또는 확률변수로 분포수렴하는 것)을 생각하는 한 가지 방법은 \\(|X_n|\\)의 확률질량이 \\(\\infty\\)로 벗어나지 않는다는 것이다. 종종 분포수렴 대신 확률유계성을 이용할 수 있다.\n\nTheorem 6.7 (확률유계인 확률변수열과 확률수렴하는 확률변수열의 곱은 확률수렴) \\(\\{X_n\\}\\)이 확률유계인 확률변수 열이고 \\(\\{Y_n\\}\\)이 0으로 확률수렴하는 확률변수 열이라면 \\[\nX_n Y_n \\stackrel{P}{\\rightarrow}0.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\varepsilon&gt;0\\)이라고 하자. 다음이 성립하도록 \\(B_{\\varepsilon}&gt;0\\)과 정수 \\(N_{\\varepsilon}\\)을 선택한다. \\[\nn \\geq N_{\\varepsilon} \\Longrightarrow P(|X_n|\\leq B_{\\varepsilon}) \\geq 1-\\varepsilon.\n\\] 그러면 다음과 같으며, 이것으로부터 원하는 결과가 도출된다.\n\\[\\begin{align*}\n\\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon) &\\leq \\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon, |X_n| \\leq B_\\varepsilon)\\\\\n&+ \\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon, |X_n| &gt; B_\\varepsilon)\\\\\n&\\leq \\overline{\\lim}_{n\\rightarrow\\infty} P(|Y_n|\\geq \\frac{\\varepsilon}{B_\\varepsilon}) + \\varepsilon = \\varepsilon.\n\\end{align*}\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#converses",
    "href": "conv.html#converses",
    "title": "6  Convergence",
    "section": "6.9 Converses",
    "text": "6.9 Converses\n\n\n\n\n\n\nRemark\n\n\n\n처음 두 개의 정리는 \\(X\\)가 어떤 상수 \\(c\\)에 대해 \\(P(X=c)=1\\)을 만족하는 degenerate random variable일 경우 역이 성립함을 보여줌\n\n\n\nTheorem 6.8 If \\(X_1, X_2, \\ldots\\)are independent and \\(c\\) a constant, then \\[\nX_n \\stackrel{\\text{c.c.}}{\\rightarrow} c \\Longleftrightarrow X_n \\stackrel{\\text{a.s.}}{\\rightarrow} c  \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nSince both statements are equiv to \\[\n\\sum_{n=1}^{\\infty} P(\\vert X_n - c\\vert &gt; \\varepsilon) &lt;\\infty, \\quad{} \\forall \\varepsilon&gt;0\n\\] the conclusion follows from the Theorem 3.1 and Theorem 3.2 .\n\n\n\n\nTheorem 6.9 Let \\(X_1,X_2, \\ldots\\) be random variables and \\(c\\) a constant. Then \\[\nX_n \\stackrel{d}{\\rightarrow} \\delta (c) \\quad{} \\text{as } n\\rightarrow\\infty \\Longleftrightarrow X_n \\stackrel{p}{\\rightarrow} c \\quad{} \\text{as } n\\rightarrow\\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n확률수렴이면 분포수렴이므로 분포수렴일때 확률수렴인지만 보면 됨. \\(X_n \\stackrel{d}{\\rightarrow} \\delta (c) \\quad{} \\text{as } n\\rightarrow\\infty\\)이 성립한다고 하자. 그러면 \\[\n\\begin{align*}\nP(\\vert X_n - c \\vert &gt; \\varepsilon) &= 1-P(c-\\varepsilon \\leq X_n \\leq c+\\varepsilon)\\\\\n&= 1 - F_{X_n}(c+\\varepsilon) + F_{X_n} (c-\\varepsilon) - P(X_n = c-\\varepsilon)\\\\\n&\\leq 1 - F_{X_n}(c+\\varepsilon) + F_{X_n} (c-\\varepsilon) \\rightarrow 1 - 1 + 0\\\\\n&= 0 \\quad{} \\text{as } n\\rightarrow \\infty.\n\\end{align*}\n\\]\n\n\n\n다음은 subsequence를 활용한 역으로 바꾸는 방법이다.\n\nTheorem 6.10 Let \\(X_1,X_2, \\ldots\\) be random variables such that \\(X_n \\stackrel{p}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\). Then there exists a non-decreasing subsequence \\(\\{n_k, k\\geq 1\\}\\) of the positive integers, such that \\[\nX_{n_k} \\stackrel{\\text{c.c.}}{\\rightarrow} X \\quad{} \\text{as } n\\rightarrow \\infty.\n\\] In particular, \\[\nX_{n_k} \\stackrel{\\text{a.s.}}{\\rightarrow} X \\quad{} \\text{as } n\\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nBy assumption, there exists a non-decreasing subsequence, \\(\\{n_k, k\\geq 1\\}\\), such that \\[\nP\\Big( \\vert X_{n_k} - X\\vert &gt; \\frac{1}{2^k}\\Big) &lt; \\frac{1}{2^k}.\n\\] Consequently, \\[\n\\sum_{k=1}^{\\infty} P \\Big(\\vert X_{n_k} - X\\vert &gt; \\frac{1}{2^k} \\Big) &lt;\\infty.\n\\] Since \\(\\frac{1}{2^k} &lt; \\varepsilon\\) for any \\(\\varepsilon&gt;0\\) whenever \\(k&gt; \\log (1/\\varepsilon)/\\log 2\\), it follows that \\[\n\\sum_{k=1}^{\\infty}P \\Big(\\vert X_{n_k} - X\\vert &gt; \\varepsilon \\Big) &lt;\\infty.\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n수열에서 \\(a\\)로 수렴하는 convergent sequence가 있는 것은 모든 subsequence에서 \\(a\\)로 수렴하는 subsequence를 만들어낼 수 있음과 동치인 유명한 정리가 있음\n(개인적인 생각) 확률수렴은 말 그대로 특정 확률변수에 수렴할 확률이 1인 것 뿐이라 어떤 \\(\\omega\\)를 생각할 때 sequence에서 매우 큰 \\(N\\)을 잡는다 하더라도 \\(X_n(\\omega), n\\geq N\\)이 항상 \\(X(\\omega)\\)에 어떤 threshold (예를 들면 \\(\\varepsilon\\))보다 항상 가까이 있다고 말할 수는 없는 것 같다. 다만 확률이 1이므로 \\(N\\)이 커지면 threshold 바깥으로 튈 가능성은 점점 주는 것 같다. 이를 이용해보면 튀는 친구들을 적절히 잘 피할 수 있는 확률변수열의 subsequence열을 항상 생각할 수 있다면 이 subsequence로 만든 새로운 확률변수열은 확률수렴이 아닌 거의 확실한 수렴등 더 강한 조건의 수렴을 만들어낼 수 있다는 것으로 보인다. (그림으로 그려두면 좋긴 한데 능력 부족)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#uniform-integrability",
    "href": "conv.html#uniform-integrability",
    "title": "6  Convergence",
    "section": "6.10 Uniform Integrability",
    "text": "6.10 Uniform Integrability\n\n앞서 Theorem 6.4 로부터 \\(X_n\\stackrel{r}{\\rightarrow}X \\Longrightarrow X_n\\stackrel{p}{\\rightarrow} X\\) as \\(n\\rightarrow\\infty\\)임을 안다. 그러면 어떤 조건이 있을 때 converge in probability 하면 mean convergence를 보장하는지 궁금할 수 있다. Uniform integrability 조건이 추가되면 그러함이 알려져 있다. (Gut 2014)\n\nDefinition 6.10 (Uniform Integrability) A sequence \\(X_1, X_2, \\ldots\\) is called uniformly integrable iff \\[\nE|X_n|I\\{ |X_n| &gt; a\\} \\rightarrow 0 \\quad{} \\text{as} \\quad{} a \\rightarrow \\infty \\quad{} \\text{uniformly in } n.\n\\] 분포함수를 이용해 다른 방법으로 정의할 수도 있다. \\(X_1, X_2,\\ldots\\) is unifomly integrable iff \\[\n\\int_{|x|&gt;a} |x|dF_{X_n}(x)\\rightarrow 0 \\quad{} \\text{as} \\quad{} a \\rightarrow \\infty \\quad{} \\text{uniformly in } n.\n\\]\n\n\n\n\n\n\n\nRemark\n\n\n\n\\(X_1, X_2 , \\ldots\\)이 유한한 평균을 갖고 있다는 뜻은 \\(E|X_n|I\\{|X_n|&gt;a\\}\\rightarrow 0\\) as \\(a \\rightarrow \\infty\\) for every \\(n\\)을 의미한다. 즉 convergent integrals의 tail이 0으로 수렴해야 하는 것이다. Uniformly integragle은 the contributions in the tails of the integrals tend to \\(0\\) uniformly for all members of the sequence임을 뜻한다. (Gut 2014)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-of-moments",
    "href": "conv.html#convergence-of-moments",
    "title": "6  Convergence",
    "section": "6.11 Convergence of Moments",
    "text": "6.11 Convergence of Moments\n위키의 설명에 따르면 \\(X_n \\stackrel{L^r}{\\rightarrow}X\\)이면 \\(\\lim_{n\\rightarrow \\infty}E[|X_n|^r] = E[|X|^r]\\)이 성립한다고 한다. 그러나 일반적인 moment의 convergence에 대해서는 잘 알지 못한다. 여기서는 uniformly integrablility를 추가해 기존 확률변수의 수렴과 moment convergence 사이의 관계에 대해 알아본다.\nWe are now in the position to show that uniform integrability is the correct concept, that is, that a sequence that converges almost surely, in probability, or in distribution, and is uniformly integrable, converges in the mean, that moments converge and that uniform integrability is the minimal additional assumption for this to happen. (Gut 2014)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#distributional-convergence-revisited",
    "href": "conv.html#distributional-convergence-revisited",
    "title": "6  Convergence",
    "section": "6.12 Distributional convergence revisited",
    "text": "6.12 Distributional convergence revisited\n\n6.12.1 Scheffe’s lemma\n\n\\(X_n\\)이 분포수렴하더라도 density는 어떤 특정 density fct로 수렴하지 않을 수 있음\n\n\nExample 6.10 \\(X_1, X_2,\\ldots\\)이 다음과 같은 density \\[\nf_{X_n}(x) =\n\\begin{cases}\n1 - \\cos (2\\pi n x), & \\text{for } 0 \\leq x 1,\\\\\n0, & \\text{o.w.}\n\\end{cases}\n\\] 를 갖는 확률변수라고 하자. 그러면 다음과 같이 \\[\nF_{X_n}(x)=\n\\begin{cases}\n0, & \\text{for } x\\leq 0,\\\\\nx - \\frac{\\sin (2\\pi n x)}{2\\pi n} \\rightarrow x, & \\text{for }0 \\leq x 1,\\\\\n1, & \\text{for } x\\geq 1,\n\\end{cases}\n\\] \\(X_n \\stackrel{d}{\\rightarrow} U(0,1)\\) as \\(n\\rightarrow \\infty\\)이다. 그러나 density는 oscillation하고 있어 수렴하지 않는다.\n\n\nDefinition 6.11 (Converges of total variance)  \n\n두 개의 분포함수 \\(F\\)와 \\(G\\)의 variational distance는 \\[\nd(F,G)= \\sup_{A\\in \\mathbb{R}} \\vert F(A) - G(A) \\vert.\n\\]\n\\(F\\)와 \\(G\\)와 관련된 확률변수가 \\(X\\), \\(Y\\)일 때, 위의 정의는 다음과 같음 \\[\nd(X,Y) =  \\sup_{A\\in \\mathbb{R}} \\vert P(X\\in A) - P(Y\\in A)\\vert .\n\\]\n확률변수 \\(X, X_1, X_2, \\ldots\\)가 \\[\nd(X_n ,X ) \\rightarrow 0 \\quad{} \\text{as} \\quad{} n \\rightarrow \\infty\n\\] 일 때, 확률변수열 \\(X_n\\)이 \\(n\\rightarrow\\infty\\)일 때 \\(X\\)에 converges in total variation이라고 한다.\n\n\n\\((-\\infty, x]\\)가 \\(x\\)가 주어졌을 때 Borel set이라고 할 때, \\[\n\\vert P(X_n \\leq x) - P(X\\leq x) \\vert \\leq \\sup_{A\\in\\mathbb{R}} \\vert P(X_n \\in A) - P(X \\in A) \\vert\n\\] 이므로 다음의 따름정리를 얻는다.\n\nLemma 6.1 \\(X_1, X_2, \\ldots\\)가 확률변수라고 하자. 만약 \\(n\\rightarrow\\infty\\)일 때 \\(X_n \\rightarrow X\\) in total variation이면 \\(n\\rightarrow\\infty\\)일 때 \\(X_n \\stackrel{d}{\\rightarrow}X\\)이다.\n\n\nTheorem 6.11 (Scheffe’s lemma) \\(X, X_1, X_2,\\ldots\\)가 absolutely continous random variable이라고 하자. 그러면 \\[\n\\sup_{A\\in\\mathbb{R}} \\vert P(X_n \\in A) - P(X \\in A) \\vert \\leq \\int_{\\mathbb{R}} \\vert f_{X_n}(x) - f_X(x)\\vert dx\n\\] 이고 만약 \\(n\\rightarrow\\infty\\)일 때 \\(f_{X_n}(x) \\rightarrow f_{X}(x)\\) almost everywhere라고 하면 \\[\nd(X_n, X) \\stackrel{n\\rightarrow \\infty}{\\longrightarrow} 0\n\\] 이다. 특별히 \\(n\\rightarrow\\infty\\)일 때 \\[\nX_n \\stackrel{d}{\\rightarrow}X\n\\] 이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#continuity-theorems",
    "href": "conv.html#continuity-theorems",
    "title": "6  Convergence",
    "section": "6.13 Continuity theorems",
    "text": "6.13 Continuity theorems\n\nUniqueness theorem: 두 개의 transform이 같으면 이와 연관된 distribution도 같음\n이를 약간 약화시켜 두 개의 transform이 almost equal이면 이와 연관된 distribution도 그렇지 않을까 하는 생각을 할 수도 있음\n어떤 transform이 coverge하면 이것과 관련된 분포의 열이나 확률변수 열로 그러할 것이라 짐작해 볼 수 있음\n이러한 류의 정리들을 continuity theorem이라고 함\n\n\nTheorem 6.12 (확률변수열의 특성함수가 수렴하면 확률변수열도 분포수렴) \\(X, X_1, X_2 ,\\ldots\\)가 확률변수라고 하자. 그러면 \\[\n\\varphi_{X_n}(t) \\stackrel{n\\rightarrow\\infty}{\\longrightarrow}\\varphi(t) ,\\quad{}\\forall t \\Longleftrightarrow X_n\\stackrel{d}{\\rightarrow}X \\quad{} \\text{as } n\\rightarrow\\infty.\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-of-functions-of-random-variables-the-continuous-mapping-theorem",
    "href": "conv.html#convergence-of-functions-of-random-variables-the-continuous-mapping-theorem",
    "title": "6  Convergence",
    "section": "6.14 Convergence of Functions of Random Variables: The Continuous Mapping Theorem",
    "text": "6.14 Convergence of Functions of Random Variables: The Continuous Mapping Theorem\nQ. \\(X_1,X_2,\\ldots\\)가 어떤 형태로든 \\(X\\)로 수렴함이 알려져 있다고 하자. 그렇다면 어떤 실함수 \\(h\\)에 대해 \\(h(X_1), h(X_2),\\ldots\\)도 같은 sense로 \\(h(X)\\)에 수렴할 것인가?\n\nTheorem 6.13 Let \\(X, X_1, X_2, \\ldots\\) be random variables such that \\[\nX_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\quad{} \\text{as } n \\rightarrow \\infty,\n\\] and suppose that \\(h\\) is a continuous function. Then \\[\nh(X_n) \\stackrel{\\text{a.s.}}{\\rightarrow} h(X) \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe definition of continuity implies that, \\[\n\\{ \\omega: X_n(\\omega) \\rightarrow X(\\omega)\\} \\subset \\{ \\omega: h(X_n(\\omega)) \\rightarrow h(X(\\omega))\\}\n\\] and since the former set has probability 1, so has the latter. (Gut 2014)\n\n\n\n\nTheorem 6.14 Let \\(X, X_1, X_2, \\ldots\\) be random variables such that \\[\nX_n \\stackrel{p}{\\rightarrow} X \\quad{} \\text{as } n \\rightarrow \\infty,\n\\] and suppose that \\(h\\) is a continuous function. Then \\[\nh(X_n) \\stackrel{p}{\\rightarrow} h(X) \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n\n\nTheorem 6.15 (The continuous mapping theorem) Let \\(X, X_1, X_2, \\ldots\\) be random variables and suppose that \\[\nX_n \\stackrel{d}{\\rightarrow} X \\quad{} \\text{as } n \\rightarrow \\infty.\n\\] If \\(g\\) is a continuous, then \\[\ng(X_n) \\stackrel{d}{\\rightarrow} g(X) \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\nRemark\n\n\n\nContinuous functions are limit-preserving. (Hansen 2022)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#references",
    "href": "conv.html#references",
    "title": "6  Convergence",
    "section": "6.15 References",
    "text": "6.15 References\n\n확률변수론\n\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. 5th ed. Cambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.\n\n\nHansen, Bruce. 2022. Econometrics. Princeton University Press.\n\n\nPolansky, Alan M. 2011. Introduction to Statistical Limit Theory. CRC Press.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "lln.html",
    "href": "lln.html",
    "title": "7  The Law of Large Numbers",
    "section": "",
    "text": "7.1 Preliminaries\n제일 많이 쓰이는 기술은 truncation이라고 하는 것으로, 이 방법의 특징은 원래 확률변수열과 asymptotically equivalent 하면서 좀 더 다루기 쉬운 수열을 생각하는 것이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#preliminaries",
    "href": "lln.html#preliminaries",
    "title": "7  The Law of Large Numbers",
    "section": "",
    "text": "Definition 7.1 (Truncation) (Durrett (2019) 2.2.3)\nTo truncate a random variable \\(X\\) at level \\(M\\) means considering \\[\n\\overline{X} = XI_{(\\vert X \\vert \\leq M)}=\n\\begin{cases}\nX & \\text{if } \\vert X \\vert \\leq M\\\\\n0 & \\text{if } \\vert X \\vert &gt; M\n\\end{cases}.\n\\]\n\n\n\n\n\n\n\nRemark\n\n\n\n예를 들어 finite second moment 없이 weak law를 하려면 truncation으로 자르고 Chebyshev’s inequality를 적용하면 된다고 한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#convergence-equivalence",
    "href": "lln.html#convergence-equivalence",
    "title": "7  The Law of Large Numbers",
    "section": "7.2 Convergence Equivalence",
    "text": "7.2 Convergence Equivalence\nQ. 두 개의 random variable의 sequence \\(\\{X_n\\}\\)과 \\(\\{Y_n\\}\\)의 같은 정도? 비슷한 정도는?\n\nDefinition 7.2 (Convergence equivalence) The sequences \\(X_1, X_2, \\ldots\\) and \\(Y_1, Y_2, \\ldots\\) of random variables are said to be convergence equivalent if \\[\n\\sum_{n=1}^{\\infty}P(X_n \\neq Y_n) &lt; \\infty.\n\\]\n\n다음 정리는 first Borel-Cantelli lemma Theorem 3.1 로부터 얻는다고 한다. (Gut 2014)\n\nTheorem 7.1 If \\(X_1, X_2, \\ldots\\) and \\(Y_1, Y_2, \\ldots\\) are converge equivalent, then:\n\n\\(P(X_n \\neq Y_n \\text{ i.o.})=0\\)\n\\(\\sum_{n=1}^{\\infty}(X_n - Y_n)\\) converges a.s.\nIf \\(b_n \\in \\mathbb{R}\\), \\(n\\geq 1\\), \\(b_n \\uparrow \\infty\\) as \\(n\\rightarrow\\infty\\), then \\[\n\\frac{1}{b_n} \\sum_{k=1}^n (X_k - Y_k) \\stackrel{\\text{a.s.}}{\\rightarrow}0 \\quad{} \\text{as }n\\rightarrow\\infty.\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n다음 예제는 truncation을 이용해 어떤 확률변수열 \\(\\{X_n\\}\\)의 convergence equivalent한 새로운 함수열을 만들 수 있음을 보인다.\n\n\n\nExample 7.1 (Truncation과 convergence equivalent) If \\(X_1, X_2,\\ldots\\) is such that \\(\\sum_{n=1}^{\\infty} P (\\vert X_n \\vert &gt;a)&lt;\\infty\\), then we obtain a convergence equivalent sequence by introducing the random variables \\(Y_n = X_n I \\{\\vert X_n \\vert  \\leq a \\}\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#moments-and-tails",
    "href": "lln.html#moments-and-tails",
    "title": "7  The Law of Large Numbers",
    "section": "7.3 Moments and Tails",
    "text": "7.3 Moments and Tails\n\nProposition 7.1 (Moments and Tails)  \n\nLet \\(r&gt;0\\). Suppose that \\(X\\) is a non-negative random variable. Then \\[\nEX^r &lt; \\infty \\quad{}\\Longrightarrow \\quad{} x^r P(X&gt;x) \\rightarrow 0 \\quad{} \\text{as }x \\rightarrow \\infty,\n\\] but not necessarily conversely.\nSuppose that \\(X, X_1, X_2, \\ldots\\) are i.i.d. random variables with mean \\(0\\). Then, for any \\(a &gt;0\\), \\[\nEXI\\{ |X| \\leq a\\}= - EXI\\{ |X|&gt;a\\},\n\\] and \\[\n\\Big| E \\sum_{k=1}^n X_k I\\{ |X_k| \\leq a\\} \\Big|\\leq n E|X| I\\{|X|&gt;a\\}.\n\\]\nLet \\(a &gt;0\\). If \\(X\\) is a random variable with mean \\(0\\), then \\(Y=XI\\{|X|\\leq a\\}\\) does not in general have mean \\(0\\). However, if \\(X\\) is symmetric, then \\(EY=0\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#a-weak-law-for-partial-maxima",
    "href": "lln.html#a-weak-law-for-partial-maxima",
    "title": "7  The Law of Large Numbers",
    "section": "7.4 A Weak Law for Partial Maxima",
    "text": "7.4 A Weak Law for Partial Maxima",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#the-weak-law-of-large-numbers",
    "href": "lln.html#the-weak-law-of-large-numbers",
    "title": "7  The Law of Large Numbers",
    "section": "7.5 The Weak Law of Large Numbers",
    "text": "7.5 The Weak Law of Large Numbers\n\n\nTheorem 7.2 (WLLN)  \n\n\\(X,X_1,X_2,\\ldots\\)가 유한한 기댓값 \\(\\mu\\), 즉 \\(E(X)&lt;\\infty\\)를 갖는 i.i.d. 확률변수들이라고 하고 \\(S_n,n\\geq 1\\)을 그들의 partial sum이라고 하자. 그러면 \\[\n\\frac{S_n}{n}\\stackrel{p}{\\rightarrow}\\mu \\quad{} \\text{as } n\\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\\(E|X|&lt; \\infty\\) 조건이 빠지게 되면 표본평균이 유한한 값에 확률수렴하지 않을 수 있음\n\n\n\n\n\nExample 7.2 (큰 수의 약법칙을 따르지 않는 확률변수열)  \n\n독립이고 한계분포가 모두 \\(\\text{Cauchy}(1,0)\\)인 확률벡터를 생각하면, \\(\\frac{S_n}{n}\\sim \\text{Cauchy}(1,0)\\)이라고 함\n즉 \\(\\frac{S_n}{n}\\)이 0에 확률수렴하지 않으므로 독립이고 분포가 같은 코시 확률변수열에서는 큰 수의 약한 법칙이 성립하지 않음\n\n\n\n\nTheorem 7.3 (Markov theorem) \\(\\{X_n, n\\geq 1\\}\\)을 다음의 조건 (Markov condition) \\[\n\\frac{1}{n^2} \\text{Var}(X_1 + \\cdots + X_n) \\rightarrow 0 \\quad{} \\text{as }n \\rightarrow \\infty\n\\] 을 만족하는 확률변수열이라 하자. 그러면 \\(\\{X_n\\}\\)은 WLLN을 만족한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n마르코프 조건은 WLLN에 대한 충분조건이나 필요조건은 아님",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#a-weak-law-without-finite-mean",
    "href": "lln.html#a-weak-law-without-finite-mean",
    "title": "7  The Law of Large Numbers",
    "section": "7.6 A Weak Law Without Finite Mean",
    "text": "7.6 A Weak Law Without Finite Mean\n\nTheorem 7.4 (A Weak law without finite mean) (Gut (2014) 의 6.4, Durrett (2019) 의 Theorem 2.2.12)\nSuppose that \\(X, X_1, X_2,\\ldots\\) are i.i.d. random variables with partial sums \\(S_n, n\\geq 1\\). Then \\[\n\\frac{S_n - n E(X I\\{\\vert X\\vert \\leq n\\})}{n} \\stackrel{p}{\\rightarrow} 0 \\quad{} \\text{as } n \\rightarrow\\infty\n\\] iff \\[\nn P(\\vert X \\vert &gt; n) \\rightarrow 0 \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#the-strong-law-of-large-numbers",
    "href": "lln.html#the-strong-law-of-large-numbers",
    "title": "7  The Law of Large Numbers",
    "section": "7.7 The Strong Law of Large Numbers",
    "text": "7.7 The Strong Law of Large Numbers\n\nTheorem 7.5 (큰 수의 센 법칙을 따르는 충분조건) 확률변수열 \\(\\{x_i\\}_{i=1}^n\\)의 평균이 \\(\\mu_i\\), 분산이 \\(\\sigma_i^2\\)일 때 \\[\n\\sum_{i=1}^{\\infty} \\sigma_i^2 &lt; \\infty\n\\] 이면 \\(\\sum_{i=1}^{\\infty}(X_i - \\mu_i)\\)는 거의 틀림없이 0으로 수렴한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n큰 수의 센 법칙을 따르는 확률변수열 은 (당연히) 큰 수의 약한 법칙도 성립함\n\n\n\n\n\nTheorem 7.6 (The Kolmogorov strong law)  \n\n만약 \\(E|X|&lt;\\infty\\)이고 \\(E(X)=\\mu\\)라면 \\[\n\\frac{S_n}{n}\\stackrel{\\text{a.s.}}{\\rightarrow}\\mu \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n만약 어떤 상수 \\(c\\)에 대해 \\(\\frac{S_n}{n}\\stackrel{\\text{a.s.}}{\\rightarrow} c\\) as \\(n\\rightarrow \\infty\\)라고 한다면 \\[\nE(X) &lt;\\infty \\quad{} \\text{and} \\quad{} c= E(X).\n\\]\n만약 \\(E|X| = \\infty\\)라 한다면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{n} = + \\infty.\n\\]\n\n\n\nExample 7.3 (WLLN은 성립하니 SLLN은 만족하지 않는 예) 확률질량함수 \\(p_{X_n}(x) = P\\{ X_n = x\\}\\)가 \\[\np_{X_n}(x) =\n\\begin{cases}\n1- \\frac{1}{n\\log n}, & x=0,\\\\\n\\frac{1}{2n\\log n}, & x = \\pm n\n\\end{cases}\n\\] 인 독립 확률변수열 \\(\\{X_n\\}_{n=2}^{\\infty}\\)를 생각하자.\n\n\\(n \\geq 2\\)일 때 \\(A_n = \\{|X_n| \\geq n\\}\\)이라고 두면 \\(P\\{A_n\\} = \\frac{1}{n\\log n}\\)이므로 \\(\\sum_{n=2}^{\\infty} P\\{A_n\\} \\rightarrow \\infty\\)이다. 바꾸어 말하면, \\(\\sum_{n=2}^{\\infty}P\\{A_n\\}\\)이 발산하고 \\(X_n\\)이 서로 독립이므로, 보렐-칸텔리 정리에서 \\(P\\{A_n \\text{ i.o.}\\}=1\\)이다. 이는 \\[\nP\\{|X_n|\\geq n \\text{ i.o.}\\} = P \\{ \\Big\\vert\\frac{X_n}{n}\\Big\\vert \\geq \\text{ i.o.} \\} = P\\{\\lim_{n\\rightarrow\\infty}\\frac{S_n}{n} \\neq 0 \\} =1\n\\] 이다. 그러므로 \\(\\{X_n\\}_{n=2}^{\\infty}\\)는 큰 수의 강법칙을 만족하지 않는다.\n\\(\\text{Var}\\{X_ k\\} = \\frac{k}{\\log k}\\)이므로 \\[\n\\begin{align*}\n\\frac{1}{n^2}\\sum_{k=2}^n \\text{Var}\\{X_k\\} &\\leq \\frac{1}{n^2} \\Big( \\frac{2}{\\log 2} + \\int_3^{n+1}\\frac{x}{\\log x} dx \\Big)\\\\\n&\\leq \\frac{2}{n^2 \\log 2} + \\frac{(n-2)(n+1)}{n^2 \\log n}\\\\\n&\\rightarrow 0\n\\end{align*}\n\\] 이고 마르코프 조건 Theorem 7.3 을 생각해 보면 \\(\\{X_n \\}_{n=2}^{\\infty}\\)는 큰 수의 약법칙을 만족한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#the-glivenkocantelli-theorem",
    "href": "lln.html#the-glivenkocantelli-theorem",
    "title": "7  The Law of Large Numbers",
    "section": "7.8 The Glivenko–Cantelli Theorem",
    "text": "7.8 The Glivenko–Cantelli Theorem\nLet \\(X_1, X_2, \\ldots, X_n\\) be a sample from the distribution \\(F\\).\n\nEmpirical distribution function \\[\nF_{n}(x) = \\frac{1}{n}\\sum_{k=1}^n I\\{X_k \\leq x\\}.\n\\]\n\n(Gut 2014) Strong law로부터 모든 \\(x\\)에 대해 \\[\nF_n(x) \\stackrel{\\text{a.s.}}{\\rightarrow} F(x),\\quad{} \\text{as }n\\rightarrow\\infty.\n\\]\n\n\n\n\n\n\nRemark\n\n\n\nGlivenko-Cantelli Theorem은 \\(n\\rightarrow\\infty\\)일 때 \\(F_n\\)이 \\(F\\)에 대해 converges uniformly한다는 것을 보여준다. (Durrett 2019)\n\n\n\nTheorem 7.7 (The Glivenko-Cantelli theorem) \\[\n\\sup_x \\vert F_n (x) - F(x) \\vert \\stackrel{\\text{a.s.}}{\\rightarrow} 0 \\quad{} \\text{as }n \\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\nFix \\(x\\) and let \\(Y_n = I_{(X_n \\leq x)}\\). Since \\(Y_n\\) are i.i.d. with \\(E(Y_n) = P(X_n \\leq x) = F(x)\\), the SLLN implies that \\(F_n (x) = \\frac{1}{n}\\sum_{m=1}^n Y_m \\stackrel{\\text{a.s.}}{\\rightarrow} F(x)\\).\nIn general, if \\(F_n\\) is a sequence of nondecreasing functions that converges pointwise to a bounded and continuous limit \\(F\\), then \\(\\sup_x \\vert F_n (x) - F(x) \\vert \\rightarrow 0\\).\n그러나 보통 \\(F(x)\\)는 jump를 가질 수 있고, 이때의 증명은 조금 복잡해진다. (Durrett 2019)\nFix \\(x\\) and let \\(Z_n =  I_{(X_n \\leq x)}\\). Since \\(Z_n\\) are i.i.d. with \\(E(Z_n) = P(X_n &lt; x) = F(x-) = \\lim_{y\\uparrow x} F(y)\\), the SLLN implies that \\(F_n (x-) = \\frac{1}{n}\\sum_{m=1}^n Z_m \\rightarrow F(x-)\\) a.s. For \\(1 \\leq j \\leq k-1\\), let \\(x_{j,k} = \\inf \\{y: F(y)\\geq j/k\\}\\). The pointwise convergence of \\(F_n(x)\\) and \\(F_n(x-)\\) imply that we can pick \\(N_k (\\omega)\\) so that if \\(n \\geq N_k (\\omega)\\), then \\[\n\\vert F_n (x_{j,k}) - F(x_{j,k}) \\vert \\frac{1}{k} \\quad{} \\text{and} \\quad{} \\vert F_n (x_{j,k}-) - F(x_{j,k}-) \\vert &lt; \\frac{1}{k}\n\\] for \\(1 \\leq j \\leq k-1\\). If we let \\(x_{0,k} = - \\infty\\) and \\(x_{k,k} = \\infty\\), then the last two inequalities hold for \\(j=0\\) or \\(k\\). If \\(x \\in (x_{j-1, k}, x_{j,k})\\) with \\(1\\leq j \\leq k\\) and \\(n\\geq N_k (\\omega)\\), then using the monotonicity of \\(F_n\\) and \\(F\\), and \\(F(x_{j,k}-) - F(x_{j-1},k) \\leq \\frac{1}{k}\\), we have \\[\n\\begin{align*}\nF_n (x) &\\leq F_n (x_{j,k}-) \\leq F(x_{j,k}-) + \\frac{1}{k}\\leq F(x_{j-1,k}) + \\frac{2}{k} \\leq F(x) + \\frac{2}{k}\\\\\nF_n (x) & \\geq F_n (x_{j-1,k}) \\geq F(x_{j-1,k}) - \\frac{1}{k} \\geq F(x_{j,k}-) - \\frac{2}{k} \\geq F(x) - \\frac{2}{k}\n\\end{align*}\n\\] so \\(\\sup_x \\vert F_n(x) - F(x) \\vert \\leq \\frac{2}{k}\\), and we have proved the result.\n\n\n\n\n\n7.8.1 Glivenko-Cantelli theorem의 R 예제\n\n출처: Computer Intensive Statistics: APTS 2023–24 Computer Practical 1 Solutions\n\n\n\nCode\nru &lt;- runif(10000); F10 &lt;- ecdf(ru[1:10]); F50 &lt;- ecdf(ru[1:50]) \nF500 &lt;- ecdf(ru[1:500]); F3000 &lt;- ecdf(ru[1:3000]); F10000 &lt;- ecdf(ru)\n\neu &lt;- c(10, max(abs(F10(ru[1:10]) - punif(ru[1:10]))))\neu &lt;- rbind(eu, c(50, max(abs(F50(ru[1:50]) - punif(ru[1:50])))))\neu &lt;- rbind(eu, c(500, max(abs(F500(ru[1:500]) - punif(ru[1:500])))))\neu &lt;- rbind(eu, c(3000, max(abs(F3000(ru[1:3000]) - punif(ru[1:3000])))))\neu &lt;- rbind(eu, c(10000, max(abs(F10000(ru[1:10000]) - punif(ru[1:10000])))))\n\nrn &lt;- rnorm(10000); Fn10 &lt;- ecdf(rn[1:10]); Fn50 &lt;- ecdf(rn[1:50]) \nFn500 &lt;- ecdf(rn[1:500]); Fn3000 &lt;- ecdf(rn[1:3000]); Fn10000 &lt;- ecdf(rn)\n\nen &lt;- c(10, max(abs(Fn10(rn[1:10]) - pnorm(rn[1:10]))))\nen &lt;- rbind(en, c(50, max(abs(Fn50(rn[1:50]) - pnorm(rn[1:50])))))\nen &lt;- rbind(en, c(500, max(abs(Fn500(rn[1:500]) - pnorm(rn[1:500])))))\nen &lt;- rbind(en, c(3000, max(abs(Fn3000(rn[1:3000]) - pnorm(rn[1:3000])))))\nen &lt;- rbind(en, c(10000, max(abs(Fn10000(rn[1:10000]) - pnorm(rn[1:10000])))))\n\nrc &lt;- rcauchy(10000); Fc10 &lt;- ecdf(rc[1:10]); Fc50 &lt;- ecdf(rc[1:50]) \nFc500 &lt;- ecdf(rc[1:500]); Fc3000 &lt;- ecdf(rc[1:3000]); Fc10000 &lt;- ecdf(rc)\n\nec &lt;- c(10, max(abs(Fc10(rc[1:10]) - pcauchy(rc[1:10]))))\nec &lt;- rbind(ec, c(50, max(abs(Fc50(rc[1:50]) - pcauchy(rc[1:50])))))\nec &lt;- rbind(ec, c(500, max(abs(Fc500(rc[1:500]) - pcauchy(rc[1:500])))))\nec &lt;- rbind(ec, c(3000, max(abs(Fc3000(rc[1:3000]) - pcauchy(rc[1:3000]))))) \nec &lt;- rbind(ec, c(10000, max(abs(Fc10000(rc[1:10000]) - pcauchy(rc[1:10000])))))\n\nplot(eu,type='l',col='red',main='Convergence of Empirical CDF')\nlines(en,col='blue')\nlines(ec,col='green')\nlegend('topright',c('Uniform','Normal','Cauchy'), lty=1, col=c('red','blue','green'))\n\n\n\n\n\nFigure: Illustration of Glivenko–Cantelli.\n\n\n\n\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. 5th ed. Cambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "clt.html",
    "href": "clt.html",
    "title": "8  Central Limit Theorem",
    "section": "",
    "text": "8.1 The i.i.d. case",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "clt.html#the-i.i.d.-case",
    "href": "clt.html#the-i.i.d.-case",
    "title": "8  Central Limit Theorem",
    "section": "",
    "text": "Theorem 8.1 (i.i.d., 유한분산일때의 CLT) Let \\(X, X_1, X_2, \\ldots\\) be i.i.d. random variables with finite expectation \\(\\mu\\), and positive, finite variance \\(\\sigma^2\\), and set \\(S_n = X_1 + X_2 + \\cdots + X_n, n\\geq 1\\). Then \\[\n\\frac{S_n - n\\mu}{\\sigma \\sqrt{n}} \\stackrel{d}{\\rightarrow}\\mathcal{N}(0,1), \\quad{} \\text{as }n \\rightarrow\\infty.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n특성함수에 대한 continuity theorem Theorem 6.12 의 관점에서 \\[\n\\varphi_{\\frac{S_n - n\\mu}{\\sigma \\sqrt{n}}} (t) \\rightarrow \\infty e^{-t^2/2} \\quad{} \\text{as }n \\rightarrow\\infty, \\text{ for} \\quad{} -\\infty &lt; t &lt; \\infty\n\\] 일을 보이면 충분하다. 간단하게 \\(\\mu=0, \\sigma=1\\)이라고 두자. 그러면 특성함수의 성질에 의해 \\[\n\\begin{align*}\n\\varphi_{\\frac{S_n - n\\mu}{\\sigma \\sqrt{n}}} (t) &=\\varphi_{\\frac{S_n }{\\sqrt{n}}} (t) = \\varphi_{S_n}\\Big( \\frac{t}{\\sqrt{n}} \\Big) = \\Big( \\varphi_X \\Big( \\frac{t}{\\sqrt{n}}\\Big)\\Big)^n = \\Big( 1- \\frac{t^2}{2n} + o\\Big( \\frac{t^2}{n}\\Big) \\Big)^n\\\\\n&\\rightarrow e^{-t^2/2} \\quad{} \\text{as }n \\rightarrow\\infty.\n\\end{align*}\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "clt.html#the-lindeberglevyfeller-theorem",
    "href": "clt.html#the-lindeberglevyfeller-theorem",
    "title": "8  Central Limit Theorem",
    "section": "8.2 The Lindeberg–Levy–Feller Theorem",
    "text": "8.2 The Lindeberg–Levy–Feller Theorem\n\n이번엔 summand가 independent이나 identically distributed는 아닌 상황을 생각\n이를 \\(X_1, X_2, \\ldots\\) be independent random variable with finite variances, and set, for \\(k\\geq 1\\), \\(E(X_k) = \\mu_k\\) \\(\\text{var}(X_k) = \\sigma_k^2\\), and, for \\(n\\geq 1\\), \\(S_n =\\sum_{k=1}^n X_k\\), and \\(s_n^2 = \\sum_{k=1}^n \\sigma_k^2\\). 그리고 degenerate한 케이스는 고려하지 않기로 한다.\n\n\nDefinition 8.1 (Lindeberg conditions) 다음 두 개의 조건은 Lindeberg conditions라고 하며 general form의 CLT와 관련이 있다. \\[\n\\begin{align*}\nL_1 (n) &= \\max_{1\\leq k \\leq n} \\frac{\\sigma_k^2}{s_n^2} \\rightarrow 0 \\quad{} \\text{as } n\\rightarrow \\infty,\\\\\nL_2 (n) &= \\frac{1}{s_n^2} \\sum_{k=1}^n E(X_k - \\mu_k)^2 I\\{ |X_k - \\mu_k | &gt; \\varepsilon s_n\\} \\stackrel{n\\rightarrow \\infty}{\\longrightarrow}0.\n\\end{align*}\n\\]\n\n\nTheorem 8.2 (Lindeberg–Levy–Feller CLT) \\(X_1, X_2,\\ldots\\)가 앞서와 같이 주어져 있다고 하자.\n\n만약 Definition 8.1 의 두 번째 식이 만족된다면, Definition 8.1 의 첫 번째 식도 만족되고 \\[\n\\frac{1}{s_n}\\sum_{k=1}^n (X_k - \\mu_k) \\stackrel{d}{\\rightarrow}\\mathcal{N}(0,1) \\quad{} \\text{as }n\\rightarrow\\infty\n\\] 도(Lindeberg–Levy–Feller 버전의 CLT) 만족한다.\n만약 Definition 8.1 의 첫 번째 식과 Lindeberg–Levy–Feller 버전의 CLT를 만족한다면, Definition 8.1 의 두 번째 식도 만족한다.\n\n\n\n8.2.1 Lyapounov’s Condition\n\nLindeberg condition은 증명하기 어려운 측면이 있어 이것보다 약간 강한 충분조건을 생각할 수 있는데 이것을 Lyapounov condition이라 함\n\n\nTheorem 8.3 (Lyapounov condition) \\(X_1, X_2,\\ldots\\)가 앞서와 같이 주어져 있다고 하자. 추가로 \\(E\\vert X_k \\vert^r &lt;\\infty\\) for all \\(k\\) and some \\(r&gt;2\\)라고 하자. 만약 \\[\n\\beta(n,r) = \\frac{\\sum_{k=1}^n E\\vert |X_k - \\mu_k \\vert^r}{s_n^r} \\rightarrow 0 \\quad{} \\text{as }n \\rightarrow \\infty\n\\] 를 만족한다면 Theorem 8.2 의 CLT도 성립한다.\n\n\n\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "lil.html",
    "href": "lil.html",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "",
    "text": "9.1 The Law of the iterated logarithm (LIL)\n한편, Theorem 9.1 과 같은 상황에서 체비세프 부등식을 적용하면 \\[\nP\\Big( \\Big\\vert \\frac{S_n}{\\sqrt{2\\sigma^2 n \\log \\log n}}  \\Big\\vert &gt; \\varepsilon \\Big)\\leq \\frac{1}{2\\varepsilon^2 \\log \\log n} \\stackrel{n\\rightarrow \\infty}{\\rightarrow} 0\n\\] 이기 때문에 \\[\n\\frac{S_n}{\\sqrt{2\\sigma^2 n \\log \\log n}} \\stackrel{p}{\\rightarrow} 0 \\quad{} \\text{as }n \\rightarrow \\infty\n\\] 즉, \\(\\frac{S_n}{\\sqrt{2\\sigma^2 n \\log \\log n}}\\)는 0으로 확률수렴한다.\n그러나 sample-wise, path-wise (a.s. 관점에서)로는 \\(-1\\)과 \\(1\\) 사이에서 진동한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "lil.html#the-law-of-the-iterated-logarithm-lil",
    "href": "lil.html#the-law-of-the-iterated-logarithm-lil",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "",
    "text": "Theorem 9.1 (Hartman and Wintner LIL)  \n\n\n\\(X, X_1, X_2, \\ldots\\)가 mean 0, variance \\(\\sigma^2 &lt;0\\)을 갖는 i.i.d. 확률변수들이라고 하고 \\(S_n = \\sum_{k=1}^n X_k, n\\geq 1\\)이라고 하면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} (\\lim\\inf_{n\\rightarrow\\infty}) \\frac{S_n}{\\sqrt{2\\sigma^2 n \\log \\log n}} = +1 (-1) \\quad{} \\text{a.s.}\n\\tag{9.1}\\]\n이를 간단히 쓰면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{\\sqrt{2\\sigma^2 n \\log \\log n}} = 1 \\quad{} \\text{a.s.}\n\\]\n역으로 만약 \\[\nP\\Big( \\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{\\sqrt{n \\log \\log n}} &lt; \\infty \\Big) &gt;0\n\\] 이면 \\(E(X^2)&lt;\\infty\\), \\(E(X)=0\\), (Equation 9.1) 이 성립\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n왜 하필 \\(\\log \\log n\\)이라는 생각이 들 수도 있는데, 어떤 사람들은 normal distribution의 density에 \\(\\exp (-x^2/2)\\)가 있어서 이 효과를 상쇄하려면 대략 \\(\\sqrt{\\log \\log n}\\)을 쓰는 것으로 이해해 볼 수도 있음",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "lil.html#r-코드",
    "href": "lil.html#r-코드",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "9.2 R 코드",
    "text": "9.2 R 코드\nHaigh (2013) 의 Example 6.21\nQ. Long-run behaviour of sums\nQ. \\(n\\)이 증가함에 따라 \\(S_n /\\sqrt{n}\\)의 fluctuations의 size는?\n\n9.2.1 Simulation setting\n\n\\(Y_n \\stackrel{\\text{indep}}{\\sim} U(0,1)\\)\n\\(X_n = Y_n \\sqrt{12} - \\sqrt{3}\\), so that \\(X_n \\stackrel{\\text{i.i.d.}}{\\sim} U(-\\sqrt{3}, \\sqrt{3})\\): 이렇게 하면 \\(E(X_n)=0, \\text{Var}(X_n)=1\\)이 됨\n\\(S_n = X_1 + \\cdots X_n\\)\n\n\n\n\n\n\n\nFigure: (a) Random sums. (b) CLT. (c) LIL. (d) LLN.\n\n\n\n\n\n\n9.2.2 Results\n\n그림에 대한 추가 설명(참고로 모든 그림의 x축은 log-스케일이다):\n\n\n\\(n\\)이 커짐에 따라 random sums \\(S_n\\)이 어떻게 되는지 보여줌, 점선은 \\(\\pm \\sqrt{2 n \\log \\log n}\\)\n\n\n(CLT) \\(n\\)이 커짐에 따라 \\(S_n/\\sqrt{n}\\)은 standard Gaussian으로 분포수렴, 점선은 \\(\\pm \\mathcal{N}^{-1}(0.01)\\) (분위수)\n\n\n(LIL) \\(n\\)이 커짐에 따라 \\(S_n/\\sqrt{n\\log \\log n}\\)은 \\([-\\sqrt{2}, \\sqrt{2}]\\) 사이에 존재, 점선은 \\(\\pm \\sqrt{2}\\)\n\n\n(SLLN) \\(n\\)이 커짐에 따라 \\(S_n/n \\rightarrow 0\\), 점선은 \\(\\pm \\sqrt{ \\frac{2 \\log \\log n}{n}}\\)\n\n\nSLLN: \\(S_n / n \\stackrel{n\\rightarrow \\infty}{\\rightarrow} 0\\) 임을 말하는데, 이는 어떤 \\(\\varepsilon&gt;0\\)이 주어졌을 때, \\(\\forall n \\geq N\\)에 대해 \\(S_n/n\\)이 구간 \\((-\\varepsilon, \\varepsilon)\\) 안에 있도록 하는 \\(N\\)이 존재\nCLT: \\(S_n /\\sqrt{n} \\stackrel{d}{\\rightarrow} \\mathcal{N}(0,1)\\) 임을 말하는데, 이는 \\(n\\)이 클때 \\(P(-1&lt; S_n /\\sqrt{n} &lt; 1) \\approx 0.68\\), \\(P(|S_n /\\sqrt{n}|&gt;2)\\approx 0.05\\)임 등을 추론할 수 있음을 의미함\n\n그러나 CLT가 boundedness를 말하는 것은 아니기 때문에 \\(n\\)이 매울 클 때에도 매우 크거나 작은 \\(S_n/\\sqrt{n}\\)이 나올 수 있음\n\nLIL: \\(U_n = S_n / \\sqrt{n \\log (\\log (n))}\\)에 대해 말하는데, \\(\\sqrt{\\log (\\log (n))}\\)은 unbounded지만 매우 천천히 증가하는 함수임, \\(n=10^6\\)일 때 비로소 \\(\\sqrt{\\log (\\log (n))}\\approx 1.62\\)가 됨\n\n\\(S_n\\) 또한 \\(n\\)이 커질수록 천천히 변하기 때문에 \\(U_n\\)은 매우 천천히 변할 것이라 생각할 수 있음\n그러나, \\(\\sqrt{\\log (\\log (n))}\\)은 \\(\\mathcal{N}(0,1)\\)의 변화를 잡아줄 수 있을 정도로 큰 값이기는 함\n\n정리해보자면, LIL은 언젠가는 \\(U_n\\)이 \\((-\\sqrt{2},\\sqrt{2})\\)에 있을 것임을 의미함\n\n\n\n\n\nHaigh, John. 2013. Probability Models. 2nd ed. 2013. SpringerLink. Dordrecht: Springer.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "limext.html",
    "href": "limext.html",
    "title": "10  Limit Theorems: Extensions and Generalizations",
    "section": "",
    "text": "10.1 Stable distributions",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Limit Theorems: Extensions and Generalizations</span>"
    ]
  },
  {
    "objectID": "limext.html#stable-distributions",
    "href": "limext.html#stable-distributions",
    "title": "10  Limit Theorems: Extensions and Generalizations",
    "section": "",
    "text": "Stable distribution의 정의에는 몇 가지가 있는 듯 (Nolan 2020)\n\n\nDefinition 10.1 (Stable distributions)  \n\n\n\\(X_1, X_2, \\ldots\\)가 확률변수 \\(X\\)의 i.i.d. copy라 하고 \\(S_n, n\\geq 1\\)을 partial sum이라 하자. 만약 어떤 상수 \\(c_n &gt; 0, d_n \\in \\mathbb{R}, n\\geq 1\\)이 존재해 \\[\nS_n \\stackrel{d}{=}c_n X + d_n, \\quad{} \\forall n\n\\] 이라 하면 확률변수 \\(X\\)의 분포를 stable in the broad sense라고 함\n만약 \\(\\forall n\\)에 대해 \\(d_n = 0\\)이라고 하면 분포를 strictly stable이라고 함\n\n\n\n\n\n\n\n\nRemark\n\n\n\n(Nolan (2020) 의 내용)\n\nStable distribution은 skeness, heavy-tail 등을 다룰 수 있는 probability distn의 큰 클래스이며 좋은 수학적 성질도 가지고 있다고 함\n문제점: Gaussian, Cauchy, Levy 등을 제외하면 density와 distn에 대한 closed formula가 부족하다는 단점 존재\n그러나 컴퓨터 프로그램의 도움을 받아 stable distn의 density나 distn 등을 계산할 수 있음\n\n\n\n\n\n\n\nNolan, John P. 2020. Univariate Stable Distributions: Models for Heavy Tailed Data. Springer Series in Operations Research and Financial Engineering. Cham, Switzerland: Springer.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Limit Theorems: Extensions and Generalizations</span>"
    ]
  },
  {
    "objectID": "ht.html",
    "href": "ht.html",
    "title": "11  Heavy-Tailed Distributions",
    "section": "",
    "text": "11.1 Heavy-tailed distributions",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Heavy-Tailed Distributions</span>"
    ]
  },
  {
    "objectID": "ht.html#heavy-tailed-distributions",
    "href": "ht.html#heavy-tailed-distributions",
    "title": "11  Heavy-Tailed Distributions",
    "section": "",
    "text": "Definition 11.1  \n\nTail function \\(\\overline{F}\\) of a distribution \\(F\\) on \\(\\mathbb{R}\\) to be given by \\(\\overline{F}(x) = F(x,\\infty), \\forall x\\).\nTail property of \\(F\\): any property which depends only on \\(\\{ \\overline{F} (x) : x \\geq x_0 \\}\\) for any (finite) \\(x_0\\).\nWe say that \\(F\\) has right-unbounded support if \\(\\overline{F}(x) &gt;0, \\forall x\\).\n\n\n\nDefinition 11.2 (Heavy-tailed distributions)  \n\nA distribution \\(F\\) on \\(\\mathbb{R}\\) is said to be right heavy-tailed if \\[\n\\int_{-\\infty}^{\\infty}e^{\\lambda x} F(dx) = \\infty, \\quad{} \\forall \\lambda &gt;0,\n\\] that is, iff \\(F\\) fails to posses any positive exponential moment.\nOtherwise \\(F\\) is said to be light-tailed.\n\n\n\nDefinition 11.3 (Long-tailed distributions)  \n\nA distribution \\(F\\) on \\(\\mathbb{R}\\) is said to be long-tailed if \\(F\\) has right-unbounded support and, for any fixed \\(y&gt;0\\), \\[\n\\frac{\\overline{F}(x+y)}{\\overline{F}(x)} \\rightarrow 1, \\quad{} \\text{as } x \\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\nClearly to be long-tailed is again a tail property of a distribution.\nFurther, it is fairly easy to see that a long-tailed distribution is also heavy-tailed.\n\n\n\n\nDefinition 11.4 (Subexponential distributions)  \n\nA distribution \\(F\\) on \\(\\mathbb{R}^{+}\\) is said to be subexponential if \\[\n\\lim_{x\\rightarrow\\infty}\\frac{\\overline{F * F}(x)}{\\overline{F}(x)}=2.\n\\]",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Heavy-Tailed Distributions</span>"
    ]
  },
  {
    "objectID": "ht.html#examples-of-heavy-tailed-distributions",
    "href": "ht.html#examples-of-heavy-tailed-distributions",
    "title": "11  Heavy-Tailed Distributions",
    "section": "11.2 Examples of heavy-tailed distributions",
    "text": "11.2 Examples of heavy-tailed distributions",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Heavy-Tailed Distributions</span>"
    ]
  },
  {
    "objectID": "mev.html",
    "href": "mev.html",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "",
    "text": "12.1 Pseudo-Polar Transforms\nKiriliouk et al. (2016) describe a pseudo-polar representation of bivariate data as a means to explore right-tail extremal dependency between the variables.\nLet \\((X_i, Y_i)\\) (real values) or \\((U_i, V_i)\\) (as probabilities) for \\(i=1,\\ldots, n\\) be a bivariate sample of size \\(n\\). When such data are transformed into a unit-Pareto scale by \\[\n\\hat{X}_i^{*} = \\frac{n}{n+1-R_{X,i}}, \\quad{} \\hat{Y}_i^{*} = \\frac{n}{n+1-R_{Y,i}},\n\\] where \\(R\\) is rank(), then letting each component sum or pseudo-polar radius be defined as \\[\n\\hat{S}_i = \\hat{X}_i^{*} + \\hat{Y}_i^{*},\n\\] and each respective pseudo-polar angle be defined as \\[\n\\hat{W}_i = \\frac{\\hat{X}_i^{*}}{\\hat{X}_i^{*} + \\hat{Y}_i^{*}} = \\frac{\\hat{X}_i^{*}}{\\hat{S}_i}\n\\] a pseudo-polar representation is available for study.\nA scatter plot of \\(\\hat{W}_i\\) (horizontal) versus \\(\\hat{S}_i\\) (vertical) will depict a pseudo-polar plot of the data.\nA density plot of the \\(\\hat{W}_i\\) is a representation of extremal dependence.\nFigure: Extremal dependence.",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#clustering-methods-in-extremes",
    "href": "mev.html#clustering-methods-in-extremes",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.2 Clustering Methods in Extremes",
    "text": "12.2 Clustering Methods in Extremes\n\n\nHandbook on Statistics of Extremes 책 발간 예정\nVector quantization\n\n\n12.2.1 K-means clustering\n\nGiven obs \\(\\pmb{x}_1, \\ldots, \\pmb{x}_n\\), find \\(K\\) cluster centroids \\(\\pmb{c}_1, \\ldots, \\pmb{c}_K\\) s.t. the avg data-point-to-centroid dist is minimized: \\[\n(\\pmb{c}_1, \\ldots, \\pmb{c}_K) := \\arg\\min_{\\pmb{c}_1, \\ldots, \\pmb{c}_K} \\sum_{k=1}^K\n\\]\nEstimate the centroids \\(\\pmb{c}_k\\) and the cluster membership of each \\(\\pmb{x}_i\\) in turns.\n\nGiven \\(\\hat{\\pmb{c}}_1, \\ldots, \\hat{\\pmb{c}}_K\\), assign \\(\\pmb{x}_i\\) to the cluster \\(k\\) with the closest centroid \\(\\hat{\\pmb{c}}_k\\). \\[\ni \\in C_k \\Longleftrightarrow d(\\pmb{x}_i, c_k) = \\min_{k'}d(\\pmb{x}_i, \\pmb{c}_{k'})\n\\]\nGiven all \\(\\pmb{x}_i\\)’s in cluster \\(k\\), update each \\(\\hat{\\pmb{c}}_k\\)\n\n\nQ. Choice of \\(d(\\cdot, \\cdot)\\): + Euclidean \\(d(\\pmb{x}, \\pmb{y}) = (\\pmb{x}- \\pmb{y})^T(\\pmb{x}- \\pmb{y})\\) + Then the centroids can be calculated as \\[\n  \\hat{\\pmb{c}}_k = \\arg\\min_{\\pmb{c}} \\sum_{i\\in C_k}(\\pmb{x}_i - \\pmb{c})^T(\\pmb{x}_i - \\pmb{c}) = \\frac{1}{|C_k|} \\sum_{i\\in C_k}\n  \\]\nQ. Choice of \\(K\\): + Prespecified + Use a scree plot where the obj fct \\[\n  \\min_{\\pmb{c}_1, \\ldots, \\pmb{c}_K} \\sum_{k=1}^K \\sum_{i \\in C_k} d(\\pmb{x}_i , \\pmb{c}_k)\n  \\]\n이러한 \\(K\\)-mean 같이 Euclidean dist를 쓰는 방법은 extreme value에서 통하기 어려움",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#spectral-clustering",
    "href": "mev.html#spectral-clustering",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.3 Spectral Clustering",
    "text": "12.3 Spectral Clustering\n\nCan detect nonlinear cluster patterns\nCan identify noise clusters",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#clustering-the-angluar-components",
    "href": "mev.html#clustering-the-angluar-components",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.4 Clustering the Angluar Components",
    "text": "12.4 Clustering the Angluar Components\n\n\\(\\pmb{Y}\\) be multivariate regularly varying with standardized margin (Frechet 등이 해당) Then \\[\n\\frac{\\pmb{Y}}{\\|\\pmb{Y}\\|}_{\\| \\pmb{Y}\\|&gt;t}\\stackrel{d}{\\rightarrow} \\Theta, \\quad{} t \\rightarrow \\infty.\n\\]\nClustering for extremes:\n\nObtain angular compts \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\) from \\(\\pmb{Y}_1, \\ldots , \\pmb{Y}_n\\)\nCluster \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\) instead.\n\n\n여기서 \\(\\Theta\\)는 unit sphere \\(\\{ \\pmb{x} \\| \\pmb{x} \\| = 1\\}\\)이라는 매우 좋은 space에 놓여 있다. (이때 \\(\\| \\cdot \\|\\)은 any norm이나 되지만 \\(L2\\) norm을 쓰기로 한다)",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#max-linear-models",
    "href": "mev.html#max-linear-models",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.5 Max-Linear Models",
    "text": "12.5 Max-Linear Models\n\nMax-linear random vector: \\[\n\\pmb{X} = (X_1, \\ldots, X_d) = \\vee_{i=1, \\ldots, K}\\pmb{b}_i Z_i\n\\]\nFactors \\(\\pmb{b}_1, \\ldots, \\pmb{b}_{K} \\in [ 0, \\infty )^{d}\\)\n\\(Z_1, \\ldots, Z_k\\): i.i.d. Frechet\n\nThen the angular measure \\(\\Theta\\) consists of point masses at \\[\n\\frac{\\pmb{b}_1}{\\|\\pmb{b}_1\\|}, \\ldots\n\\]\n\n12.5.1 Spherical \\(K\\)-means\n\nApply to \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\): \\(K\\)-means clustering with choice of distance \\[\nd(\\pmb{x}, \\pmb{y}) = 1- \\cos (\\pmb{x}, \\pmb{y})\n\\]\n\nOn the unit sphere \\(\\mathbb{S}_{+}^{d-1}\\),\n\n\\(d(\\pmb{x}, \\pmb{y})= 1-\\pmb{x}^T\\pmb{y}\\)\n\\(d\\) is equiv to the Euclidean dist\n\n\n\n12.5.2 Spherical \\(K\\)-PCs clustering for extremes\n\n앞선 방법과 달리 \\(d(\\pmb{x}, \\pmb{y}) = 1-(\\pmb{x}^T\\pmb{y})^2\\)을 쓰는 것이 차이점(제곱이 들어감)\nhttps://academic.oup.com/biomet/article-abstract/110/1/135/6551983?redirectedFrom=PDF\n\\(\\arg\\max_{\\|\\pmb{c}\\|_2=1} \\pmb{c}^T\\Sigma_k \\pmb{c}\\) 형태가 나옴\nFor any spectral measure that can be decomposed into two sub-faces \\(l_1\\) and \\(l_2\\), we would like the optimal centroids to satisfy \\[\n\\pmb{c}_1 \\in \\mathbb{F}_{l_1}, \\quad{} \\pmb{c}_2 \\in \\mathbb{F}_{l_2}\n\\]\nThis holds for spheical \\(K\\)-means iff \\[\n\\|l_1 | - | l_2 \\| \\leq 1\n\\]\nThis holds for spherical \\(K\\)-PCs always.\nIf angular components \\(\\pmb{x}\\) and \\(\\pmb{y}\\) belongs to different sub-faces, then \\(\\pmb{x}^T\\pmb{y}\\) close to \\(0\\).\n\n\n\n12.5.3 Spectral clustering for extremes\n\nLinear factor model with noise: \\[\n\\pmb{X} = (X_1, \\ldots, X_d) = \\sum_{i=1}^K\n\\]",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "rmatrices.html",
    "href": "rmatrices.html",
    "title": "13  Random Matrices",
    "section": "",
    "text": "13.1 Intro: R 예제",
    "crumbs": [
      "High-Dimensional Probability",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Matrices</span>"
    ]
  },
  {
    "objectID": "rmatrices.html#intro-r-예제",
    "href": "rmatrices.html#intro-r-예제",
    "title": "13  Random Matrices",
    "section": "",
    "text": "13.1.1 실험 1: Normal random symmetric matrix\n\n\\(A_{ij} \\sim \\mathcal{N}(0,1)\\)에서 \\(5000\\times 5000\\) random symmetric matrix 작성\nEigenvalue 계산 후 histogram 그림\n\n\n\n13.1.2 실험 2: Uniform random symmetric matrix\n\n\\(A_{ij} \\sim \\text{Uniform}(0,1)\\)에서 \\(5000\\times 5000\\) random symmetric matrix 작성\nEigenvalue 계산 후 histogram 그림\n\n\n\n\n\n\nFigure: (왼쪽) Normal random matrix의 eigenvalue의 distribution. (오른쪽) Uniform random matrix의 eigenvalue의 distribution.\n\n\n\n\n\n붉은 선은 Wigner semicircle distribution",
    "crumbs": [
      "High-Dimensional Probability",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Matrices</span>"
    ]
  },
  {
    "objectID": "bigoh.html",
    "href": "bigoh.html",
    "title": "14  Order Notation",
    "section": "",
    "text": "14.1 Big \\(O\\) and small \\(o\\) notation (deterministic versions)\nFor a deterministic sequence \\(a_n\\), \\(\\text{limsup}_{n\\rightarrow \\infty}:=\\lim_{n\\rightarrow \\infty}(\\sup_{k \\geq n} a_k)\\) is the largest limit of the subsequences of \\(a_n\\). It can be defined even if \\(\\lim_{n\\rightarrow\\infty}a_n\\) does not exist (e.g., in trigonometric functions). If \\(\\lim_{n\\rightarrow\\infty} a_n\\) exists, as in most of the common usages of the big-\\(O\\) notation, then \\(\\text{limsup}_{n\\rightarrow\\infty}a_n = \\lim_{n\\rightarrow\\infty}a_n\\).\n다음은 (García-Portugués 2024)에 적혀 있는 big-O, small-o에 대한 몇 가지 성질들이다.\n다음은 (García-Portugués 2024)가 소개한 \\(C_p\\) inequality이다.\n다음으로 생각해 볼 만한 것은 \\(n\\rightarrow\\infty\\)일 때 \\(O(n^{-1/2})\\)와 \\(O(n^{-1})\\)처럼 차수가 다른 수열의 수렴에 대한 비교이다.",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Order Notation</span>"
    ]
  },
  {
    "objectID": "bigoh.html#big-o-and-small-o-notation-deterministic-versions",
    "href": "bigoh.html#big-o-and-small-o-notation-deterministic-versions",
    "title": "14  Order Notation",
    "section": "",
    "text": "In mathematical analysis, \\(O\\)-related notation is mostly used to bound sequences that shrink to \\(0\\).\n\n\nDefinition 14.1 (Big-\\(O\\)) Given two strictly positive sequence \\(a_n\\) and \\(b_n\\), \\[\na_n = O(b_n): \\Longleftrightarrow \\text{limsup}_{n\\rightarrow \\infty}\\frac{a_n}{b_n} \\leq C, \\quad{} \\text{for a } C&gt;0\n\\] If \\(a_n = O(b_n)\\), then we say that \\(a_n\\) is big-O of \\(b_n\\). To indicate that \\(a_n\\) is bounded, we write \\(a_n = O(1)\\).\n\n\n\nDefinition 14.2 (Little-\\(o\\)) Given two strictly positive sequence \\(a_n\\) and \\(b_n\\), \\[\na_n = o(b_n): \\Longleftrightarrow \\lim_{n\\rightarrow\\infty} \\frac{a_n}{b_n} = 0.\n\\] If \\(a_n = o(b_n)\\), then we say that \\(a_n\\) is little-o of \\(b_n\\). To indicate that \\(a_n\\rightarrow 0\\), we write \\(a_n = o(1)\\).\n\n\nDefinition 14.3 (Asymptotically equivalent) (Polansky 2011) The notation \\(x_n \\asymp y_n\\) means that \\[\n\\lim_{n\\rightarrow\\infty} \\frac{x_n}{y_n}=1,\n\\] or that the two sequences are asymptotically equivalent as \\(n\\rightarrow\\infty\\).\n\n\n\n\n\n\n\nRemark\n\n\n\nOrder notation로 asymptotic behavior를 표현하는 것은 unique하지 않다. (Polansky 2011) 예를 들어 \\(a_n = O(n^{-1})\\)이라고 하자. 그렇다는 것은 \\(\\vert n a_n \\vert\\)가 모든 \\(n\\in \\mathbb{N}\\)에 대해 bounded하다는 것이다. 그런데 \\(|n^{1/2}a_n| \\leq |na_n|\\), \\(\\forall n\\in\\mathbb{N}\\)이므로, \\(a_n = O(n^{-1/2})\\)이기도 하다.\n\n\n\nExercise 14.1  \n\n\\(n^{-2} =o(n^{-1})\\) since \\(\\lim_{n\\rightarrow\\infty}\\frac{n^{-2}}{n^{-1}}\\lim_{n\\rightarrow\\infty}\\frac{1}{n}=0\\)\n\n\n\n\\(\\log n = O(n)\\): We want to show that \\(\\forall n\\geq 1, \\log (n) \\leq n\\). The proof is by indunction on \\(n\\). The claim is true for \\(n=1\\), since \\(0&lt;1\\). Now suppose \\(n\\geq 1\\) and \\(\\log (n) \\leq n\\). Since \\(n+1\\leq 2n\\), (밑이 2인 로그를 쓴 듯) \\[\n\\log (n+1) \\leq \\log (2n) = \\log(n) + 1 \\leq n+1\n\\] or \\[\n\\log (n+1) = \\log n \\log (1 + \\frac{1}{n}) &lt; n + \\log (1 + \\frac{1}{n}) &lt; n+1 \\because \\text{ since } \\log 2 &lt; 1\n\\]\n\\(n^{-1} = o((\\log n)^{-1})\\): 로피탈의 정리를 쓰면 \\[\n\\lim_{n\\rightarrow \\infty} \\frac{n^{-1}}{(\\log n)^{-1}}=\\lim_{n\\rightarrow \\infty}  \\frac{\\log n}{n}=0\n\\] 임을 보일 수 있음\n\\(n^{-4/5} = o(n^{-2/3})\\) \\[\n\\lim_{n\\rightarrow \\infty} \\frac{n^{-4/5}}{n^{-2/3}} = \\lim_{n\\rightarrow \\infty} n^{2/3 - 4/5} = \\lim_{n\\rightarrow\\infty} n^{-2/15}=0  \n\\] 으로 알 수 있음\n\\(3\\sin (n) = O(1)\\): \\(\\sin\\)함수는 진동함수이다.\n\n\n\n\n\n\n\n\nRemark\n\n\n\nBig-O, small-o의 정의로부터 다음을 알 수 있다.\n\n\\(a_n = O(b_n)\\) means that \\(a_n\\) is not larger than \\(b_n\\) asymptotically. If \\(a_n , b_n \\rightarrow 0\\), then it means that \\(a_n\\) does not decrease more slowly than \\(b_n\\), i.e., that \\(a_n\\) either decreases as fast as \\(b_n\\) or faster than \\(b_n\\).\n\\(a_n = o(b_n)\\) means that \\(a_n\\) is smaller than \\(b_n\\) asymptotically. If \\(a_n, b_n \\rightarrow 0\\), then it means that \\(a_n\\) decrease faster than \\(b_n\\).\n\n위의 사실로부터, big-O는 같은 속도로 수렴하거나 더 빠른 속도로 수렴하는 두 가지 경우를 모두 포함하고 있고, small-o는 더 빠른 속도로 수렴하는 경우만 포함하기 때문에 어떤 \\(C&gt;0\\)에 대해 little-o implies big-O라고 할 수 있다.\n\n\n\n\nProposition 14.1 Consider two strictly positive sequences \\(a_n, b_n \\rightarrow 0\\). The following properties hold (García-Portugués 2024):\n\n\\(kO(a_n) = O(a_n)\\), \\(ko(a_n) = o(a_n)\\), \\(k\\mathbb{R}\\).\n\\(o(a_n) + o(b_n) = o(a_n + b_n)\\), \\(O(a_n) + O(b_n) = O(a_n + b_n)\\).\n\\(o(a_n)o(b_n) = o(a_nb_n)\\), \\(O(a_n)O(b_n) = O(a_nb_n)\\).\n\\(o(a_n) + O(b_n) = O(a_n + b_n)\\), \\(o(a_n)O(b_n) = o(a_nb_n)\\).\n\\(o(1)O(a_n) = o(a_n)\\).\n\\(a_n^r = o(a_n^s)\\), for \\(r&gt;s\\geq 0\\).\n\\(a_nb_n =o(a_n^2 +b_n^2)\\) (아마 \\(O(a_n^2 + b_n^2)\\)이 되어야 할 듯)\n\\((a_n + b_n)^k = O(a_n^k + b_n^k)\\).\n\n\n\n\n\n\n\n\n\nSequence\nResult\n\n\n\n\n\\(b_n = 1/\\log (n)\\)\n\n\n\n\\(a_{1,n}=\\frac{2}{n}+\\frac{50}{n^2}\\)\n\\(o(b_n)\\) (hence also \\(O(b_n)\\))\n\n\n\\(a_{2,n}=\\frac{\\sin (n/5)+2}{n^{5/4}}\\)\n\\(o(b_n)\\) (hence also \\(O(b_n)\\))\n\n\n\\(a_{3,n}=\\frac{3(1+5\\exp(-(n-55.5)^2/200))}{n}\\)\n\\(o(b_n)\\) (hence also \\(O(b_n)\\))\n\n\n\\(a_{4,n}=\\frac{n+3}{4n\\log_{10}(n)}+\\frac{a_{3,n}}{2}\\)\n\\(O(b_n)\\), but not \\(o(b_n)\\)\n\n\n\\(a_{5,n}=\\frac{1}{4\\log_{2} (\\frac{n}{2})}\\)\n\\(O(b_n)\\), but not \\(o(b_n)\\)\n\n\n\\(a_{6,n}=\\frac{1}{\\log (n^2+n)}\\)\n\\(O(b_n)\\), but not \\(o(b_n)\\)\n\n\n\\(a_{7,n}=\\frac{1}{2\\log(5n+3)^{1/4}}\\)\nnot \\(O(b_n)\\) (hence neither \\(o(b_n)\\))\n\n\n\\(a_{8,n}=\\frac{1}{4\\log(\\log (10n+2))}\\)\nnot \\(O(b_n)\\) (hence neither \\(o(b_n)\\))\n\n\n\\(a_{9,n}=\\frac{1}{2\\log(\\log (n^2+10n+2))}\\)\nnot \\(O(b_n)\\) (hence neither \\(o(b_n)\\))\n\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n오른쪽의 그림들을 보면 수렴에 대해 파악할 수 있음\n\n위: \\(\\frac{a_{i,n}}{b_{n}}\\)이 \\(n\\rightarrow \\infty\\)일 때 0으로 수렴, 따라서 \\(\\frac{a_{i,n}}{b_{n}}=\\mathcal{o}(1)\\) 이고 \\(\\frac{a_{i,n}}{b_{n}}=\\mathcal{O}(1)\\)임\n가운데: \\(\\frac{a_{i,n}}{b_{n}}\\)이 \\(n\\rightarrow \\infty\\)일 때 0이 아닌 어떤 값으로 수렴하는 것처럼 보임, 따라서 \\(\\frac{a_{i,n}}{b_{n}}\\neq\\mathcal{o}(1)\\) 이나 \\(\\frac{a_{i,n}}{b_{n}}=\\mathcal{O}(1)\\)임\n아래: \\(\\frac{a_{i,n}}{b_{n}}\\)이 \\(n\\rightarrow \\infty\\)일 때 발산하는 것으로 보이며 따라서 \\(\\frac{a_{i,n}}{b_{n}}\\neq\\mathcal{o}(1)\\) 이고 \\(\\frac{a_{i,n}}{b_{n}}\\neq\\mathcal{O}(1)\\)임\n\n\n\n\n\n\nLemma 14.1 (\\(C_p\\) inequality) Given \\(a,b\\in \\mathbb{R}\\) and \\(p&gt;0\\), \\[\n|a+b|^p \\leq C_p (|a|^p + |b|^p), \\quad{} C_p=\n\\begin{cases}\n1, & p\\leq 1\\\\\n2^{p-1}, & p &gt;1.\n\\end{cases}\n\\]\n\n\n\nTheorem 14.1 ((Polansky 2011 의 thm 1.19)) Consider two sequences \\(\\{a_n\\}_{n=1}^{\\infty}\\) and \\(\\{b_n\\}_{n=1}^{\\infty}\\) and positive real numbers \\(k\\) and \\(m\\) where \\(k \\leq m\\). Then\n\nIf \\(a_n = o(n^{-k})\\) and \\(b_n = o(n^{-m})\\) as \\(n\\rightarrow \\infty\\), then \\(a_n + b_n = o(n^{-k})\\) as \\(n\\rightarrow \\infty\\).\nIf \\(a_n = O(n^{-k})\\) and \\(b_n = O(n^{-m})\\) as \\(n\\rightarrow \\infty\\), then \\(a_n + b_n = O(n^{-k})\\) as \\(n\\rightarrow \\infty\\).\nIf \\(a_n = O(n^{-k})\\) and \\(b_n = o(n^{-m})\\) as \\(n\\rightarrow \\infty\\), then \\(a_n + b_n = O(n^{-k})\\) as \\(n\\rightarrow \\infty\\).\nIf \\(a_n = o(n^{-k})\\) and \\(b_n = O(n^{-m})\\) as \\(n\\rightarrow \\infty\\), then \\(a_n + b_n = O(n^{-k})\\) as \\(n\\rightarrow \\infty\\).\n\n\n\n14.1.1 Big-\\(\\mathcal{O}\\)의 적분\n\nBig-\\(\\mathcal{O}\\)의 정의를 다시 생각해보자. \\[\nf(x) =\\mathcal{O}(g(x)) \\Longleftrightarrow \\exists M, c \\quad{}\\text{ s.t. }\\quad{}\\forall x &gt; c, \\quad{} |f(x)| \\leq M |g(x)|\n\\] 따라서 \\(a&lt;c&lt;b\\)에 대해 \\[\n\\Big\\vert \\int_a^b f(x) dx \\Big\\vert \\leq \\int_a^b \\Big\\vert f(x)\\Big\\vert  dx \\leq \\int_a^c \\Big\\vert f(x)\\Big\\vert  dx + M \\int_c^{b} |g(x)| dx\n\\]\n\nExample 14.1  \n\n함수가 \\[\nf(x) = \\mathcal{O}(x^{\\alpha})\n\\] 라고 하자. 그러면\n\n\\(\\alpha &lt;-1\\)일 때에는 \\(\\int_0^x f(y)dy =\\mathcal{O}(1)\\)이라고 말할 수 있는 것이 최선\n\\(\\alpha &gt;-1\\)일 때에는 \\(\\int_0^x f(y)dy =\\mathcal{O}(x^{\\alpha + 1})\\)인데 \\[\n  \\int_0^c |f(y)|dy = \\mathcal{O}(1)\n  \\] 이고 \\(\\alpha \\neq -1\\)일 때에는 \\[\n  \\int_c^x |f(y)|dy \\leq M \\int_c^x y^\\alpha dy =\\frac{M}{\\alpha+1}(x^{\\alpha+1}-c^{\\alpha+1}) = \\mathcal{O}(x^{\\alpha + 1}) + \\mathcal{O}(1)\n  \\]\n\n\n\n\n\n14.1.2 Big-\\(\\mathcal{O}\\)의 미분\n\n안타깝게도 big-\\(\\mathcal{O}\\)의 미분에 대해서는 estimate를 얻을 수 없다. 즉 \\(f(x) = \\mathcal{O}(g(x))\\)라고 해서 \\(f'(x) =\\mathcal{O}(g'(x))\\)를 만족하지는 않는다는 것이다.\n\n예를 들어 \\(f(x) = \\mathcal{O}(g(x))\\)이고 \\(h(x) = \\sin (x^n) f(x)\\)라고 하자. 그러면 \\(h(x) = \\mathcal{O}(g(x))\\)이다. 그러나 \\(h'(x) = \\mathcal{O}(x^{n-1}g(x)) + O(f'(x))\\)이므로, 첫 번째 항이 \\(f'(x)\\)보다 빨리 grow할 것이라고 짐작할 수 있다.",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Order Notation</span>"
    ]
  },
  {
    "objectID": "bigoh.html#stochastic-versions",
    "href": "bigoh.html#stochastic-versions",
    "title": "14  Order Notation",
    "section": "14.2 Stochastic versions",
    "text": "14.2 Stochastic versions\n\nDefinition 14.4 (Little-\\(o_p\\)) Given a strictly positive sequence \\(a_n\\) and a sequence of random variable \\(X_n\\), \\[\\begin{align*}\nX_n = o_P (a_n): &\\Longleftrightarrow  \\frac{|X_n|}{a_n}\\stackrel{P}{\\rightarrow}0\\\\\n&\\Longleftrightarrow\\lim_{n\\rightarrow\\infty}P\\Big[ \\frac{|X_n|}{a_n}&gt;\\varepsilon \\Big] =0, \\quad{} \\forall \\varepsilon &gt;0.\n\\end{align*}\\] If \\(X_n = o_p (a_n)\\), then we say that \\(X_n\\) is little-\\(o_p\\) of \\(a_n\\). To indicate that \\(X_n \\stackrel{P}{\\rightarrow}0\\), we write \\(X_n = o_p(1)\\).\n\n\nExample 14.2 Let \\(Y_n = o_p (n^{-1/2})\\) and \\(Z_n = o_p(n^{-1})\\). Then \\(Z_n\\) converges faster to zero in probability than \\(Y_n\\). To visualize this, recall that \\(X_n = o_p(a_n)\\) and that limit definitions entail that \\[\n\\forall \\varepsilon, \\delta &gt;0, \\exists n_0 = n_0 (\\varepsilon, \\delta)\\in \\mathbb{N}: \\forall n \\geq n_0(\\varepsilon, \\delta), \\quad{} P[|X_n|&gt;a_n\\varepsilon]&lt;\\delta.\n\\] Therefore, for fixed \\(\\varepsilon, \\delta&gt;0\\) and a fixed \\(n\\geq \\max (n_{0,Y}, n_{0,Z})\\), then \\(P[Y_n \\in (-n^{-1/2}\\varepsilon, n^{-1/2}\\varepsilon)]&gt;1-\\delta\\) and \\(P[Z_n \\in (-n^{-1}\\varepsilon, n^{-1}\\varepsilon)]&gt;1-\\delta\\), but the latter interval is much shorter, hence \\(Z_n\\) is forced to be more tightly concentrated about \\(0\\).\n\n\n\n\n\n\n\nRemark\n\n\n\n\nLittle-\\(o_p\\) allows us to easily quantify the speed at which a sequence of random variables converges to zero in probability.\nBig \\(O_p\\) allows us to bound a sequence of random variables in probability, in the sense that we can state that the probability of being above an arbitrarily large threshold \\(C\\) converges to zero.\nAs with its deterministic versions \\(o\\) and \\(O\\), a little-\\(o_p\\) is more restrictive than a big-\\(O_p\\), and the former implies the latter.\n\n\n\n\nDefinition 14.5 (Big-\\(o_p\\)) Given a strictly positive sequence \\(a_n\\) and a sequence of random variable \\(X_n\\), \\[\\begin{align*}\nX_n = O_P (a_n): \\Longleftrightarrow&  \\forall \\varepsilon&gt;0, \\exists C_{\\varepsilon}&gt;0, n_0(\\varepsilon) \\in \\mathbb{N}:\\\\\n&\\forall n \\geq n_0 (\\varepsilon), P \\Big[\\frac{|X_n|}{a_n} &gt; C_{\\varepsilon} \\Big] &lt; \\varepsilon\\\\\n\\Longleftrightarrow &\\lim_{C\\rightarrow\\infty}\\text{limsup}_{n\\rightarrow\\infty} P\\Big[\\frac{|X_n|}{a_n} &gt;C \\Big]=0.\n\\end{align*}\\] If \\(X_n = O_p(a_n)\\), then we say that \\(X_n\\) is big-\\(O_p\\) of \\(a_n\\).\n\n\nExample 14.3 Chebyshev inequality entails that \\(P[|X_n - E[X_n]|\\geq t]\\leq \\text{Var}[X_n]/t^2\\), \\(\\forall t&gt;0\\). Setting \\(\\varepsilon :=\\text{Var}[X_n]/t^2\\) and \\(C_{\\varepsilon}:=1/\\sqrt{\\varepsilon}\\), then \\(P\\Big[ |X_n - E[X_n]|\\geq \\sqrt{\\text{Var}[X_n]}C_{\\varepsilon} \\Big] \\leq \\varepsilon\\). Therefore, \\[\nX_n - E[X_n] = O_p (\\sqrt{\\text{Var}[X_n]}).\n\\] This is a very useful result, as it gives an efficient way of deriving the big-\\(O_p\\) form of a sequence of random variables \\(X_n\\) with finite variances.\n\nAn application of Example 14.3 shows that \\(X_n = O_p (n^{-1/2})\\) for \\(X_n \\stackrel{d}{=}\\mathcal{N}(0,1/n)\\). The nature of this statement and its relation with little-\\(o_p\\) is visualized, which shows a particular realization \\(X_n(\\omega)\\) of the sequence of random variables.\n\n\n\n\n\n\n\n\n\n\nExercise 14.2 It is actually true that:\n\n\\(X_n \\stackrel{P}{\\rightarrow}0\\).\n\\(n^{1/3}X_n \\stackrel{P}{\\rightarrow} 0\\).\n\\(n^{1/2}X_n \\stackrel{P}{\\rightarrow} \\mathcal{N}(0,1)\\).\n\n\n다음은 (Jiang 2022) 에 나와있는 정리다.\n\nTheorem 14.2 (\\(O_p(1)\\)이기 위한 충분조건) 다음 세 가지 조건 중 하나를 만족하면 \\(X_n = O_p(1)\\)이다.\n\nThere is \\(p&gt;0\\) such that \\(E(|X_n|^p), n\\geq 1\\) is bounded.\n\\(X_n\\stackrel{p}{\\rightarrow}X\\) as \\(n\\rightarrow\\infty\\) for some random variable \\(X\\).\n\\(X_n \\stackrel{d}{\\rightarrow}X\\) as \\(n\\rightarrow\\infty\\) for some random variable \\(X\\). (Polansky (2011) 의 theorem 8.1)\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\n1번이 성립한다고 하자. \\(\\varepsilon&gt;0\\)에 대해 Chebyshev 부등식을 쓰면 \\[\n\\begin{align*}\nP(|X_n|&gt;M) &= P(|X_n|^p &gt; M^p)\\\\\n&\\leq \\frac{E(|X_n|^p)}{M^p} \\leq \\frac{c}{M^p},\n\\end{align*}\n\\] where \\(c= \\sup_{n\\geq 1}E(|X_n|^p)&lt;\\infty\\). Thus, if we choose \\(M\\) such that \\(M&gt;(c/\\varepsilon)^{1/p}\\), we have \\(P(|X_n|&gt;M)&lt;\\varepsilon\\). Hence, \\(P(|X_n|\\leq M) &gt; 1-\\varepsilon\\) for any \\(n\\geq 1\\).\n3번 관련 StackExchange 참고\n\n\n\n\n다음은 big-\\(O_p\\) 및 little-\\(o_p\\)에 관한 성질들이다.\n\nProposition 14.2 Consider two strictly positive sequences \\(a_n, b_n \\rightarrow 0\\). The following properties hold (García-Portugués 2024) :\n\n\\(o_p(a_n) = O_p(a_n)\\) (little-\\(o_p\\) implies big-\\(O_p\\))\n\\(o(1) = o_p(1)\\), \\(O(1) = O_p(1)\\) (deterministic implies probabilistic)\n\\(kO_p(a_n) = O_p(a_n)\\), \\(k o_p(a_n) = o_p (a_n), k\\in \\mathbb{R}\\).\n\\(o_p(a_n) + o_p(b_n) = o_p(a_n + b_n)\\), \\(O_p(a_n) + O_p(b_n) = O_p(a_n + b_n)\\).\n\\(o_p(a_n)o_p(b_n) = o_p(a_n b_n)\\), \\(O_p(a_n)O_p(b_n) = O_p(a_n b_n)\\) .\n\\(o_p(a_n) + O_p(b_n) = O_p(a_n + b_n)\\), \\(o_p(a_n)O_p(b_n)=o_p(a_n b_n)\\).\n\\(o_p(1) O_p(a_n) = o_p (a_n)\\).\n\\((1+o_p(1))^{-1} = O_p(1)\\).\n\n\n\nExample 14.4 위 proposition의 2, 4번을 이용하면 Example 14.3 에 다음과 같은 표현이 가능하다. \\[\n\\begin{align*}\nX_n &= O(E[X_n]) + O_p (\\sqrt{\\text{var}[X_n]})\\\\\n&= O_p(E[X_n] + \\sqrt{\\text{var}[X_n]}).\n\\end{align*}\n\\]\n\nPolansky (2011) 의 theorem 8.3에서는 big-O, small-o, big-\\(O_p\\), small-\\(o_p\\)에 대한 모든 곱의 상황을 정리해 놓았다.\n\nTheorem 14.3 Let \\(\\{X_n\\}_{n=1}^{\\infty}\\) and \\(\\{Y_n \\}_{n=1}^{\\infty}\\) be sequences of random variables and let \\(\\{y_n\\}_{n=1}^{\\infty}\\) be a sequence of real numbers.\n\nIf \\(X_n = O_p (n^{-a})\\) and \\(Y_n = O_p(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n Y_n = O_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = O_p (n^{-a})\\) and \\(Y_n = o(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n y_n = o_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = O_p (n^{-a})\\) and \\(Y_n = o_p(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n Y_n = o_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = o_p (n^{-a})\\) and \\(y_n = o(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n y_n = o_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = O_p (n^{-a})\\) and \\(y_n = O(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n y_n = O_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = o_p (n^{-a})\\) and \\(y_n = O(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n y_n = o_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\nIf \\(X_n = o_p (n^{-a})\\) and \\(Y_n = o_p(n^{-b})\\) as \\(n\\rightarrow\\infty\\), then \\(X_n Y_n = o_p(n^{-(a+b)})\\) as \\(n\\rightarrow\\infty\\).\n\n\n다음은 Richard Lockhart 교수님의 강의노트 나 Shumway and Stoffer (2017) 의 appendix A에서 알 수 있는 big-O, small-o, big-\\(O_p\\), small-\\(o_p\\) 덧셈 관련 내용이다.\n\nTheorem 14.4 \\(a_n&gt;0\\), \\(b_n&gt;0\\)\n\n\\(O(a_n) + O(b_n) = O(\\max \\{a_n ,b_n\\})\\)\n\\(o(a_n) + o(b_n) = o(\\max \\{a_n ,b_n\\})\\)\n\\(O_p(a_n) + O_p(b_n) = O_p(\\max \\{a_n ,b_n\\})\\)\n\\(o_p(a_n) + o_p(b_n) = o_p(\\max \\{a_n ,b_n\\})\\)\n\\(o(O(a_n)) = o(a_n)\\)\n\\(o(a_n) + O(b_n) = O(\\max \\{a_n ,b_n\\})\\)\n\\(o_p(a_n) + O_p(b_n) = O_p(\\max \\{a_n ,b_n\\})\\)\n\nYou can’t cancel because each new occurence of \\(O\\) is different \\[\nO(a_n) - O(a_n) \\neq 0,\n\\] only add and multiply and use positive rates.\n\n\n\n\n\nGarcía-Portugués, E. 2024. Notes for Nonparametric Statistics. https://bookdown.org/egarpor/NP-UC3M/.\n\n\nJiang, Jiming. 2022. Large Sample Techniques for Statistics. Springer Texts in Statistics. Springer International Publishing. https://doi.org/10.1007/978-3-030-91695-4.\n\n\nPolansky, Alan M. 2011. Introduction to Statistical Limit Theory. CRC Press.\n\n\nShumway, Robert H., and David S. Stoffer. 2017. Time Series Analysis and Its Applications. Springer-Verlag GmbH. https://www.ebook.de/de/product/28224354/robert_h_shumway_david_s_stoffer_time_series_analysis_and_its_applications.html.",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Order Notation</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "Appendix",
      "Summary"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Durrett, Rick. 2019. Probability: Theory and Examples. 5th ed.\nCambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGarcía-Portugués, E. 2024. Notes for Nonparametric Statistics.\nhttps://bookdown.org/egarpor/NP-UC3M/.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed.\nSpringer New York.\n\n\nHaigh, John. 2013. Probability Models. 2nd ed. 2013.\nSpringerLink. Dordrecht: Springer.\n\n\nHansen, Bruce. 2022. Econometrics. Princeton University Press.\n\n\nJiang, Jiming. 2022. Large Sample Techniques for Statistics.\nSpringer Texts in Statistics. Springer International\nPublishing. https://doi.org/10.1007/978-3-030-91695-4.\n\n\nNolan, John P. 2020. Univariate Stable Distributions: Models for\nHeavy Tailed Data. Springer Series in Operations Research and\nFinancial Engineering. Cham, Switzerland: Springer.\n\n\nPolansky, Alan M. 2011. Introduction to Statistical Limit\nTheory. CRC Press.\n\n\nProschan, Michael A. 2016. Essentials of Probability Theory for\nStatisticians. CRC Press.\n\n\nShumway, Robert H., and David S. Stoffer. 2017. Time Series Analysis\nand Its Applications. Springer-Verlag GmbH. https://www.ebook.de/de/product/28224354/robert_h_shumway_david_s_stoffer_time_series_analysis_and_its_applications.html.",
    "crumbs": [
      "Appendix",
      "References"
    ]
  }
]