[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Biggner’s Guide to Probability Theory",
    "section": "",
    "text": "Preface\n확률론은 통계학을 공부하는 데 있어 굉장히 중요한 과목이다. 그러므로 열심히 공부해야 한다.\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Probability Theory\n우리가 random experiement를 독립적으로, 반복적으로 수행한다고 하고 어떤 특정한 사건(event) \\(A\\)가 일어나는지 아닌지를 기록한다고 하자. \\(f_n (A)\\)를 처음 \\(n\\)개의 독립시행에서 \\(A\\)사건이 일어난 횟수라고 하고, \\(r_n (A) = f_n (A)/n\\)이라고 하자. 그러면 이 relative frequency \\(r_n (A)\\)는 \\(n\\rightarrow \\infty\\)일 때 다음과 같다고 생각하는 것이다(stabilization). \\[\nr_n(A) \\stackrel{n\\rightarrow \\infty}{\\longrightarrow} \\text{some real number.}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#probability-theory",
    "href": "intro.html#probability-theory",
    "title": "1  Introduction",
    "section": "",
    "text": "Probability models: random experiment를 묘사하는데 목적이 있음\nRandom experiment: 무작위성이 있어 미래에 일어날 결과물을 정확하게 예측할 수 없는 실험\nProbability space: 확률론의 기초가 됨, 확률공간의 키가 되는 아이디어는 stabilization of the relative frequencies임",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02_prob.html",
    "href": "02_prob.html",
    "title": "2  The Elements of Proability Theory",
    "section": "",
    "text": "2.1 Probability Triples\n다음은 콜모고로프 가 정리한 수리적 기반의 확률론이다.\nQ. 왜 probability triple이 필요한가? Single도 아니고 double도 아니고 왜 triple이어야 하는가?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "02_prob.html#probability-triples",
    "href": "02_prob.html#probability-triples",
    "title": "2  The Elements of Proability Theory",
    "section": "",
    "text": "Sample space \\(\\Omega\\) (표본공간): 이것은 any non-empty set이면 된다. 예를 들어 uniform distribution일 때 \\(\\Omega = [0,1]\\)이 있다.\n\\(\\mathcal{F}\\): \\(\\sigma\\)-algebra 또는 \\(\\sigma\\)-field: 이것은 \\(\\Omega\\)의 subset들의 collection으로 \\(\\emptyset\\), \\(\\Omega\\) 등을 포함한다.\nProbability \\(P\\): a mapping from \\(\\mathcal{F}\\) to \\([0,1]\\) with\n\n\\(P(\\emptyset)=0\\)\n\\(P(\\Omega)=1\\)\n\\(P\\) is countably additive, \\(P(A_1 \\cup A_2 \\cup \\cdots) = P(A_1) + P(A_2) + \\cdots\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "02_prob.html#field-and-sigma-field",
    "href": "02_prob.html#field-and-sigma-field",
    "title": "2  The Elements of Proability Theory",
    "section": "2.2 Field and \\(\\sigma\\)-field",
    "text": "2.2 Field and \\(\\sigma\\)-field\n\n\nDefinition 2.1 (Field) The class \\(\\mathcal{A}\\) of subsets of \\(\\Omega\\) is called a field if it contains \\(\\Omega\\) and is closed under the formulation of complements and finite unions, that is if:\n\n\\(\\Omega \\in \\mathcal{A}\\)\n\\(A\\in\\mathcal{A} \\Longrightarrow A^c \\in \\mathcal{A}\\)\n\\(A_1, A_2 \\in \\mathcal{A} \\Longrightarrow A_1 \\cup A_2 \\in \\mathcal{A}\\)\n\n\n\nDefinition 2.2 (\\(\\sigma\\)-field) The class \\(\\mathcal{F}\\) of subsets of \\(\\Omega\\) is called a \\(\\sigma\\)-field if it is a field and if it is closed under the formulation of countable unions, that is if:\n\n\\(A_1, A_2, \\ldots \\in \\mathcal{F} \\Longrightarrow \\cup_{n=1}^{\\infty} A_n \\in \\mathcal{F}\\)\n\n\n\nRecall that the elements of any field or \\(\\sigma\\)-field are called random events (or simply events).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "02_prob.html#pi-lambda-system",
    "href": "02_prob.html#pi-lambda-system",
    "title": "2  The Elements of Proability Theory",
    "section": "2.3 \\(\\pi-\\lambda\\) System",
    "text": "2.3 \\(\\pi-\\lambda\\) System\n\nSome intuition for \\(\\pi-\\lambda\\) is that you can take a finite non \\(\\pi\\)-system such as \\(S = \\{\\{1,2\\},\\{2,3\\}\\}\\), and this is not enought to guarantee uniqueness on the \\(\\sigma\\)-algebra generated by \\(S\\), which includes sets like \\(\\{2\\}, \\{1,2,3\\}\\). But, at least in the countable case, you can use the \\(\\pi\\)-system property to do disjointification/partitioning on \\(\\Omega\\), which finished the proof.\n\nLemma 2.1 (\\(\\sigma\\)-algebra and \\(\\pi\\)-\\(\\lambda\\) system) A family of sets is a \\(\\sigma\\)-algebra iff it is both \\(\\pi\\) and \\(\\lambda\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "02_prob.html#probabilities",
    "href": "02_prob.html#probabilities",
    "title": "2  The Elements of Proability Theory",
    "section": "2.4 Probabilities",
    "text": "2.4 Probabilities\n\n::: {#def-prob}\n\n2.4.1 Probability\n\nLet \\(\\Omega\\) be any set and \\(\\mathcal{A}\\) be a field of its subsets. We say that \\(P\\) is a probability on the measurable space \\((\\Omega, \\mathcal{A})\\) if \\(P\\) is defined for all events \\(A\\in\\mathcal{A}\\) and satisfies the following axioms.\n\n\n\\(P(A)\\geq 0\\) for each \\(A\\in \\mathcal{A}\\); \\(P(\\Omega)=1\\)\n\\(P\\) is finitely additive. That is, for any finite number of pairwise disjoint events \\(A_1, \\ldots, A_n \\in \\mathcal{A}\\) we have \\[\nP\\Big( \\cup_{i=1}^n A_i \\Big) = \\sum_{i=1}^n P(A_i).\n\\]\n\\(P\\) is continuous at \\(\\emptyset\\). That is, for any events \\(A_1, A_2, \\ldots, \\mathcal{A}\\) such that \\(A_{n+1} \\subset A_n\\) and \\(\\cap_{n=1}^{\\infty}A_n = \\emptyset\\), it is true that \\[\n\\lim_{n\\rightarrow \\infty}P(A_n) = 0.\n\\]\n\nNote that conditions 2 and 3 are equivalent to the next one 4.\n\n\\(P\\) is \\(\\sigma\\)-additive (countably additive), that is \\[\nP\\Big( \\cup_{n=1}^{\\infty} A_n\\Big) = \\sum_{n=1}^{\\infty}P(A_n)\n\\] for any events \\(A_1, A_2, \\ldots \\in \\mathcal{A}\\) which are pairwise disjoint.\n\n\nExample 2.1 (A probability measure which is additive but not \\(\\sigma\\)-additive) Let \\(\\Omega\\) be the set of all rational numbers \\(r\\) of the unit interval \\([0,1]\\) and \\(\\mathcal{F}_1\\) the class of the subsets of \\(\\Omega\\) of the form \\([a,b]\\), \\((a,b]\\), \\((a,b)\\) or \\([a,b)\\) where \\(a\\) and \\(b\\) are rational numbers. Denote by \\(\\mathcal{F}_2\\) the class of all finite sums of disjoint sets of \\(\\mathcal{F}_1\\). Then \\(\\mathcal{F}_2\\) is a field. Let us define the probability measure \\(P\\) as follows: \\[\\begin{align*}\nP(A) &= b-a, \\quad{} \\text{if } A \\in \\mathcal{F}_1,\\\\\nP(B) &= \\sum_{i=1}^n P(A_i), \\quad{} \\text{if } B\\in \\mathcal{F}_2, \\text{ that is, } B=\\sum_{i=1}^n A_i, A_i \\in \\mathcal{F}_1.\n\\end{align*}\\]\nConsider two disjoint sets of \\(\\mathcal{F}_2\\) say \\[\nB=\\sum_{i=1}^n A_i \\quad{} \\text{ and } B' = \\sum_{j=1}^m A_j',\n\\] where \\(A_i, A_j' \\in \\mathcal{F}_1\\) and all \\(A_i, A_j'\\) are disjoint. Then \\(B+B' = \\sum_{k=1}^{m+n}C_k\\) where either \\(C_k = A_i\\) for some \\(i=1, \\ldots, n\\), or \\(C_k = A_j'\\) for some \\(j=1, \\ldots, m\\). Moreover, \\[\\begin{align*}\nP(B+B')&= P\\Big( \\sum_k C_k \\Big) = \\sum_k P(C_k) = \\sum_{i,j}(P(A_i) + P(A_j'))\\\\\n&= P(A_i) + \\sum_{j} P(A_j') = P(B) + P(B').\n\\end{align*}\\]\nand hence \\(P\\) is an additive measure.\nObviously every one-point set \\(\\{r\\}\\in\\mathcal{F}_2\\) and \\(P(\\{r\\}) = 0\\). Since \\(\\Omega\\) is a countable set and \\(\\Omega = \\sum_{i=1}^{\\infty}\\{r_i\\}\\), we get \\[\nP(\\Omega) = 1\\neq 0 = \\sum_{i=1}^{\\infty} P(\\{r_i\\}).\n\\] This contradiction shows that \\(P\\) is not \\(\\sigma\\)-additive.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "03_rvs.html",
    "href": "03_rvs.html",
    "title": "3  Random Variables",
    "section": "",
    "text": "3.1 Random Variables",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "03_rvs.html#random-variables",
    "href": "03_rvs.html#random-variables",
    "title": "3  Random Variables",
    "section": "",
    "text": "Definition 3.1 (Random Variables) Given a probability triple \\((\\Omega, \\mathcal{F}, P)\\), a random variable is a function \\(X\\) from \\(\\Omega\\) to \\(\\mathbb{R}\\), such that \\[\n\\{ \\omega \\in \\Omega; X(\\omega) \\leq x  \\} \\in \\mathcal{F} ,\\quad{} x \\in \\mathbb{R}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "03_rvs.html#radon-nikodym-derivative",
    "href": "03_rvs.html#radon-nikodym-derivative",
    "title": "3  Random Variables",
    "section": "3.2 Radon-nikodym derivative",
    "text": "3.2 Radon-nikodym derivative\n\n\n\n\n\n\nChange of measures.\n\n\n\n\n확률측도는 volume element의 일반화라고 볼 수 있다.\n\n\\(\\mu(x)\\): probability measure, interval이나 set of points들을 인풋으로 받고 area/volume에 해당하는 확률(양수)을 아웃풋으로 주는 함수다.\n\\(\\lambda (x)\\): reference measure. We often take \\(\\lambda (x)\\) as the Lebesgue measure which is essentially just a uniform function over the sample space.\n\nThe reference measure \\(\\lambda (x)\\) is essentially just a meter-stick that allows us to express the probability measure as a simple function \\(f(x)\\). That is, we represent the probability measure \\(\\mu(x)\\) as \\(f(x)\\) by comparing the probability measure to some specified reference measure \\(\\lambda (x)\\). This is essentially the intuition that is given by the Radon-Nikodym derivative \\[\nf(x) = \\frac{d\\mu (x)}{d\\lambda (x)}\n\\] or equivalently \\[\n\\text{height = area / width.}\n\\] Note that we can also represent the same idea by \\[\n\\mu (A) = \\int_{A\\in X} f(x) d\\lambda (x),\n\\] where \\(\\mu(A)\\) is the sum of the probability of events in the set \\(A\\) which is itself a subset of the entire sample space \\(X\\). Note that when \\(A=X\\) then the integral must equal \\(1\\) by definition of probability.\n라돈-니코딤 정리는 조건부 확률에 응용된다고 함.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "03_rvs.html#integration",
    "href": "03_rvs.html#integration",
    "title": "3  Random Variables",
    "section": "3.3 Integration",
    "text": "3.3 Integration",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "03_rvs.html#리만-스틸체스-적분",
    "href": "03_rvs.html#리만-스틸체스-적분",
    "title": "3  Random Variables",
    "section": "3.4 리만-스틸체스 적분",
    "text": "3.4 리만-스틸체스 적분\n종종 헷갈리는 표현이 기댓값을 다음과 같이 분포함수를 이용해 표현하는 경우가 있다.\n\\[\nE(X) = \\int x dF(x).\n\\]\n우리가 알고 있는 정적분은 \\(x\\)축을 따라가며 함수값 f(x)가 만드는 면적을 계산한다.\n\\[\n\\int_a^b f(x) dx.\n\\]\n위 식을 더 확장하면 \\(x\\) 대신 임의의 곡선 \\(g(x)\\)를 적분 변수로 두고 \\(f(x)\\) 를 단순하게 정적분 할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x).\n\\]\n여기서 \\(dg(x)\\)는 \\(g(x)\\)의 미분소(differential)로, \\(g(x)\\)의 움직임을 결정하는 \\(x\\)는 단조 증가하거나 감소한다. 위와 같이 리만 적분을 일반화한 정적분을 리만-스틸체스 적분(Riemann-Stieltjes Integral)이라 한다. 리만 적분의 정의를 이용해 리만-스틸체스의 적분을 표현할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x) = \\lim_{N\\rightarrow \\infty} \\sum_{n=0}^{N-1} f(t_n) [g(x_{n+1}) - g(x_n)].\n\\]\n여기서 \\(x_n\\)은 정적분을 위해 구간 \\([a,b]\\)를 나눈 점, \\(t_n\\)은 닫힌 세부공간 \\([x_n, x_{n+1} ]\\)사이에 있는 임의점이다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "03_rvs.html#리만-적분과-르베그-적분",
    "href": "03_rvs.html#리만-적분과-르베그-적분",
    "title": "3  Random Variables",
    "section": "3.5 리만 적분과 르베그 적분",
    "text": "3.5 리만 적분과 르베그 적분\n여기는 Confused when changing from Lebesgue Integral to Riemann Integral 에 올라왔던 내용을 살펴보기로 한다. 여기서 질문자는 리만 적분을 어떻게 르베그 적분으로 바꾸는지에 대해 관심이 있다.\n다음과 같이 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서 정의된 음이 아닌 확률변수 \\(X\\)가 지수분포를 따른다고 하자. \\[\nP(X&lt;x) = 1-e^{-\\lambda x}.\n\\] 한편, 르베그 적분으로 \\(X\\)의 기댓값을 쓰면 다음과 같다. \\[\nE[X] = \\int_{\\{\\omega | X(\\omega) \\geq 0 \\}} X(\\omega) dP(\\omega).\n\\] 여기서 질문자는 이것을 리만 적분으로 어떻게 바꾸냐 \\[\nE[X] = \\int_0^\\infty x \\lambda e^{-\\lambda x}dx\n\\] 를 물어보고 있다.\n답변은 이것이 적분의 문제가 아닌 변수변환의 문제라고 한다.\nBy definition, given \\(X: \\Omega \\rightarrow \\mathbb{R}\\) a random variable, \\(E[X] = \\int_{\\Omega} X\\). \\(X\\) defines a measure \\(\\tilde{m}\\) in \\(\\mathbb{R}\\), called the push-forward, by \\(\\tilde{m}(A) = P(X^{-1}(A))\\). By definition, this measure is invariant under \\(X\\), and hence \\[\n\\int_{\\mathbb{R}} f d\\tilde{m} = \\int_{\\Omega} f \\circ X dP.\n\\] The equality follows from the usual arguments (prove for characteristics, simple functions, then use convergence. Recall that \\(1_A \\circ X = 1_{X^{-1}(A)}\\)).\nLet \\(h\\) be the density of \\(X\\). We then have, by definition of density, that \\(\\tilde{m}(A) = P(X^{-1}(A)) = \\int_A h dm\\) for any \\(A \\in \\mathcal{B}(\\mathbb{R})\\), where \\(m\\) is the Lebesgue measure. By change of variables, we have \\[\n\\int_{\\mathbb{R}}f d\\tilde{m} = \\int_{\\mathbb{R}} f\\cdot h dm.\n\\] Combining these equations, \\[\n\\int_{\\mathbb{R}} f \\cdot h dm =\\int_{\\Omega} f \\circ X dP.\n\\] Taking \\(f=\\text{Id}\\) yields \\[\n\\int_{\\mathbb{R}}xh(x)dx = \\int_{\\Omega} X dP = E[X].\n\\] Taking \\(f = \\text{Id} \\cdot \\mathbf{1}_{I}\\), where \\(I\\) is some interval (for example, \\((0, +\\infty)\\) as in your case), we have \\[\n\\int_{I}xh(x)dx = \\int_{X^{-1}}XdP,\n\\] recalling again that \\(\\mathbf{1}_A \\circ X = \\mathbf{1}_{X^{-1}(A)}\\). Since \\(P(X&lt;0)\\) in your case is \\(0\\), this last integral is actually equal to the integral over the whole space, and hence to \\(E[X]\\), which gives your equality.\n\nDefinition 3.2 (Integrable Random Variable) Gut (2014) 의 53쪽에 따르면, \\(E|X|&lt;\\infty\\)인 경우 random varible \\(X\\)가 integrable 하다고 부른다.\n\n\nDefinition 3.3 (\\(\\mathcal{L}^p\\)) 다음과 같은 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)를 생각하자. \\(p&gt;1\\)에 대해, 확률변수 \\(X\\)가 \\(E|X|^p &lt; \\infty\\)이면 \\(X\\in \\mathcal{L}^p\\)라고 하며 다음과 같은 놈 \\(\\|X_p\\| = (E|X|^p)^{\\frac{1}{p}}\\)를 정의할 수 있다.\n\n\n\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "conv.html",
    "href": "conv.html",
    "title": "4  Convergence",
    "section": "",
    "text": "4.1 Definitions\n다음의 정의들은 확률론에서 많이 등장하는 정의들이다. \\(X_1,X_2,\\ldots\\)를 확률변수열이라 하자.\n때때로 \\(X_n \\stackrel{\\text{d}}{\\rightarrow} \\mathcal{N}(0,1)\\)처럼 쓰기도 한다.\nDistributional convergence is often called weak convergence in these more general settings. (Gut 2014)\n다음은 Gut (2014) 의 5.8.1에 나오는 vague convergence이다. Vague convergence의 limiting random variable이 proper하지 않아도 된다는 점이 distributional convergence와의 차이점이다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#definitions",
    "href": "conv.html#definitions",
    "title": "4  Convergence",
    "section": "",
    "text": "Definition 4.1 (Almost sure convergence) 확률변수열 \\(X_n\\)은 \\[\nP\\{ \\omega: X_n (\\omega)\\rightarrow X(\\omega) \\text{ as } n\\rightarrow \\infty\\})=1\n\\] 을 만족하면 \\(X_n\\) converges almost surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.2 (Converge in Probability) 확률변수열 \\(X_n\\)이 임의의 \\(\\varepsilon&gt;0\\)에 대해 \\[\nP\\{ |X_n-X| &gt;\\varepsilon) \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in probability to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{p}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.3 (Converge in \\(r\\)-mean) 확률변수열 \\(X_n\\)가 \\[\nE|X_n - X|^r \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in \\(r-\\)mean to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.4 (Converge in Distribution) \\(C(F_X)=\\{x : F_X(x) \\text{ is continuous at }x\\}=\\text{the continuity set of }F_X\\)라 하자. 확률변수열 \\(X_n\\)가 \\[\nF_{X_n}(x) \\rightarrow F_X(x) \\text{as} \\quad{} n\\rightarrow \\infty, \\quad{} \\forall x \\in C(F_X).\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{d}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n다음과 같이 정의할 수도 있다고 한다. 확률변수열 \\(X_n\\)가 모든 \\(h\\in C_{B}\\)에 대해 \\[\nE h(X_n) \\rightarrow E h(X) \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 한다.\n이 두개의 정의가 동치라는 증명이 Gut (2014) 의 Theorem 5.6.1에 있다.\n\n\n\n\nDefinition 4.5 (Converge Weakly) 이는 (Durrett 2019) 의 3.2에 나온다. A sequence of distribution functions is said to converge weakly to a limit \\(F\\) (written \\(F_n \\Rightarrow F\\)) if \\(F_n(y) \\rightarrow F(y)\\) for all \\(y\\) that are continuity points of \\(F\\). A sequence of random variables \\(X_n\\) is said to converge weakly or converge in distribution to a limit \\(X_{\\infty}\\) (written \\(X_n \\Rightarrow X_{\\infty})\\) if their distribution functions \\(F_n (x) = P(X_n \\leq x)\\) converges weakly.\n\n\n\nDefinition 4.6 (Converge Vaguely) A sequence of distribution functions \\(\\{F_n, n\\geq 1\\}\\) converges vaguely to the pseudo-distribution function \\(H\\) if, for every finite interval \\(I=(a,b] \\subset \\mathbb{R}\\), where \\(a,b\\in C(H)\\), \\[\nF_n(I) \\rightarrow H(I) \\quad{} \\text{as} \\quad{} n \\rightarrow \\infty.\n\\] Notation: \\(F_n \\stackrel{\\text{v}}{\\rightarrow}H\\) as \\(n\\rightarrow \\infty\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#almost-sure-convergence-1",
    "href": "conv.html#almost-sure-convergence-1",
    "title": "4  Convergence",
    "section": "6.1 Almost Sure Convergence",
    "text": "6.1 Almost Sure Convergence",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-probability",
    "href": "conv.html#convergence-in-probability",
    "title": "4  Convergence",
    "section": "6.2 Convergence in Probability",
    "text": "6.2 Convergence in Probability",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-distribution",
    "href": "conv.html#convergence-in-distribution",
    "title": "4  Convergence",
    "section": "6.3 Convergence in Distribution",
    "text": "6.3 Convergence in Distribution\n\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. 5th ed. Cambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "lln.html",
    "href": "lln.html",
    "title": "5  The Law of Large Numbers",
    "section": "",
    "text": "6 Preliminaries\n제일 많이 쓰이는 기술은 truncation이라고 하는 것으로, 이 방법의 특징은 원래 확률변수열과 asymptotically equivalent 하면서 좀 더 다루기 쉬운 수열을 생각하는 것이다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#moments-and-tails",
    "href": "lln.html#moments-and-tails",
    "title": "5  The Law of Large Numbers",
    "section": "6.1 Moments and Tails",
    "text": "6.1 Moments and Tails\n\nProposition 6.1 (Moments and Tails)  \n\nLet \\(r&gt;0\\). Suppose that \\(X\\) is a non-negative random variable. Then \\[\nEX^r &lt; \\infty \\quad{}\\Longrightarrow \\quad{} x^r P(X&gt;x) \\rightarrow 0 \\quad{} \\text{as }x \\rightarrow \\infty,\n\\] but not necessarily conversely.\nSuppose that \\(X, X_1, X_2, \\ldots\\) are i.i.d. random variables with mean \\(0\\). Then, for any \\(a &gt;0\\), \\[\nEXI\\{ |X| \\leq a\\}= - EXI\\{ |X|&gt;a\\},\n\\] and \\[\n\\Big| E \\sum_{k=1}^n X_k I\\{ |X_k| \\leq a\\} \\Big|\\leq n E|X| I\\{|X|&gt;a\\}.\n\\]\nLet \\(a &gt;0\\). If \\(X\\) is a random variable with mean \\(0\\), then \\(Y=XI\\{|X|\\leq a\\}\\) does not in general havemean \\(0\\). However, if \\(X\\) is symmetric, then \\(EY=0\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Durrett, Rick. 2019. Probability: Theory and Examples. 5th ed.\nCambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed.\nSpringer New York.",
    "crumbs": [
      "References"
    ]
  }
]