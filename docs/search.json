[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Biggner’s Guide to Probability and Extremes",
    "section": "",
    "text": "Preface\n확률론은 통계학을 공부하는 데 있어 굉장히 중요한 과목이다. 그러므로 열심히 공부해야 한다.\n덤으로 극단값 이론의 기초도 수록하였다.\n최대한 제가 이해할 수 있는 수준의 내용으로 구성하였으므로, 그러므로 기초 레벨에 해당이 된다.\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Intro",
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Probability Theory\n우리가 random experiement를 독립적으로, 반복적으로 수행한다고 하고 어떤 특정한 사건(event) \\(A\\)가 일어나는지 아닌지를 기록한다고 하자. \\(f_n (A)\\)를 처음 \\(n\\)개의 독립시행에서 \\(A\\)사건이 일어난 횟수라고 하고, \\(r_n (A) = f_n (A)/n\\)이라고 하자. 그러면 이 relative frequency \\(r_n (A)\\)는 \\(n\\rightarrow \\infty\\)일 때 다음과 같다고 생각하는 것이다(stabilization). \\[\nr_n(A) \\stackrel{n\\rightarrow \\infty}{\\longrightarrow} \\text{some real number.}\n\\]",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#probability-theory",
    "href": "intro.html#probability-theory",
    "title": "1  Introduction",
    "section": "",
    "text": "Probability models: random experiment를 묘사하는데 목적이 있음\nRandom experiment: 무작위성이 있어 미래에 일어날 결과물을 정확하게 예측할 수 없는 실험\nProbability space: 확률론의 기초가 됨, 확률공간의 키가 되는 아이디어는 stabilization of the relative frequencies임",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "measure.html",
    "href": "measure.html",
    "title": "2  Measure and Integration",
    "section": "",
    "text": "2.1 Limit of sets",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#measures",
    "href": "measure.html#measures",
    "title": "2  Measure and Integration",
    "section": "2.2 Measures",
    "text": "2.2 Measures\n\n\nDefinition 2.1 (Push-forward measure)  \n\n\\((E,\\mathcal{E},\\mu)\\): measure space, \\((F, \\mathcal{F})\\): measurable space, \\(f: E\\rightarrow F\\): measurable transformation\n그러면 다음과 같은 변환 \\[\n\\mu_f (A) \\stackrel{\\Delta}{=}\\mu \\circ f^{-1}(A) = \\mu (f^{-1}(A)), \\quad{} A\\in \\mathcal{F}\n\\] 은 \\((F, \\mathcal{F})\\)에서의 measure를 정의\n\\(\\mu_f\\) (또는 \\(f^\\#\\mu\\)로 씀): push-forward measure via \\(f\\)\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\nPush-forward measure는 change-of-variables formula 등 적분이론에서 많이 쓰임",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#integration",
    "href": "measure.html#integration",
    "title": "2  Measure and Integration",
    "section": "2.3 Integration",
    "text": "2.3 Integration\n\n2.3.1 Integration notations\n\n\n\n\n\n\nRemark\n\n\n\n적분이론에서 굉장히 다양한 적분 notation을 쓰는데 알아두면 좋을 듯\n\n\n\n\n\\((E,\\mathcal{E},\\mu)\\): measure space, \\(f: E \\rightarrow\\mathbb{R}\\): a real-valued transformation\n다음의 세 개의 기호는 같은 것임\n\n\\(\\int_E f(x) d\\mu (x)\\)\n\\(\\int_E f d\\mu\\) (적분하려는 변수가 분명한 경우 생략)\n\\(\\int_E f(x) \\mu (dx)\\)\n\n\n\n\n2.3.2 리만-스틸체스 적분\n종종 헷갈리는 표현이 기댓값을 다음과 같이 분포함수를 이용해 표현하는 경우가 있다.\n\\[\nE(X) = \\int x dF(x).\n\\]\n우리가 알고 있는 정적분은 \\(x\\)축을 따라가며 함수값 f(x)가 만드는 면적을 계산한다.\n\\[\n\\int_a^b f(x) dx.\n\\]\n위 식을 더 확장하면 \\(x\\) 대신 임의의 곡선 \\(g(x)\\)를 적분 변수로 두고 \\(f(x)\\) 를 단순하게 정적분 할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x).\n\\]\n여기서 \\(dg(x)\\)는 \\(g(x)\\)의 미분소(differential)로, \\(g(x)\\)의 움직임을 결정하는 \\(x\\)는 단조 증가하거나 감소한다. 위와 같이 리만 적분을 일반화한 정적분을 리만-스틸체스 적분(Riemann-Stieltjes Integral)이라 한다. 리만 적분의 정의를 이용해 리만-스틸체스의 적분을 표현할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x) = \\lim_{N\\rightarrow \\infty} \\sum_{n=0}^{N-1} f(t_n) [g(x_{n+1}) - g(x_n)].\n\\]\n여기서 \\(x_n\\)은 정적분을 위해 구간 \\([a,b]\\)를 나눈 점, \\(t_n\\)은 닫힌 세부공간 \\([x_n, x_{n+1} ]\\)사이에 있는 임의점이다.\n\nExample 2.1 (리만-스틸체스 적분을 이용한 기댓값의 계산)  \n\n\n\\(X\\): random variable with support \\(R_X = [0,1]\\) and distribution function \\[\nF_X(x) = \\begin{cases}\n0, &\\text{if } x &lt;0\\\\\n\\frac{1}{2}x, &\\text{if } 0 \\leq x &lt; 1\\\\\n1, &\\text{if } x \\geq 1.\n\\end{cases}\n\\]\n이때의 기댓값은 \\[\n\\begin{align*}\nE[X] &= \\int_{-\\infty}^{\\infty} x dF_X(x)\\\\\n&= \\int_0^1 xdF_{X}(x) + 1\\cdot \\Big[ F_X(1) -\\lim_{x\\rightarrow 1, x &lt; 1}F_X(x) \\Big]\\\\\n&= \\int_0^1 x \\frac{d}{dx} \\Big(\\frac{1}{2}x \\Big) dx  + 1 \\cdot \\Big[ 1- \\frac{1}{2} \\Big]\\\\\n&= \\Big[\\frac{1}{4}x^2 \\Big]_{0}^1 + \\frac{1}{2} = \\frac{1}{4}+\\frac{1}{2}=\\frac{3}{4}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "measure.html#리만-적분과-르베그-적분",
    "href": "measure.html#리만-적분과-르베그-적분",
    "title": "2  Measure and Integration",
    "section": "2.4 리만 적분과 르베그 적분",
    "text": "2.4 리만 적분과 르베그 적분\n여기는 Confused when changing from Lebesgue Integral to Riemann Integral 에 올라왔던 내용을 살펴보기로 한다. 여기서 질문자는 리만 적분을 어떻게 르베그 적분으로 바꾸는지에 대해 관심이 있다.\n다음과 같이 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서 정의된 음이 아닌 확률변수 \\(X\\)가 지수분포를 따른다고 하자. \\[\nP(X&lt;x) = 1-e^{-\\lambda x}.\n\\] 한편, 르베그 적분으로 \\(X\\)의 기댓값을 쓰면 다음과 같다. \\[\nE[X] = \\int_{\\{\\omega | X(\\omega) \\geq 0 \\}} X(\\omega) dP(\\omega).\n\\] 여기서 질문자는 이것을 리만 적분으로 어떻게 바꾸냐 \\[\nE[X] = \\int_0^\\infty x \\lambda e^{-\\lambda x}dx\n\\] 를 물어보고 있다.\n답변은 이것이 적분의 문제가 아닌 변수변환의 문제라고 한다.\nBy definition, given \\(X: \\Omega \\rightarrow \\mathbb{R}\\) a random variable, \\(E[X] = \\int_{\\Omega} X\\). \\(X\\) defines a measure \\(\\tilde{m}\\) in \\(\\mathbb{R}\\), called the push-forward, by \\(\\tilde{m}(A) = P(X^{-1}(A))\\). By definition, this measure is invariant under \\(X\\), and hence \\[\n\\int_{\\mathbb{R}} f d\\tilde{m} = \\int_{\\Omega} f \\circ X dP.\n\\] The equality follows from the usual arguments (prove for characteristics, simple functions, then use convergence. Recall that \\(1_A \\circ X = 1_{X^{-1}(A)}\\)).\nLet \\(h\\) be the density of \\(X\\). We then have, by definition of density, that \\(\\tilde{m}(A) = P(X^{-1}(A)) = \\int_A h dm\\) for any \\(A \\in \\mathcal{B}(\\mathbb{R})\\), where \\(m\\) is the Lebesgue measure. By change of variables, we have \\[\n\\int_{\\mathbb{R}}f d\\tilde{m} = \\int_{\\mathbb{R}} f\\cdot h dm.\n\\] Combining these equations, \\[\n\\int_{\\mathbb{R}} f \\cdot h dm =\\int_{\\Omega} f \\circ X dP.\n\\] Taking \\(f=\\text{Id}\\) yields \\[\n\\int_{\\mathbb{R}}xh(x)dx = \\int_{\\Omega} X dP = E[X].\n\\] Taking \\(f = \\text{Id} \\cdot \\mathbf{1}_{I}\\), where \\(I\\) is some interval (for example, \\((0, +\\infty)\\) as in your case), we have \\[\n\\int_{I}xh(x)dx = \\int_{X^{-1}}XdP,\n\\] recalling again that \\(\\mathbf{1}_A \\circ X = \\mathbf{1}_{X^{-1}(A)}\\). Since \\(P(X&lt;0)\\) in your case is \\(0\\), this last integral is actually equal to the integral over the whole space, and hence to \\(E[X]\\), which gives your equality.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measure and Integration</span>"
    ]
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "3  Probabilty",
    "section": "",
    "text": "3.1 Probability Triples\n다음은 콜모고로프 가 정리한 수리적 기반의 확률론이다.\nQ. 왜 probability triple이 필요한가? Single도 아니고 double도 아니고 왜 triple이어야 하는가?",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probabilty</span>"
    ]
  },
  {
    "objectID": "prob.html#probability-triples",
    "href": "prob.html#probability-triples",
    "title": "3  Probabilty",
    "section": "",
    "text": "Sample space \\(\\Omega\\) (표본공간): 이것은 any non-empty set이면 된다. 예를 들어 uniform distribution일 때 \\(\\Omega = [0,1]\\)이 있다.\n\\(\\mathcal{F}\\): \\(\\sigma\\)-algebra 또는 \\(\\sigma\\)-field: 이것은 \\(\\Omega\\)의 subset들의 collection으로 \\(\\emptyset\\), \\(\\Omega\\) 등을 포함한다.\nProbability \\(P\\): a mapping from \\(\\mathcal{F}\\) to \\([0,1]\\) with\n\n\\(P(\\emptyset)=0\\)\n\\(P(\\Omega)=1\\)\n\\(P\\) is countably additive, \\(P(A_1 \\cup A_2 \\cup \\cdots) = P(A_1) + P(A_2) + \\cdots\\)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probabilty</span>"
    ]
  },
  {
    "objectID": "prob.html#field-and-sigma-field",
    "href": "prob.html#field-and-sigma-field",
    "title": "3  Probabilty",
    "section": "3.2 Field and \\(\\sigma\\)-field",
    "text": "3.2 Field and \\(\\sigma\\)-field\n\n\nDefinition 3.1 (Field) The class \\(\\mathcal{A}\\) of subsets of \\(\\Omega\\) is called a field if it contains \\(\\Omega\\) and is closed under the formulation of complements and finite unions, that is if:\n\n\\(\\Omega \\in \\mathcal{A}\\)\n\\(A\\in\\mathcal{A} \\Longrightarrow A^c \\in \\mathcal{A}\\)\n\\(A_1, A_2 \\in \\mathcal{A} \\Longrightarrow A_1 \\cup A_2 \\in \\mathcal{A}\\)\n\n\n\nDefinition 3.2 (\\(\\sigma\\)-field) The class \\(\\mathcal{F}\\) of subsets of \\(\\Omega\\) is called a \\(\\sigma\\)-field if it is a field and if it is closed under the formulation of countable unions, that is if:\n\n\\(A_1, A_2, \\ldots \\in \\mathcal{F} \\Longrightarrow \\cup_{n=1}^{\\infty} A_n \\in \\mathcal{F}\\)\n\n\n\nRecall that the elements of any field or \\(\\sigma\\)-field are called random events (or simply events).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probabilty</span>"
    ]
  },
  {
    "objectID": "prob.html#pi-lambda-system",
    "href": "prob.html#pi-lambda-system",
    "title": "3  Probabilty",
    "section": "3.3 \\(\\pi-\\lambda\\) System",
    "text": "3.3 \\(\\pi-\\lambda\\) System\n\nSome intuition for \\(\\pi-\\lambda\\) is that you can take a finite non \\(\\pi\\)-system such as \\(S = \\{\\{1,2\\},\\{2,3\\}\\}\\), and this is not enought to guarantee uniqueness on the \\(\\sigma\\)-algebra generated by \\(S\\), which includes sets like \\(\\{2\\}, \\{1,2,3\\}\\). But, at least in the countable case, you can use the \\(\\pi\\)-system property to do disjointification/partitioning on \\(\\Omega\\), which finished the proof.\n\nLemma 3.1 (\\(\\sigma\\)-algebra and \\(\\pi\\)-\\(\\lambda\\) system) A family of sets is a \\(\\sigma\\)-algebra iff it is both \\(\\pi\\) and \\(\\lambda\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probabilty</span>"
    ]
  },
  {
    "objectID": "prob.html#probabilities",
    "href": "prob.html#probabilities",
    "title": "3  Probabilty",
    "section": "3.4 Probabilities",
    "text": "3.4 Probabilities\n\n\nDefinition 3.3 (Probability)  \n\nLet \\(\\Omega\\) be any set and \\(\\mathcal{A}\\) be a field of its subsets. We say that \\(P\\) is a probability on the measurable space \\((\\Omega, \\mathcal{A})\\) if \\(P\\) is defined for all events \\(A\\in\\mathcal{A}\\) and satisfies the following axioms.\n\n\n\\(P(A)\\geq 0\\) for each \\(A\\in \\mathcal{A}\\); \\(P(\\Omega)=1\\)\n\\(P\\) is finitely additive. That is, for any finite number of pairwise disjoint events \\(A_1, \\ldots, A_n \\in \\mathcal{A}\\) we have \\[\nP\\Big( \\cup_{i=1}^n A_i \\Big) = \\sum_{i=1}^n P(A_i).\n\\]\n\\(P\\) is continuous at \\(\\emptyset\\). That is, for any events \\(A_1, A_2, \\ldots, \\mathcal{A}\\) such that \\(A_{n+1} \\subset A_n\\) and \\(\\cap_{n=1}^{\\infty}A_n = \\emptyset\\), it is true that \\[\n\\lim_{n\\rightarrow \\infty}P(A_n) = 0.\n\\]\n\nNote that conditions 2 and 3 are equivalent to the next one 4.\n\n\\(P\\) is \\(\\sigma\\)-additive (countably additive), that is \\[\nP\\Big( \\cup_{n=1}^{\\infty} A_n\\Big) = \\sum_{n=1}^{\\infty}P(A_n)\n\\] for any events \\(A_1, A_2, \\ldots \\in \\mathcal{A}\\) which are pairwise disjoint.\n\n\n\nExample 3.1 (A probability measure which is additive but not \\(\\sigma\\)-additive) Let \\(\\Omega\\) be the set of all rational numbers \\(r\\) of the unit interval \\([0,1]\\) and \\(\\mathcal{F}_1\\) the class of the subsets of \\(\\Omega\\) of the form \\([a,b]\\), \\((a,b]\\), \\((a,b)\\) or \\([a,b)\\) where \\(a\\) and \\(b\\) are rational numbers. Denote by \\(\\mathcal{F}_2\\) the class of all finite sums of disjoint sets of \\(\\mathcal{F}_1\\). Then \\(\\mathcal{F}_2\\) is a field. Let us define the probability measure \\(P\\) as follows: \\[\\begin{align*}\nP(A) &= b-a, \\quad{} \\text{if } A \\in \\mathcal{F}_1,\\\\\nP(B) &= \\sum_{i=1}^n P(A_i), \\quad{} \\text{if } B\\in \\mathcal{F}_2, \\text{ that is, } B=\\sum_{i=1}^n A_i, A_i \\in \\mathcal{F}_1.\n\\end{align*}\\]\nConsider two disjoint sets of \\(\\mathcal{F}_2\\) say \\[\nB=\\sum_{i=1}^n A_i \\quad{} \\text{ and } B' = \\sum_{j=1}^m A_j',\n\\] where \\(A_i, A_j' \\in \\mathcal{F}_1\\) and all \\(A_i, A_j'\\) are disjoint. Then \\(B+B' = \\sum_{k=1}^{m+n}C_k\\) where either \\(C_k = A_i\\) for some \\(i=1, \\ldots, n\\), or \\(C_k = A_j'\\) for some \\(j=1, \\ldots, m\\). Moreover, \\[\\begin{align*}\nP(B+B')&= P\\Big( \\sum_k C_k \\Big) = \\sum_k P(C_k) = \\sum_{i,j}(P(A_i) + P(A_j'))\\\\\n&= P(A_i) + \\sum_{j} P(A_j') = P(B) + P(B').\n\\end{align*}\\]\nand hence \\(P\\) is an additive measure.\nObviously every one-point set \\(\\{r\\}\\in\\mathcal{F}_2\\) and \\(P(\\{r\\}) = 0\\). Since \\(\\Omega\\) is a countable set and \\(\\Omega = \\sum_{i=1}^{\\infty}\\{r_i\\}\\), we get \\[\nP(\\Omega) = 1\\neq 0 = \\sum_{i=1}^{\\infty} P(\\{r_i\\}).\n\\] This contradiction shows that \\(P\\) is not \\(\\sigma\\)-additive.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probabilty</span>"
    ]
  },
  {
    "objectID": "rvs.html",
    "href": "rvs.html",
    "title": "4  Random Variables",
    "section": "",
    "text": "4.1 Random Variables\nQ. Random variable을 정의하는데 왜 inverse image를 쓰는가?\nCommonly a probability measure \\(P\\) is added to \\((\\Omega, \\mathcal{F})\\). Then sets like \\(\\{X \\in A\\}:= \\{\\omega \\in \\Omega | X(\\omega) \\in A\\}\\) can \\(=X^{-1}(A)\\) be measured if they belong to \\(\\mathcal{F}\\). 예를 들면 \\(X: \\Omega \\rightarrow \\mathbb{R}\\)이 확률변수일 때 \\(X&lt;1\\)일 확률을 구하려면 \\(X^{-1}(-\\infty, 1)\\)이 가측이어야 할 것이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#random-variables",
    "href": "rvs.html#random-variables",
    "title": "4  Random Variables",
    "section": "",
    "text": "Definition 4.1 (잴 수 있는 함수 (가측함수))  \n\n확률공간: \\((\\Omega, \\mathcal{F}, P)\\), \\(f: \\Omega \\rightarrow \\mathbb{R}\\) \\[\nB \\in \\mathcal{B}(\\mathbb{R}) \\Longrightarrow f^{-1}(B) \\in \\mathcal{F}\n\\] 이면 함수 \\(f\\)를 잴 수 있는 함수(measurable function)라 부름\n\n\n\nExample 4.1 (잴 수 없는 함수의 예)  \n\n표본공간 \\(\\Omega =\\{1,2,3\\}\\), 사건공간 \\(\\mathcal{F} =\\{ \\Omega, \\emptyset, \\{1,2\\},\\{3\\} \\}\\)\n이때 \\(f(1)=1, f(2)=2, f(3)=3\\)인 함수 \\(f: (\\Omega,\\mathcal{F}) \\rightarrow (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\)인 함수\n그런데 \\(\\{1\\} \\in \\mathcal{B}(\\mathbb{R})\\)이지만 \\(f^{-1}(\\{1\\}) = \\{1\\}\\notin \\mathcal{F}\\)이므로 \\(f\\)는 가측이 아니며, 따라서 확률변수가 아님\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n확률변수는 확률공간 위에서 잴 수 있는 함수임\n\n\n\n\nDefinition 4.2 (Random Variables) Given a probability triple \\((\\Omega, \\mathcal{F}, P)\\), a random variable is a function \\(X\\) from \\(\\Omega\\) to \\(\\mathbb{R}\\), such that \\[\n\\{ \\omega \\in \\Omega; X(\\omega) \\leq x  \\} \\in \\mathcal{F} ,\\quad{} x \\in \\mathbb{R}.\n\\]\n\n\n\n\n\nExample 4.2 (확률변수의 inverse image) Proschan (2016) 예제 4.2이다.\n\n\\((\\Omega, \\mathcal{F}, P) = ((0,1),\\mathbb{B}_{(0,1)}, \\mu_L)\\)에서의 확률변수 \\[\nX(\\omega) = \\frac{1}{\\omega (1-\\omega)}\n\\] 를 생각하자.\nBorel set \\(B\\)를 \\(\\{ (6.25, \\infty) \\cup \\{4\\}\\}\\)\n역상: \\(X^{-1}(B) = \\{ (0,0.2) \\cup (0.8,1) \\cup \\{0.5\\} \\} \\in \\mathcal{B}_{(0,1)}\\)\n\n\n\n\n\n\nFigure: 확률변수 \\(X\\)의 그림.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#radon-nikodym-derivative",
    "href": "rvs.html#radon-nikodym-derivative",
    "title": "4  Random Variables",
    "section": "4.2 Radon-nikodym derivative",
    "text": "4.2 Radon-nikodym derivative\n\n\n\n\n\n\nChange of measures.\n\n\n\n\n확률측도는 volume element의 일반화라고 볼 수 있다.\n\n\\(\\mu(x)\\): probability measure, interval이나 set of points들을 인풋으로 받고 area/volume에 해당하는 확률(양수)을 아웃풋으로 주는 함수다.\n\\(\\lambda (x)\\): reference measure. We often take \\(\\lambda (x)\\) as the Lebesgue measure which is essentially just a uniform function over the sample space.\n\nThe reference measure \\(\\lambda (x)\\) is essentially just a meter-stick that allows us to express the probability measure as a simple function \\(f(x)\\). That is, we represent the probability measure \\(\\mu(x)\\) as \\(f(x)\\) by comparing the probability measure to some specified reference measure \\(\\lambda (x)\\). This is essentially the intuition that is given by the Radon-Nikodym derivative \\[\nf(x) = \\frac{d\\mu (x)}{d\\lambda (x)}\n\\] or equivalently \\[\n\\text{height = area / width.}\n\\] Note that we can also represent the same idea by \\[\n\\mu (A) = \\int_{A\\in X} f(x) d\\lambda (x),\n\\] where \\(\\mu(A)\\) is the sum of the probability of events in the set \\(A\\) which is itself a subset of the entire sample space \\(X\\). Note that when \\(A=X\\) then the integral must equal \\(1\\) by definition of probability.\n라돈-니코딤 정리는 조건부 확률에 응용된다고 함.\n\nDefinition 4.3 (Integrable Random Variable) Gut (2014) 의 53쪽에 따르면, \\(E|X|&lt;\\infty\\)인 경우 random variable \\(X\\)가 integrable 하다고 부른다.\n\n\n\nExample 4.3 Given a probability measure \\(P\\) and sample space \\(\\Omega\\), it is true that \\[\n\\int_{\\Omega} dP = 1.\n\\] Because \\[\n\\int_{\\Omega} dP = P(\\Omega) = 1.\n\\] More generally \\[\n\\int_A dP = \\int_{\\Omega} 1_A dP = P(A), \\quad{} A \\in \\mathcal{F}.\n\\]\n\n\nDefinition 4.4 (\\(\\mathcal{L}^p\\)) 다음과 같은 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)를 생각하자. \\(p&gt;1\\)에 대해, 확률변수 \\(X\\)가 \\(E|X|^p &lt; \\infty\\)이면 \\(X\\in \\mathcal{L}^p\\)라고 하며 다음과 같은 놈 \\(\\|X_p\\| = (E|X|^p)^{\\frac{1}{p}}\\)를 정의할 수 있다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#distribution",
    "href": "rvs.html#distribution",
    "title": "4  Random Variables",
    "section": "4.3 Distribution",
    "text": "4.3 Distribution\n\n\n확률변수의 정의는 임의의 measurable subset of possible outcomes (points, bounded/unbounded intervals 등)에 measure (확률)를 부여할 수 있어야 함\nSemi-infinite interval \\((-\\infty, x]\\) 또한 이러한 measurable subset이므로 \\(\\mathbb{R}\\)에서 정의된 모든 확률변수는 CDF를 갖음\nPDF는 CDF의 도함수 개념이므로 CDF가 미분가능해야 전역적으로 PDF도 존재",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#expectation",
    "href": "rvs.html#expectation",
    "title": "4  Random Variables",
    "section": "4.4 Expectation",
    "text": "4.4 Expectation\n\n\nExpectation: integral with respect to the probability measure\n\n\nDefinition 4.5 (Expectation)  \n\n\\((\\Omega, \\mathcal{A}, \\mathbb{P})\\): Probability space\n\n\\(\\Omega\\): set (sample space)\n\\(\\mathcal{A}\\): \\(\\sigma\\)-algebra on \\(\\Omega\\)\n\\(\\mathbb{P}\\): Probability measure\n\n\\(X: \\Omega \\rightarrow \\mathbb{R}\\): Random variable (a measurable fct)\nExpectation: The concept of integral of \\(X\\) w.r.t. \\(\\mathbb{P}\\) \\[\nE[X] \\stackrel{\\Delta}{=}\\int_{\\Omega} X(\\omega) d\\mathbb{P}[\\omega]\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n다음의 notation들은 모두 \\(X\\)의 기댓값을 의미\n\n\\(\\int_{\\Omega} X(\\omega) d\\mathbb{P}[\\omega]\\)\n\\(\\int_{\\Omega} X d\\mathbb{P}\\) (적분하려는 변수가 분명한 경우 생략)\n\\(\\int_{\\Omega} X(\\omega) \\mathbb{P}[d\\omega]\\)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#cantor-random-variable",
    "href": "rvs.html#cantor-random-variable",
    "title": "4  Random Variables",
    "section": "4.5 Cantor Random Variable",
    "text": "4.5 Cantor Random Variable\n\nCantor distribution: 누적분포함수가 Cantor function인 probability distribution\nCantor distribution은 PDF나 PMF가 존재하지 않음\n동전던지기를 할 때, \\(n\\)번째 던지기에서 앞면이 나왔을 때 \\(\\frac{2}{3^n}\\)을 갖는 실험을 하면, 최종적으로 \\(X\\) 달러를 받는다고 할 때, \\(X\\)는 확률변수이며 Cantor distribution의 예가 됨\n특별히 \\(\\{\\xi_n\\}\\)을 i.i.d. Bernoulli라 할 때 칸토르 확률변수 \\(X\\)를 \\(X=\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\xi_n\\)과 같이 놓을 수 있음 (위의 예제 참고)\n\n\n\n칸토를 집합을 \\(C\\)라 하고, \\(X\\in C\\)라 할 때, 칸트로 집합이 Lebesgue measure 0 임을 알고 있으며, \\(P(X\\in C)=1&gt;0\\)이므로 \\(X\\)는 not absolutely continuous with respect to the Lebesgue measure임\n\n\nExample 4.4 (Cantor distribution의 적률 계산)  \n\n\nPDF나 PMF가 존재하지 않더라도 Cantor distribution 같이 음이 아닌 확률변수에서는 \\(F(x) = P(X&gt;x)\\)를 계산할 수 있고, 이를 이용해 \\[\n\\begin{align*}\nE(X) &= \\int_0^{\\infty} F(x) dx\\\\\n\\text{Var} (X) &= \\int_0^{\\infty} 2x F(x) dx - \\Big( \\int_0^{\\infty}F(x) dx \\Big)^2\n\\end{align*}\n\\] 와 같이 기댓값과 분산을 구할 수 있음\n특별히 \\(\\{\\xi_n\\}\\)을 i.i.d. Bernoulli라 할 때 칸토르 확률변수 \\(X\\)를 \\(X=\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\xi_n\\)과 같이 놓을 수 있고 (앞선 동전던지기 참고) \\(E(\\xi_n)=\\frac{1}{2}\\), \\(\\text{Var}(\\xi_n) = \\frac{1}{4}\\)라는 점을 이용해 다음과 같이 구할 수 있음 \\[\n\\begin{align*}\nE(X) &= \\sum_{n=1}^{\\infty} E\\Big( \\frac{2}{3^n} \\xi_n \\Big)= \\sum_{n=1}^{\\infty}  \\frac{2}{3^n} E(\\xi_n)\\\\&= \\sum_{n=1}^{\\infty} \\frac{2}{3^n }\\cdot \\frac{1}{2}= \\sum_{n=1}^{\\infty} \\frac{1}{3^n} = \\frac{1}{2}\\\\\n\\text{Var}(X) &= \\sum_{n=1}^{\\infty} \\text{Var}\\Big( \\frac{2}{3^n} \\xi_n \\Big)= \\sum_{n=1}^{\\infty}  \\Big(\\frac{2}{3^n}\\Big)^2 \\text{Var}(\\xi_n)\\\\&= \\sum_{n=1}^{\\infty} \\frac{4}{9^n }\\cdot \\frac{1}{4}= \\sum_{n=1}^{\\infty} \\frac{1}{9^n} = \\frac{1}{8}.\n\\end{align*}\n\\]\n\n\n\n\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.\n\n\nProschan, Michael A. 2016. Essentials of Probability Theory for Statisticians. CRC Press.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "ineq.html",
    "href": "ineq.html",
    "title": "5  Probability Inequalities",
    "section": "",
    "text": "5.1 왜 concentration inequality가 필요한가?\nFigure: CLT 묘사.\nQ. \\(N\\)번 시행 시 \\(\\frac{3}{4}\\)이상 앞면이 나올 확률을 구하고 싶다.\nFigure: Berry-Essen bound와 empirical difference.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#왜-concentration-inequality가-필요한가",
    "href": "ineq.html#왜-concentration-inequality가-필요한가",
    "title": "5  Probability Inequalities",
    "section": "",
    "text": "출처: Concentration Inequalities\n\n\n\nHigh-Dimensional Probability 책에 있는 동전 던지기 예제 생각\n\\(i\\)번째 동전던지기: 앞면이 나오면 1, 뒷면이 나오면 0인 Bernoulli random variable로 간주 가능\n\\(N\\)번 던졌을 때 나온 앞면의 수: \\(S_N = \\sum_i X_i\\)\nde Moivre-Laplace theorem (Binomial의 CLT) \\[\nZ_N \\stackrel{D}{\\rightarrow}\\mathcal{N}(0,1)\n\\] 이때 \\[\nZ_N  = \\frac{S_N - N_p}{\\sqrt{Np (1-p)}}\n\\]\n\n\n\n\nGaussian density는 exponential decay하는데, \\(Z_N\\)이 분포수렴하는 속도는 훨씬 느림\nCLT의 quantitative version인 Berry-Essen CLT를 보면 \\[\n|P\\{Z_n \\geq t\\} - P\\{Z \\geq t\\} | \\leq \\frac{C}{\\sqrt{N}}\n\\] 이때 \\(C\\)는 상수이며, convergence의 order가 \\(\\frac{1}{\\sqrt{N}}\\)임을 (아래 그림에 녹색으로 표시) 확인 가능",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#markov-inequality",
    "href": "ineq.html#markov-inequality",
    "title": "5  Probability Inequalities",
    "section": "5.2 Markov inequality",
    "text": "5.2 Markov inequality\n\nTheorem 5.1 (Markov inequality) 음이 아는 확률변수 \\(X\\)에 대해 \\[\nP\\{ X\\geq t\\} \\leq \\frac{E[X]}{t}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n확률공간 \\((\\Omega, \\Sigma, P)\\)을 생각하자. \\[\nEX = \\int X dP \\geq \\int_{\\{X\\geq t\\}} X dP \\geq t \\int_{\\{X\\geq t \\}}dP \\geq t\\cdot P\\{ X\\geq t\\}\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n마르코프 bound는 매우 약한 (즉 true probabilty로의 수렴이 느린) bound\n그러나 \\(X\\)에 대한 제약조건이 없음 (기댓값 계산 필요, 음이 아닌 확률변수)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#chebyshev-inequality",
    "href": "ineq.html#chebyshev-inequality",
    "title": "5  Probability Inequalities",
    "section": "5.3 Chebyshev inequality",
    "text": "5.3 Chebyshev inequality\n\nTheorem 5.2 (Chebyshev inequality) 어떤 확률변수 \\(X\\)에 대해 \\[\nP\\{|X-E(X)|\\geq t \\}\\leq \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(|X-E(X)|\\geq t\\)를 제곱한 후 마르코프 부등식을 적용 \\[\nP\\{ |X-E(X)|^2 \\geq t^2\\} \\leq \\frac{E[(X-E(X))]^2}{t^2} = \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n체비세프 부등식을 쓰려면 분산이 정의되어야 함",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#hoeffdings-inequality",
    "href": "ineq.html#hoeffdings-inequality",
    "title": "5  Probability Inequalities",
    "section": "5.4 Hoeffding’s Inequality",
    "text": "5.4 Hoeffding’s Inequality\n\n(드디어) \\(\\sum_i X_i\\)에 대한 exponential bound를 줌\n그러나 독립 가정이 필요\n단순한 케이스로 먼저 \\(X_1, \\ldots, X_N\\)이 symmetric Bernoulli라고 하자. 이는 즉 반반의 확률로 1 또는 -1을 갖는 확률변수\n\n\nTheorem 5.3 (Symmetric Bernoulli에서의 Hoeffding’s inequality) \\(X_1, \\ldots, X_N\\)이 symmetric Bernoulli 확률변수라고 하자. 어떤 \\(t\\geq 0\\)에 대해 \\(a \\in \\mathbb{R}^n\\)이 존재해 \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq \\exp \\Big( - \\frac{t^2}{2\\|a\\|^2} \\Big)\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n마르코프 부등식을 적용하면 다음과 같다. \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} = P \\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\geq e^{\\lambda t} \\} \\leq e^{-\\lambda t}E\\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\}\n\\] 독립성에 의해 다음과 같다. \\[\nE\\{ \\exp (\\lambda \\sum_{i=1}^N a_i X_i) \\} = E \\{ \\prod_{i=1}^N \\exp (\\lambda a_i X_i)  \\} = \\prod_{i=1}^N E\\{ \\exp (\\lambda a_i X_i)\\}\n\\] \\(X_i\\)를 \\(1/2\\)의 확률로 -1과 1을 갖는 확률변수라고 제한했으므로, 위의 기댓값을 쉽게 구할 수 있다. \\[\nE\\{ \\exp (\\lambda a_i X_i)\\} = \\frac{e^{\\lambda a_i }+ e^{-\\lambda a_i}}{2}\\leq e^{\\lambda^2 a_i^2 / 2}\n\\] 지수함수의 테일러 급수 전개를 이용하면 \\[\ne^{x}=\\sum_{k=0}^{\\infty}\\frac{x^k}{k!},\\quad{} \\frac{e^{x}+e^{-x}}{2} =\\sum_{k=0}^{\\infty}\\frac{x^{2k}}{(2k)!}, \\quad{} e^{x^2/2}=\\sum_{k=0}^{\\infty}\\frac{x^{2k}}{2^k k!},\\quad{} \\Longrightarrow\\quad{} \\frac{e^{x}+e^{-x}}{2} \\leq e^{x^2/2}.\n\\] \\(\\|a\\|^2=1\\)이라 두고 위의 결과를 대입해보자. \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq e^{-\\lambda t}(\\prod_{i=1}^N e^{\\lambda^2 a_i^2/2})\\leq e^{-\\lambda t}(e^{\\lambda^2 \\sum_{i=1}^N a_i^2/2}) = e^{-\\lambda t}(e^{\\lambda^2/2}) = e^{\\lambda^2/2 - \\lambda t}.\n\\] 위의 부등식은 모든 \\(\\lambda\\)에 대해 성립하고, \\(\\lambda=t\\)일 때 최소화된다. 따라서 \\[\nP\\{ \\sum_{i=1}^N a_i X_i \\geq t \\} \\leq e^{-t^2/2}.\n\\] 따라서, homogeneity에 의해 \\(\\|a\\|=1\\)을 가정하면 다음과 같다. \\[\nP \\{ \\sum_{i=1}^N \\frac{a_i}{\\| a\\|}X_i \\geq \\frac{t}{\\|a\\|} \\} \\leq e^{-\\frac{t^2}{2\\|a\\|^2}}.\n\\]\n\n\n\n\\(X_i\\)가 1 또는 0을 갖는 베르누이 확률변수라고 할 때, \\(Y_i = 2(X_i - \\frac{1}{2})\\)로 놓으면 \\(Y_i\\)는 symmetric Bernoulli 확률변수임 \\[\nP\\{ \\sum_i X_i &gt; t\\} = P \\{ \\sum_i (\\frac{Y_i}{2}+ \\frac{1}{2}) &gt; t \\} = P\\{\\sum_i Y_i &gt; 2t - N \\} \\leq \\exp (-\\frac{(2t-N)^2}{2N})\n\\] 여기서 \\(a=\\begin{bmatrix} 1,1,\\ldots, 1 \\end{bmatrix}\\)로 두면 \\(\\|a\\|_2^2=N\\)이 된다. 따라서 \\[\nP\\{\\sum_i X_i &gt; \\frac{3N}{4} \\}\\leq \\exp (- \\frac{(\\frac{3N}{2}-N)^2}{2N}) = \\exp (-\\frac{N}{8})\n\\]\n\n\n\n\n\nFigure: Chebyshev와 Hoeffding bound의 비교.\n\n\n\n\n\nTheorem 5.4 (Hoeffding’s inequality) \\(X_1, \\ldots, X_N\\)이 독립인 확률변수이고, \\(X_i \\in [m_i, M_i]\\) almost surely라고 하자. 그러면 어떤 \\(t&gt;0\\)에 대해 \\[\nP \\{\\sum_{i=1}^N (X_i - E(X_i))\\geq t \\} \\leq \\exp (- \\frac{2t^2}{\\sum_{i=1}^N (M_i - m_i)^2})\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n앞에서처럼 \\(\\lambda\\)를 곱하고 제곱근을 취한 다음 마르코프 부등식을 이용한다 \\[\n\\begin{align*}\nP\\{\\sum (X_i - E(X_i)) \\geq t \\} &= P \\{\\exp (\\lambda \\sum (X_i - E(X_i)))\\geq e^{\\lambda t} \\}\\\\\n&\\leq E \\{\\exp (\\lambda \\sum (X_i - E(X_i)))\\} e^{-\\lambda t}\\\\\n&= \\prod_i E\\{\\exp (\\lambda (X_i - E(X_i))) \\}e^{-\\lambda t}.\n\\end{align*}\n\\] 그러면 기댓값의 bound만 찾아주면 된다. 여기서는 \\(X_i\\)와 독립인 copy인 \\(X_i'\\)를 생각하는 symmetrization 기법을 이용한다. \\[\n\\begin{align*}\nE\\{\\exp (\\lambda \\sum (X_i - E(X_i)) ) \\} &= E\\{\\exp (\\lambda \\sum (X_i - E(X_i')) ) \\} \\\\\n&= E_{X_i} \\{ \\exp (E_{X_i'} \\lambda \\sum (X_i - X_i')) \\}\\\\\n&\\leq E_{X_i} E_{X_i'} \\{ \\exp (\\lambda \\sum (X_i - X_i')) \\}\\\\\n&= E\\{ \\exp (\\lambda \\sum (X_i - X_i')) \\}.\n\\end{align*}\n\\] 여기서 exponential이 convex이므로 Jensen의 부등식을 적용하였다. 여기서 \\(X_i - X_i'\\)는 0 근처에서 symmetric이고 이것의 분포는 \\(S(X_i - X_i')\\)와 같다. 이때 \\(S\\)는 -1, 1을 동일한 확률로 갖는 Rademacher variable이다. \\[\n\\begin{align*}\nE\\{\\exp (\\lambda \\sum (X_i - E(X_i)) ) \\} &\\leq E_{X_i,X_i'} \\{ E_S \\exp (\\lambda \\sum S(X_i - X_i')) \\}\\\\\n&\\leq E_{X_i,X_i'} \\{ \\exp (\\lambda^2 (X_i - X_i')^2/2) \\}\\\\\n&\\leq \\exp (\\lambda^2 (M_i - m_i)^2/2).\n\\end{align*}\n\\] 이때 첫 번째 부등식은 exponential의 테일러 전개를, 두 번째 부등식은 \\(X_i\\)의 boundedness를 이용하였다. \\[\n\\begin{align*}\nP\\{\\sum (X_i - E(X_i)) \\geq t \\} &=  \\prod_i E\\{\\exp (\\lambda (X_i - E(X_i))) \\}e^{-\\lambda t}\\\\\n&= \\prod_i \\exp (\\lambda^2 (M_i - m_i)^2/2)e^{-\\lambda t}\\\\\n&= \\exp (\\lambda^2 \\sum_i (M_i - m_i)^2/2 -\\lambda t)\\\\\n&\\leq \\exp (\\frac{2t^2}{\\sum_i (M_i -m_i)^2}).\n\\end{align*}\n\\] 여기서 마지막 부등식은 exponent를 최소화하는 \\(\\lambda\\)를 잡았다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#chernoff-bounds",
    "href": "ineq.html#chernoff-bounds",
    "title": "5  Probability Inequalities",
    "section": "5.5 Chernoff Bounds",
    "text": "5.5 Chernoff Bounds\n\n베르누이 확률변수에 대한 Hoeffding bound는 \\(p=0.5\\)일 때에는 잘 작동하지만, 작거나 큰 \\(p\\)에 대해서는 잘 작동하지 않음\n\\(X_i \\sim \\text{Bernoulli}(p)\\)라고 하고 \\(S_N = \\sum_{i=1}^N X_i\\)라고 두자. 그리고 Hoeffding의 부등식을 이용하여 \\(S_N &gt; 10pN\\)의 bound를 구해보자. \\[\nP \\{ \\sum_i X_i &gt; 10pN \\} = P\\{ \\sum_i X_i - pN &gt; 9pN \\}\\leq \\exp (-\\frac{2(9pN)^2}{N}) = \\exp (-182p^2 N).\n\\] 식을 보면 Binomial random variable이 평균보다 9배 클 확률의 bound를 계산함\n\n\n\nTheorem 5.5 (Chernoff inequality) \\(X_1, \\ldots, X_N\\)이 모수 \\(p_i\\)를 갖는 독립인 베르누이 확률변수라 하자. \\(S_N = \\sum_i X_i\\)이고 \\(\\mu = E(S_N)\\)이라고 하자. 그러면 \\(t&gt;\\mu\\)에 대해 \\[\nP \\{ S_N \\geq t \\} \\leq \\exp (-\\mu) \\Big( \\frac{e\\mu}{t} \\Big)^t.\n\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n다시 \\(\\lambda\\)를 곱하고 마르코프 부등식을 적용하자. \\[\nP\\{ S_N \\geq t \\} \\leq E\\{ \\exp (\\lambda \\sum_{i} X_i) \\}e^{-\\lambda t} = \\prod_i E\\{ \\exp (\\lambda X_i) \\}e^{-\\lambda t}.\n\\] \\(1+x \\leq e^{x}\\)라는 부등식을 이용하면 다음과 같다. \\[\nP\\{ S_N \\geq t \\} \\leq  e^{\\lambda}p_i + (1-p_i) = 1 + (e^{\\lambda} - 1)p_i \\leq \\exp (p_i (e^\\lambda - 1)).\n\\] 이것을 정리하면 다음과 같다. \\[\n\\begin{align*}\nP\\{ S_N \\geq t \\} &\\leq \\prod_i \\exp (p_i (e^\\lambda -1))e^{-\\lambda t}\\\\\n&\\leq \\exp \\Big( (e^\\lambda - 1)\\sum_i p_i \\Big) e^{-\\lambda t}\\\\\n&\\leq \\exp ((e^{\\lambda}-1)\\mu) e^{-\\lambda t}.\n\\end{align*}\n\\] 여기서 \\(\\lambda\\)를 고를 수 있는데, \\(\\lambda = \\log (t/mu)\\)로 잡으면 다음과 같다. \\[\n\\begin{align*}\nP\\{ S_N \\geq t \\} &\\leq \\exp \\Big( (\\frac{t}{\\mu}-1)\\mu \\Big) \\Big( \\frac{\\mu}{t} \\Big)^t\\\\\n&= \\exp (t-\\mu) \\Big( \\frac{\\mu}{t} \\Big)^t\\\\\n&=\\exp (-\\mu) \\Big( \\frac{e\\mu}{t} \\Big)^t.\n\\end{align*}\n\\]\n\n\n\n\n다시 앞 예제에 Chernoff 부등식을 적용하면 \\[\nP \\{\\sum_i X_i &gt; 10pN \\} \\leq \\exp (-p N) \\Big( \\frac{epN}{10pN}\\Big)^{10pN} = \\exp (-p N) \\Big( \\frac{e}{10}\\Big)^{10pN}.\n\\]\n\n\n\n\n\n\nFigure: Hoeffding과 Chernoff bound의 비교.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#gaussian-tails-and-mgf",
    "href": "ineq.html#gaussian-tails-and-mgf",
    "title": "5  Probability Inequalities",
    "section": "5.6 Gaussian tails and MGF",
    "text": "5.6 Gaussian tails and MGF\n\n출처: High-Dimensional Statistics Lecture Notes\n\\(X\\)가 Gaussian일 때 pdf \\[\np(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\Big( - \\frac{(x-\\mu)^2}{2\\sigma^2} \\Big), \\quad{} x \\in \\mathbb{R}\n\\]\nBounded support: \\(P(|X-\\mu|\\leq 3\\sigma)\\) 등의 확률 구할 때 사용\n\n\nProposition 5.1 (Gaussian의 tail probability) \\(X\\sim \\mathcal{N}(\\mu, \\sigma^2)\\)일 때 \\(t&gt;0\\)에 대해 \\[\nP(|X-\\mu | &gt;t) \\leq \\sqrt{\\frac{2}{\\pi}}\\frac{e^{-\\frac{t^2}{2\\sigma^2}}}{t}.\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#sub-gaussian",
    "href": "ineq.html#sub-gaussian",
    "title": "5  Probability Inequalities",
    "section": "5.7 Sub-Gaussian",
    "text": "5.7 Sub-Gaussian\n\n출처: Concentration Inequalities\n앞서 Chernoff appraoch로 얻어지는 tail bound의 form은 MGF의 growth rate에 depend됨을 암\n따라서 tail bound study에서는 확률변수들을 MGF에 따라 분류하는 것이 자연스러운 생각\n\n\nDefinition 5.1 (Sub-Gaussian) 어떤 확률변수 \\(X\\in \\mathbb{R}\\)이 \\(E(X)=0\\)이고 이것의 MGF가 \\[\nE[\\exp (sX)] \\leq \\exp \\Big( \\frac{\\sigma^2 s^2}{2} \\Big), \\forall s \\in \\mathbb{R}\n\\] 일 때 \\(X \\sim \\text{subG}(\\sigma^2)\\)이라고 한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\nSub-Gaussian random variable은 클래스가 큼",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#sub-exponential",
    "href": "ineq.html#sub-exponential",
    "title": "5  Probability Inequalities",
    "section": "5.8 Sub-Exponential",
    "text": "5.8 Sub-Exponential\n\n\\(X\\sim \\text{Lap}(1)\\)과 같이 \\[\nP(|X|&gt;t)=e^{-t},\\quad{} t\\geq 0\n\\] Gaussian보다 꼬리가 두꺼운 경우는 어떻할 것인가?\nLaplace의 MGF: \\[\nE[e^{sX}] = \\frac{1}{1-s^2},\\quad{} \\text{if } |s|&lt;1.\n\\]\n\n\nDefinition 5.2 (Sub-Exponential) 어떤 확률변수 \\(X\\in \\mathbb{R}\\)이 \\(E(X)=0\\)이고 이것의 MGF가 \\[\nE[e^{sX}] \\leq e^{s^2 \\lambda^2 / 2}, \\quad{} \\forall |s| \\leq \\frac{1}{\\lambda}\n\\] 일 때 \\(X \\sim \\text{subE}(\\lambda)\\)라고 한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "ineq.html#bernsteins-inequality",
    "href": "ineq.html#bernsteins-inequality",
    "title": "5  Probability Inequalities",
    "section": "5.9 Bernstein’s inequality",
    "text": "5.9 Bernstein’s inequality\n\nTheorem 5.6 (Berstein’s inequality) 어떤 확률변수 \\(X_1, \\ldots, X_n\\)이 독립이고 \\(E(X_i) = 0\\)이며 \\(X_i \\sim \\text{subE}(\\lambda)\\)인 확률변수라고 하자. 그러면 \\(t&gt;0\\)에 대해 \\[\nP(\\overline{X} &gt;t) \\vee P(\\overline{X} &lt; -t) \\leq \\exp \\Big[ - \\frac{n}{2}\\Big(\\frac{t^2}{\\lambda^2}\\wedge \\frac{t}{\\lambda} \\Big) \\Big] .\n\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability Inequalities</span>"
    ]
  },
  {
    "objectID": "conv.html",
    "href": "conv.html",
    "title": "6  Convergence",
    "section": "",
    "text": "6.1 Definitions\n다음의 정의들은 확률론에서 많이 등장하는 정의들이다. \\(X_1,X_2,\\ldots\\)를 확률변수열이라 하자.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#almost-sure-convergence",
    "href": "conv.html#almost-sure-convergence",
    "title": "6  Convergence",
    "section": "6.2 Almost Sure Convergence",
    "text": "6.2 Almost Sure Convergence\n\n\nDefinition 6.1 (Sure convergence (틀림없는 수렴)) 확률변수열 \\(X_n\\)이 표본공간 안에 어떤 점 \\(\\omega\\)를 잡아도 \\[\n\\lim_{n\\rightarrow\\infty} X_n (\\omega) = X(\\omega)\n\\] 을 만족하면 \\(X_n\\) converges surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{s}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 6.2 (Almost sure convergence (거의 틀림없는 수렴)) 확률변수열 \\(X_n\\)은 \\[\nP\\{ \\omega: X_n (\\omega)\\rightarrow X(\\omega) \\text{ as } n\\rightarrow \\infty\\})=1\n\\] 을 만족하면 \\(X_n\\) converges almost surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n거의 틀림없이 수렴하는 확률변수 \\(\\{ X_n (\\omega)\\}\\)에서는 \\(P(\\tilde{\\Omega})=1\\)이고 \\(\\tilde{\\Omega} \\subseteq \\Omega\\)일 때 \\(\\omega \\in \\tilde{\\Omega}\\)를 어떻게 고르더라도 \\(\\lim_{n\\rightarrow \\infty} X_n (\\omega) = X(\\omega)\\)임\n다만, \\(\\omega \\notin \\tilde{\\Omega}\\)인 수열 \\(\\{ X_n (\\omega)\\}\\)는 수렴하지 않을 수는 있지만, \\(P\\{ \\omega: \\omega \\notin \\tilde{\\Omega}, \\omega \\in \\Omega\\} = 0\\)임\n\\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}0\\)은 \\(0\\)보다 큰 수 \\(\\varepsilon\\)을 어떻게 잡더라도 \\(P\\{ |X_n| \\geq \\varepsilon\\} =0\\)이라는 것과 필요충분조건임\n\n\n\n\nExample 6.1 (거의 틀림없는 수렴 예제)  \n\n구간 \\([0,1]\\)에서 아무렇게나 한 점을 골라서 \\(\\omega\\)라 하고, \\(\\omega\\)가 \\([0,1]\\)의 어느 부분 구간에 들어갈 확률은 그 부분 구간의 길이와 같다고 가정\n\n\n\n\n\n\n\n\n\n\n\n\\(A_n(\\omega)\\)\n\\(B_n(\\omega)\\)\n\\(C_n(\\omega)\\)\n\\(D_n(\\omega)\\)\n\\(H_n(\\omega)\\)\n\n\n\n\n\\(\\frac{\\omega}{n}\\)\n\\(\\omega (1-\\frac{1}{n})\\)\n\\(\\omega e^n\\)\n\\(\\cos 2\\pi n \\omega\\)\n\\(\\exp \\{ -n (n\\omega -1) \\}\\)\n\n\n\n\n\\(A_n(\\omega)\\)는 \\(\\omega\\)가 어떤 값이더라도 늘 0에 수렴하므로 틀림없이 0에 수렴\n\\(B_n(\\omega)\\)는 \\(\\omega\\)가 어떤 값이더라도 \\(\\omega\\)에 수렴하므로 틀림없이 \\(\\omega\\)에 수렴하며, 그 극한 분포는 \\(U[0,1]\\)\n\\(C_n (\\omega)\\)는 \\(\\omega =0\\)이면 0에 수렴하고, \\(\\omega \\in (0,1]\\)이면 발산, 즉 \\(C_n (\\omega)\\)는 수렴하지 않음\n\\(D_n (\\omega)\\)는 \\(\\omega \\in \\{0,1\\}\\)이면 1에 수렴하고, \\(\\omega \\in (0,1)\\)이면 -1과 1 사이에서 진동, 즉 \\(D_n (\\omega)\\)는 수렴하지 않음\n\\(\\omega=0\\)이면 \\(H_n (0) = e^n \\rightarrow \\infty\\)이고 \\(\\omega \\in (0,1]\\)이면 \\(H_n  (\\omega) \\rightarrow 0\\)이므로 \\(H_n (\\omega)\\)는 틀림없이 수렴하지는 않지만, \\(P\\{\\omega &gt;0\\}=1\\)이므로 \\(H_n (\\omega)\\)는 거의 틀림 없이 0으로 수렴\n\n\n\nExample 6.2 (보렐-칸텔리 정리와 거의 어디서나 수렴)  \n\n(\\(\\Longrightarrow\\)) 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)는 \\(\\varepsilon&gt;0\\)일 때 \\[\n\\sum_{n=1}^\\infty P\\{ |X_n | &gt; \\varepsilon\\} &lt; \\infty\n\\] 이면 보렐-칸텔리 정리를 써서 \\(n\\rightarrow \\infty\\)일 때 \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow} 0\\)이라는 것을 알 수 있음\n(\\(\\Longleftarrow\\)) \\(\\omega\\)의 분포가 \\([0,1]\\)에서 고르고 \\[\nX_n (\\omega)=\n\\begin{cases}\n0, & 0 \\leq \\omega \\leq 1-\\frac{1}{n},\\\\\n1, & 1- \\frac{1}{n}&lt; \\omega \\leq 1\n\\end{cases}\n\\] 인 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)는 \\(n\\rightarrow \\infty\\)일 때, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}0\\)이다. 그러나 \\(\\varepsilon_n \\downarrow 0\\)인 \\(\\varepsilon_n\\)을 어떻게 잡더라도 \\(n\\)이 충분히 크면 \\(P\\{ |X_n| &gt; \\varepsilon_n \\} = P\\{ X_n = 1\\}= \\frac{1}{n}\\)이므로 \\(\\sum_{n=1}^{\\infty}P\\{ |X_n| &gt; \\varepsilon_n\\}\\rightarrow \\infty\\)이다. 그러므로 앞서 조건은 거의 틀림없이 수렴하는 충분조건이나 필요조건은 아니다.\n\n\n\nTheorem 6.1 (Almost sure convergence와 동치조건) 확률변수 열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)가 \\(X_n \\stackrel{\\text{a.s}}{\\rightarrow}X\\)이면 0보다 큰 수 \\(\\varepsilon\\)을 어떻게 고르더라도 \\[\n\\lim_{n\\rightarrow\\infty} P \\{ \\sup_{m\\geq n} |X_m - X| &gt; \\varepsilon \\} = 0\n\\] 이고, 그 역도 성립한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n확률변수 열이 거의 틀림없이 수렴하는지를 보이려면, \\(\\omega\\)의 분포와 \\(\\omega\\)와 확률변수 사이의 관계를 알든지, 아니면 수렴을 손쉽게 보일 수 있을 만큼 확률변수가 간단해야 함",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-mean",
    "href": "conv.html#convergence-in-mean",
    "title": "6  Convergence",
    "section": "6.3 Convergence in Mean",
    "text": "6.3 Convergence in Mean\nQ. 거의 틀림없는 수렴보다 조금 더 느슨한 수렴은 없을까?\n\nDefinition 6.3 (Converge in \\(r\\)-mean) 확률변수열 \\(X_n\\)가 \\[\nE|X_n - X|^r \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in \\(r-\\)mean to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\) 또는 \\(X_n \\stackrel{L^\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n특별히 \\(r=2\\)일 때를 제곱 평균 수렴이라 부르며, 해석이 쉽고 공학적인 응용에서도 많이 쓰임\n제곱 평균 수렴은 어떤 시점 \\(n\\)에서 \\(E\\{ (X_n-X)^2\\}\\)이 작다는 관점에서 대부분의 수열 \\(X_n\\)이 \\(X\\)에 가깝기만 바라는 것임\n이런 수렴은 시간에 중점을 두는 것인데, 거의 틀림없는 수렴과는 달리 수열 모두의 수렴을 생각하는 것이 아니고, 수렴하는지 아닌지 보이기도 더 쉬움\n\n\n\n\n코쉬 기준: 극한 확률변수 \\(X\\)를 모를 때에서 확률변수 열이 제곱 평균 수렴하는지 알아볼 수 있음\n\n\nTheorem 6.2 (Cauchy condition) 확률변수 열 \\(\\{X_n\\}\\)이 제곱 평균 수렴할 필요충분조건은 \\[\n\\lim_{n,m\\rightarrow\\infty} E \\{ (X_n - X_m)^2 \\} = 0\n\\] 이다.\n\n\nExample 6.3  \n\nExample 6.2 의 \\(B_n(\\omega) = (1-\\frac{1}{n})\\omega\\)는 Theorem 6.2 를 이용해보면 \\[\n\\begin{align*}\n\\lim_{n,m\\rightarrow\\infty}E\\{(B_n - B_m)^2 \\}&= \\lim_{n,m\\rightarrow\\infty}E\\{(\\frac{1}{n}-\\frac{1}{m} )^2 \\omega^2 \\}\\\\ &= E\\{\\omega^2\\}\\lim_{n,m\\rightarrow\\infty} (\\frac{1}{n}-\\frac{1}{m})^2 =0\n\\end{align*}\n\\] 이므로 코쉬 기준을 만족함을 알 수 있고, 따라서 제곱 평균 수렴할 것임을 알 수 있음\n또한 다음을 알고 있으므로 \\[\n\\begin{align*}\n\\lim_{n\\rightarrow\\infty} E[\\{ B_n(\\omega) - \\omega\\}^2] &= \\lim_{n\\rightarrow\\infty}E\\{ (\\frac{\\omega}{n})^2 \\} \\\\\n&= \\lim_{n\\rightarrow\\infty}\\frac{1}{3n^2}=0\n\\end{align*}\n\\] \\(B_n(\\omega)\\)는 \\(\\omega\\)에 제곱 평균 수렴\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n제곱 평균 수렴은 \\(n\\)이 커질 때 점점 더 많은 수열들이 \\(X\\)에 가까이 간다는 것을 의미하나, 거의 틀림없는 수렴과 달리 한 번 \\(X\\)에 가까이 간 수열이 그 뒤로도 늘 \\(X\\) 가까이에 머물러 있는 것은 아님\n\n\n\n\nExample 6.4  \n\nExample 6.2 의 \\(H_n(\\omega)=\\exp \\{-n (n\\omega - 1) \\}\\)은 거의 틀림없이 0으로 수렴하나 \\[\n\\begin{align*}\n\\lim_{n\\rightarrow\\infty}E[\\{ H_n (\\omega) - 0 \\}^2] &= \\lim_{n\\rightarrow\\infty} e^{2n} \\int_{0}^1 \\exp (-2n^2 \\omega) d\\omega\\\\ &= \\lim_{n\\rightarrow\\infty}\\frac{e^{2n}}{2n^2}\\{ 1-\\exp(-2n^2)\\}\\rightarrow\\infty\n\\end{align*}\n\\] 이므로 \\(\\{H_n(\\omega)\\}\\)은 0으로 제곱 평균 수렴하지는 않음",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-probability",
    "href": "conv.html#convergence-in-probability",
    "title": "6  Convergence",
    "section": "6.4 Convergence in Probability",
    "text": "6.4 Convergence in Probability\n\n\nDefinition 6.4 (Converge in Probability) 확률변수열 \\(X_n\\)이 임의의 \\(\\varepsilon&gt;0\\)에 대해 \\[\nP\\{ |X_n-X| &gt;\\varepsilon) \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in probability to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{p}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\nDefinition 6.4 에 적혀 있는 식은 어떤 순간에는 거의 모든 수열이 \\(2\\varepsilon\\)이라는 범위 안에 들어가 있지만 그 수열들이 그 안에 꼭 머물러 있는 것은 아니라는 것을 뜻함\n따라서 한 번 \\(2\\varepsilon\\)이라는 범위 안에 들어가면 그 안에 꼭 머문다는 것을 뜻하는 Theorem 6.1 의 식과 다름\n이 사실은 \\(\\{|X_n - X|&gt; \\varepsilon\\}\\)과 \\(\\{\\sup_{m\\geq n} |X_m-X|&gt;\\varepsilon \\}\\)의 뜻의 차이로부터 옴",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-distribution",
    "href": "conv.html#convergence-in-distribution",
    "title": "6  Convergence",
    "section": "6.5 Convergence in Distribution",
    "text": "6.5 Convergence in Distribution\n\n\nDefinition 6.5 (Converge in Distribution) \\(C(F_X)=\\{x : F_X(x) \\text{ is continuous at }x\\}=\\text{the continuity set of }F_X\\)라 하자. 확률변수열 \\(X_n\\)가 \\[\nF_{X_n}(x) \\rightarrow F_X(x) \\text{as} \\quad{} n\\rightarrow \\infty, \\quad{} \\forall x \\in C(F_X).\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{d}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n다음과 같이 정의할 수도 있다고 한다. 확률변수열 \\(X_n\\)가 모든 \\(h\\in C_{B}\\)에 대해 \\[\nE h(X_n) \\rightarrow E h(X) \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 한다.\n이 두개의 정의가 동치라는 증명이 Gut (2014) 의 Theorem 5.6.1에 있다.\n\n때때로 \\(X_n \\stackrel{\\text{d}}{\\rightarrow} \\mathcal{N}(0,1)\\)처럼 쓰기도 한다.\n\nExample 6.5  \n\n확률변수 \\(X_n\\)의 누적분포함수를 \\(F_n (x) = \\int_{-\\infty}^x \\frac{\\sqrt{n}}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{nt^2}{2\\sigma^2}}dt\\)처럼 두면 \\[\n\\lim_{n\\rightarrow\\infty} F_n (x)\n=\n\\begin{cases}\n0, & x&lt;0,\\\\\n\\frac{1}{2}, & x=0,\\\\\n1, & x &gt;0.\n\\end{cases}\n\\] 따라서, \\(\\{X_n\\}\\)은 누적분포함수가 \\[\nF(x) =\n\\begin{cases}\n0, & x&lt; 0,\\\\\n1, & x \\geq 0\n\\end{cases}\n\\] 인 확률변수 \\(X\\)로 분포에서 수렴한다.\n\\(\\lim_{n\\rightarrow\\infty}F_n (0) \\neq F(0)\\)이지만, 분포수렴은 누적분포함수의 불연속 점에서 수렴을 따지지 않기 때문에 \\(F(x)\\)의 불연속점인 \\(x=0\\)에서 \\(F_n(x)\\)가 수렴하는지 따지지 않아도 된다.\n\n\n\n6.5.1 Weak convergence\nDistributional convergence is often called weak convergence in these more general settings. (Gut 2014)\n\nDefinition 6.6 (Converge Weakly) 이는 Durrett (2019) 의 3.2에 나온다. A sequence of distribution functions is said to converge weakly to a limit \\(F\\) (written \\(F_n \\Rightarrow F\\)) if \\(F_n(y) \\rightarrow F(y)\\) for all \\(y\\) that are continuity points of \\(F\\). A sequence of random variables \\(X_n\\) is said to converge weakly or converge in distribution to a limit \\(X_{\\infty}\\) (written \\(X_n \\Rightarrow X_{\\infty})\\) if their distribution functions \\(F_n (x) = P(X_n \\leq x)\\) converges weakly.\n\n\n\n\n\n\n\nRemark\n\n\n\nPolansky (2011) 의 4장에서는 converges weakly를 converge in distribution을 정의할 때 쓴 random variable의 sequence를 생략한 채 \\(\\{F_n\\}_{n=1}^{\\infty}\\)와 \\(F\\)로만 정의한 것으로 보았다. 또한 converges weakly를 \\(F_n \\rightsquigarrow F\\)로 표기하기도 하였다.\n\n\n\n\n6.5.2 Vague convergence\n다음은 Gut (2014) 의 5.8.1에 나오는 vague convergence이다. Vague convergence의 limiting random variable이 proper하지 않아도 된다는 점이 distributional convergence와의 차이점이다.\n\nDefinition 6.7 (Converge Vaguely) A sequence of distribution functions \\(\\{F_n, n\\geq 1\\}\\) converges vaguely to the pseudo-distribution function \\(H\\) if, for every finite interval \\(I=(a,b] \\subset \\mathbb{R}\\), where \\(a,b\\in C(H)\\), \\[\nF_n(I) \\rightarrow H(I) \\quad{} \\text{as} \\quad{} n \\rightarrow \\infty.\n\\] Notation: \\(F_n \\stackrel{\\text{v}}{\\rightarrow}H\\) as \\(n\\rightarrow \\infty\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#relationship-among-convergences",
    "href": "conv.html#relationship-among-convergences",
    "title": "6  Convergence",
    "section": "6.6 Relationship Among Convergences",
    "text": "6.6 Relationship Among Convergences\n\nExample 6.6 (분포수렴하나 확률수렴하지 않는 확률변수열)  \n\n확률변수 \\(X\\)의 확률밀도함수가 대칭이라고 하고 \\(X_n = - X\\)라고 두자. 그러면 \\[\nX_n \\stackrel{d}{=}X\n\\] 이므로 \\(X_n \\stackrel{d}{\\rightarrow}X\\)이다.\n그러나 \\(n\\rightarrow\\infty\\)일 때 \\(P \\{ |X_n - X| &gt; \\varepsilon \\} = P \\{ |X| &gt; \\frac{\\varepsilon}{2} \\} \\not\\rightarrow 0\\)이므로 \\(X_n \\stackrel{p}{\\not\\rightarrow}X\\)이다.\n\n\n\nExample 6.7 (확률수렴하나 거의 틀림없이 수렴하지는 않는 확률변수열)  \n\n독립인 확률변수열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)에서 \\(P\\{X_n=1\\}=\\frac{1}{n}\\)이고 \\(P\\{X_n =0\\}=1-\\frac{1}{n}\\)이라고 두자. 그러면 \\(\\varepsilon \\in (0,1)\\)을 어떻게 고르더라도 \\(n\\rightarrow\\infty\\)일 떄 \\(P\\{ |X_n - 0| &gt; \\varepsilon\\}= P\\{X_n = 1\\} =\\frac{1}{n}\\rightarrow 0\\)이므로 \\(X_n \\stackrel{p}{\\rightarrow}0\\)이다.\n그러나 \\(A_n (\\varepsilon) = \\{|X_n - 0|&gt;\\varepsilon\\}\\)이라고 두고 \\(B_m (\\varepsilon) = \\cup_{n=m}^{\\infty}A_n (\\varepsilon)\\)이라고 두면 \\[\nP\\{B_m (\\varepsilon)\\} = 1- \\lim_{M\\rightarrow \\infty}P\\{ X_n =0, \\forall n \\text{ s.t. } m\\leq n \\leq M\\}\n\\] 이다. \\(X_n\\)이 독립이므로 자연수 \\(m\\)에 대해 \\(\\prod_{k=m}^{\\infty}(1-\\frac{1}{k})=0\\)이라는 것을 쓰면 \\[\n\\begin{align*}\nP\\{B_m (\\varepsilon)\\} &= 1- \\lim_{M\\rightarrow \\infty} \\Big(1-\\frac{1}{m} \\Big) \\Big(1-\\frac{1}{m+1} \\Big)\\cdots  \\Big(1-\\frac{1}{M} \\Big)\\\\\n&=1.\n\\end{align*}\n\\] 따라서 \\(\\lim_{m\\rightarrow\\infty} P\\{B_m (\\varepsilon) \\} \\neq 0\\)이고 Theorem 6.1 에서 \\(X_n \\stackrel{\\text{a.s.}}{\\not\\rightarrow}0\\)이다.\n\n\n\nExample 6.8 (확률수렴하나 평균수렴하지 않는 확률변수열)  \n\n확률변수열 \\(\\{X_n\\}_{n=1}^{\\infty}\\)에서 \\[\nP\\{ X_n = x\\} =\n\\begin{cases}\n\\frac{1}{n}, &  x= e^n\\\\\n1-\\frac{1}{n}, & x=0\n\\end{cases}\n\\] 이면 \\(\\varepsilon&gt;0\\)이고 \\(n\\rightarrow\\infty\\)일 때 \\(P\\{ |X_n| &lt; \\varepsilon\\}= P\\{X_n =0\\} = 1-\\frac{1}{n} \\rightarrow 1\\)이므로 \\(X_n \\stackrel{p}{\\rightarrow}0\\)이다.\n그러나 \\(E\\{X_n^r\\}=\\frac{e^{rn}}{n}\\rightarrow\\infty\\)이므로 \\(X_n \\stackrel{L^r}{\\not\\rightarrow} 0\\)이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#bounded-in-probability",
    "href": "conv.html#bounded-in-probability",
    "title": "6  Convergence",
    "section": "6.7 Bounded in Probability",
    "text": "6.7 Bounded in Probability\n(Polansky 2011) Convergence of distribution과 관련된 중요한 질문 중 하나는 limiting distribution이 valid distribution function이냐는 것이다. 이 말인 즉슨 sequence of distribution functions \\(\\{ F_n \\}_{n=1}^{\\infty}\\)가 \\[\n\\lim_{n\\rightarrow\\infty} F_n (x) = F(x), \\quad{} \\forall x \\in C(F) \\quad{} \\text{for some fct } F(x)\n\\] 일 때 \\(F(x)\\)가 distribution functions여야 할 필요가 있는가? 여기에서 \\(F(x) \\in [0,1]\\), \\(F(x)\\)가 non-decreasing, right continuity 등은 미적분학 등의 내용을 이용해 보일 수 있으므로 \\[\n\\lim_{x\\rightarrow \\infty} F(x) = 1, \\quad{} \\lim_{x\\rightarrow -\\infty} F(x) = 0\n\\] 을 만족하면 \\(F\\)가 valid distribution function이 될 것이다.\n\nDefinition 6.8 (Bounded in Probability (확률유계)) Let \\(\\{X_n\\}_{n=1}^{\\infty}\\) be a sequence of random variables. The sequence is bounded in probability if for every \\(\\varepsilon&gt;0\\), \\(\\exists x_{\\varepsilon} \\in \\mathbb{R}\\) and \\(n_{\\varepsilon} \\in \\mathbb{N}\\) such that \\(P(|X_n| \\leq x_{\\varepsilon})&gt;1-\\varepsilon\\) for all \\(n &gt; n_{\\varepsilon}\\).\n\n\nExample 6.9 (Bounded in Probability가 아닌 확률변수열) Consider the situation that \\(\\{X_n\\}_{n=1}^{\\infty}\\) is a sequence of random variables such that the distribution function of \\(X_n\\) is given by \\[\nF_n(x) =\n\\begin{cases}\n0, & x&lt;0\\\\\n1-p_n, & 0 \\leq x &lt; n\\\\\n1, & x\\geq n\n\\end{cases},\n\\] where \\(\\{p_n\\}_{n=1}^{\\infty}\\) is a sequence of real numbers such that \\[\n\\lim_{n\\rightarrow \\infty} p_n = p.\n\\]\n\n\\(p=0\\)이면 bounded in probability\n그러나 \\(p&gt;0\\)이면 we set a value of \\(\\varepsilon\\) such that \\(0&lt; \\varepsilon &lt; p\\). Let \\(x\\) be a positive real value. For any \\(n&gt;x\\) we have the property that \\(P(|X_m|\\leq x) = 1-p \\leq 1- \\varepsilon\\) for all \\(m&gt;n\\). Therefore, it is not possible to find the value of \\(x\\) required in the definition of bounded in probability.\n\n\n\nTheorem 6.3 (Bounded in Probability는 Limiting distribution이 valid인 것과 동치) Let \\(\\{X_n\\}_{n=1}^{\\infty}\\) be a sequence of random variables where \\(X_n\\) has distribution function \\(F_n\\) for all \\(n\\in \\mathbb{N}\\). Suppose that \\(F_n \\rightsquigarrow F\\) as \\(n\\rightarrow \\infty\\) where \\(F\\) may or may not be a vaild distribution function. Then, \\[\n\\lim_{x\\rightarrow \\infty} F(x) = 1, \\quad{} \\lim_{x\\rightarrow -\\infty} F(x) = 0\n\\] if and only if the sequence \\(\\{X_n \\}_{n=1}^{\\infty}\\) is bounded in probability.\n\n\n6.7.1 Bounded in probability와 converge in distribution\n\n\nTheorem 6.4 (분포수렴이면 확률유계) \\(\\{X_n\\}\\)이 확률변수 열이고 \\(X\\)가 확률변수라고 하자. \\(X_n \\rightarrow X\\)로 분포수렴하면 \\(\\{X_n\\}\\)은 확률유계이다.\n\n\nProof. \\(\\varepsilon&gt;0\\)일 때 \\(X\\)에 대해 \\(P(|X|\\leq x_{\\varepsilon})\\geq 1-\\varepsilon\\)이 성립하는 \\(x_{\\varepsilon}\\)을 선택하자. \\(x_{\\varepsilon}\\)와 \\(-x_{\\varepsilon}\\)가 \\(F\\)의 연속인 점이 되도록 항상 \\(x_{\\varepsilon}\\)를 선택할 수 있다. 그러면 다음을 얻는다.\n\\[\\begin{align*}\n\\lim_{n\\rightarrow \\infty}P(|X_n|&\\leq x_{\\varepsilon})\\geq \\lim_{n\\rightarrow\\infty}F_{X_n}(x_{\\varepsilon}) - \\lim_{n\\rightarrow\\infty}F_{X_n}(-x_{\\varepsilon}-0)\\\\\n&= F_{X}(x_{\\varepsilon})-F_X(-x_{\\varepsilon})\\geq 1-\\varepsilon.\n\\end{align*}\\]\n정확하게 하기 위해 \\(n\\geq N\\)에 대해 \\(P(|X_n| \\leq x_{\\varepsilon})\\geq 1-\\varepsilon\\)이 성립하도록 충분히 큰 \\(N\\)을 선택할 수 있다.\n\n그러나 앞선 정리의 역은 성립하지 않는다.\n\nExample 6.10 (확률유계이나 분포수렴하지 않는 예) \\(\\{X_n\\}\\)이 짝수 \\(n=2m\\)에 대해 \\(X_{2m}=2+ \\frac{1}{2m}\\)일 확률이 1이고, 홀수 \\(n=2m-1\\)에 대해 \\(X_{2m-1}=1+\\frac{1}{2m}\\)일 확률이 1인 퇴화확률변수열이라고 하자. 그러면 열 \\(\\{X_2,X_4,X_6,\\ldots\\}\\)은 퇴화확률변수 \\(Y=2\\)에 분포수렴하고, 열 \\(\\{X_1,X_3,X_5,\\ldots\\}\\)은 퇴화확률변수 \\(W=1\\)에 분포수렴한다. \\(Y\\)와 \\(W\\)의 분포가 동일하지 않으므로 열 \\(\\{X_n\\}\\)은 분포수렴하지 않는다. 그러나 열 \\(\\{X_n\\}\\)의 모든 값이 구간 \\([1,\\frac{5}{2}]\\)안에 있으므로 열 \\(\\{X_n\\}\\)은 확률유계이다.\n\n확률유계인 열(또는 확률변수로 분포수렴하는 것)을 생각하는 한 가지 방법은 \\(|X_n|\\)의 확률질량이 \\(\\infty\\)로 벗어나지 않는다는 것이다. 종종 분포수렴 대신 확률유계성을 이용할 수 있다.\n\nTheorem 6.5 (확률유계인 확률변수열과 확률수렴하는 확률변수열의 곱은 확률수렴) \\(\\{X_n\\}\\)이 확률유계인 확률변수 열이고 \\(\\{Y_n\\}\\)이 0으로 확률수렴하는 확률변수 열이라면 \\[\nX_n Y_n \\stackrel{P}{\\rightarrow}0.\n\\]\n\n\nProof. \\(\\varepsilon&gt;0\\)이라고 하자. 다음이 성립하도록 \\(B_{\\varepsilon}&gt;0\\)과 정수 \\(N_{\\varepsilon}\\)을 선택한다. \\[\nn \\geq N_{\\varepsilon} \\Longrightarrow P(|X_n|\\leq B_{\\varepsilon}) \\geq 1-\\varepsilon.\n\\] 그러면 다음과 같으며, 이것으로부터 원하는 결과가 도출된다.\n\\[\\begin{align*}\n\\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon) &\\leq \\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon, |X_n| \\leq B_\\varepsilon)\\\\\n&+ \\overline{\\lim}_{n\\rightarrow\\infty}P(|X_nY_n|\\geq \\varepsilon, |X_n| &gt; B_\\varepsilon)\\\\\n&\\leq \\overline{\\lim}_{n\\rightarrow\\infty} P(|Y_n|\\geq \\frac{\\varepsilon}{B_\\varepsilon}) + \\varepsilon = \\varepsilon.\n\\end{align*}\\]",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#uniform-integrability",
    "href": "conv.html#uniform-integrability",
    "title": "6  Convergence",
    "section": "6.8 Uniform Integrability",
    "text": "6.8 Uniform Integrability\nConverge in probability가 mean convergence를 imply하지 않는다는 사실로부터, 그러면 어떤 조건이 있을 때 converge in probability 하면 mean convergence를 보장하는지 궁금할 수 있다. Uniform integrability 조건이 추가되면 그러함이 알려져 있다. (Gut 2014)\n\nDefinition 6.9 (Uniform Integrability) A sequence \\(X_1, X_2, \\ldots\\) is called uniformly integrable iff \\[\nE|X_n|I\\{ |X_n| &gt; a\\} \\rightarrow 0 \\quad{} \\text{as} \\quad{} a \\rightarrow \\infty \\quad{} \\text{uniformly in } n.\n\\] 분포함수를 이용해 다른 방법으로 정의할 수도 있다. \\(X_1, X_2,\\ldots\\) is unifomly integrable iff \\[\n\\int_{|x|&gt;a} |x|dF_{X_n}(x)\\rightarrow 0 \\quad{} \\text{as} \\quad{} a \\rightarrow \\infty \\quad{} \\text{uniformly in } n.\n\\]\n\n\nRemark. \\(X_1, X_2 , \\ldots\\)이 유한한 평균을 갖고 있다는 뜻은 \\(E|X_n|I\\{|X_n|&gt;a\\}\\rightarrow 0\\) as \\(a \\rightarrow \\infty\\) for every \\(n\\)을 의미한다. 즉 convergent integrals의 tail이 0으로 수렴해야 하는 것이다. Uniformly integragle은 the contributions in the tails of the integrals tend to \\(0\\) uniformly for all members of the sequence임을 뜻한다. (Gut 2014)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-of-moments",
    "href": "conv.html#convergence-of-moments",
    "title": "6  Convergence",
    "section": "6.9 Convergence of Moments",
    "text": "6.9 Convergence of Moments\n위키의 설명에 따르면 \\(X_n \\stackrel{L^r}{\\rightarrow}X\\)이면 \\(\\lim_{n\\rightarrow \\infty}E[|X_n|^r] = E[|X|^r]\\)이 성립한다고 한다. 그러나 일반적인 moment의 convergence에 대해서는 잘 알지 못한다. 여기서는 uniformly integrablility를 추가해 기존 확률변수의 수렴과 moment convergence 사이의 관계에 대해 알아본다.\nWe are now in the position to show that uniform integrability is the correct concept, that is, that a sequence that converges almost surely, in probability, or in distribution, and is uniformly integrable, converges in the mean, that moments converge and that uniform integrability is the minimal additional assumption for this to happen. (Gut 2014)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#references",
    "href": "conv.html#references",
    "title": "6  Convergence",
    "section": "6.10 References",
    "text": "6.10 References\n\n확률변수론\n\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. 5th ed. Cambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.\n\n\nPolansky, Alan M. 2011. Introduction to Statistical Limit Theory. CRC Press.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "lln.html",
    "href": "lln.html",
    "title": "7  The Law of Large Numbers",
    "section": "",
    "text": "7.1 Preliminaries\n제일 많이 쓰이는 기술은 truncation이라고 하는 것으로, 이 방법의 특징은 원래 확률변수열과 asymptotically equivalent 하면서 좀 더 다루기 쉬운 수열을 생각하는 것이다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#moments-and-tails",
    "href": "lln.html#moments-and-tails",
    "title": "7  The Law of Large Numbers",
    "section": "7.2 Moments and Tails",
    "text": "7.2 Moments and Tails\n\nProposition 7.1 (Moments and Tails)  \n\nLet \\(r&gt;0\\). Suppose that \\(X\\) is a non-negative random variable. Then \\[\nEX^r &lt; \\infty \\quad{}\\Longrightarrow \\quad{} x^r P(X&gt;x) \\rightarrow 0 \\quad{} \\text{as }x \\rightarrow \\infty,\n\\] but not necessarily conversely.\nSuppose that \\(X, X_1, X_2, \\ldots\\) are i.i.d. random variables with mean \\(0\\). Then, for any \\(a &gt;0\\), \\[\nEXI\\{ |X| \\leq a\\}= - EXI\\{ |X|&gt;a\\},\n\\] and \\[\n\\Big| E \\sum_{k=1}^n X_k I\\{ |X_k| \\leq a\\} \\Big|\\leq n E|X| I\\{|X|&gt;a\\}.\n\\]\nLet \\(a &gt;0\\). If \\(X\\) is a random variable with mean \\(0\\), then \\(Y=XI\\{|X|\\leq a\\}\\) does not in general havemean \\(0\\). However, if \\(X\\) is symmetric, then \\(EY=0\\).",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#a-weak-law-for-partial-maxima",
    "href": "lln.html#a-weak-law-for-partial-maxima",
    "title": "7  The Law of Large Numbers",
    "section": "7.3 A Weak Law for Partial Maxima",
    "text": "7.3 A Weak Law for Partial Maxima",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#the-weak-law-of-large-numbers",
    "href": "lln.html#the-weak-law-of-large-numbers",
    "title": "7  The Law of Large Numbers",
    "section": "7.4 The Weak Law of Large Numbers",
    "text": "7.4 The Weak Law of Large Numbers\n\n\nTheorem 7.1 (WLLN)  \n\n\\(X,X_1,X_2,\\ldots\\)가 유한한 기댓값 \\(\\mu\\), 즉 \\(E(X)&lt;\\infty\\)를 갖는 i.i.d. 확률변수들이라고 하고 \\(S_n,n\\geq 1\\)을 그들의 partial sum이라고 하자. 그러면 \\[\n\\frac{S_n}{n}\\stackrel{p}{\\rightarrow}\\mu \\quad{} \\text{as } n\\rightarrow \\infty.\n\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\n\n\\(E|X|&lt; \\infty\\) 조건이 빠지게 되면 표본평균이 유한한 값에 확률수렴하지 않을 수 있음\n\n\n\n\n\nExample 7.1 (큰 수의 약법칙을 따르지 않는 확률변수열)  \n\n독립이고 한계분포가 모두 \\(\\text{Cauchy}(1,0)\\)인 확률벡터를 생각하면, \\(\\frac{S_n}{n}\\sim \\text{Cauchy}(1,0)\\)이라고 함\n즉 \\(\\frac{S_n}{n}\\)이 0에 확률수렴하지 않으므로 독립이고 분포가 같은 코시 확률변수열에서는 큰 수의 약한 법칙이 성립하지 않음\n\n\n\n\nTheorem 7.2 (Markov theorem) \\(\\{X_n, n\\geq 1\\}\\)을 다음의 조건 (Markov condition) \\[\n\\frac{1}{n^2} \\text{Var}(X_1 + \\cdots + X_n) \\rightarrow 0 \\quad{} \\text{as }n \\rightarrow \\infty\n\\] 을 만족하는 확률변수열이라 하자. 그러면 \\(\\{X_n\\}\\)은 WLLN을 만족한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n마르코프 조건은 WLLN에 대한 충분조건이나 필요조건은 아님",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#the-strong-law-of-large-numbers",
    "href": "lln.html#the-strong-law-of-large-numbers",
    "title": "7  The Law of Large Numbers",
    "section": "7.5 The Strong Law of Large Numbers",
    "text": "7.5 The Strong Law of Large Numbers\n\nTheorem 7.3 (큰 수의 센 법칙을 따르는 충분조건) 확률변수열 \\(\\{x_i\\}_{i=1}^n\\)의 평균이 \\(\\mu_i\\), 분산이 \\(\\sigma_i^2\\)일 때 \\[\n\\sum_{i=1}^{\\infty} \\sigma_i^2 &lt; \\infty\n\\] 이면 \\(\\sum_{i=1}^{\\infty}(X_i - \\mu_i)\\)는 거의 틀림없이 0으로 수렴한다.\n\n\n\n\n\n\n\nRemark\n\n\n\n\n큰 수의 센 법칙을 따르는 확률변수열 은 (당연히) 큰 수의 약한 법칙도 성립함\n\n\n\n\n\nTheorem 7.4 (The Kolmogorov strong law)  \n\n만약 \\(E|X|&lt;\\infty\\)이고 \\(E(X)=\\mu\\)라면 \\[\n\\frac{S_n}{n}\\stackrel{\\text{a.s.}}{\\rightarrow}\\mu \\quad{} \\text{as } n \\rightarrow \\infty.\n\\]\n만약 어떤 상수 \\(c\\)에 대해 \\(\\frac{S_n}{n}\\stackrel{\\text{a.s.}}{\\rightarrow} c\\) as \\(n\\rightarrow \\infty\\)라고 한다면 \\[\nE(X) &lt;\\infty \\quad{} \\text{and} \\quad{} c= E(X).\n\\]\n만약 \\(E|X| = \\infty\\)라 한다면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{n} = + \\infty.\n\\]\n\n\n\nExample 7.2 (WLLN은 성립하니 SLLN은 만족하지 않는 예) 확률질량함수 \\(p_{X_n}(x) = P\\{ X_n = x\\}\\)가 \\[\np_{X_n}(x) =\n\\begin{cases}\n1- \\frac{1}{n\\log n}, & x=0,\\\\\n\\frac{1}{2n\\log n}, & x = \\pm n\n\\end{cases}\n\\] 인 독립 확률변수열 \\(\\{X_n\\}_{n=2}^{\\infty}\\)를 생각하자.\n\n\\(n \\geq 2\\)일 때 \\(A_n = \\{|X_n| \\geq n\\}\\)이라고 두면 \\(P\\{A_n\\} = \\frac{1}{n\\log n}\\)이므로 \\(\\sum_{n=2}^{\\infty} P\\{A_n\\} \\rightarrow \\infty\\)이다. 바꾸어 말하면, \\(\\sum_{n=2}^{\\infty}P\\{A_n\\}\\)이 발산하고 \\(X_n\\)이 서로 독립이므로, 보렐-칸텔리 정리에서 \\(P\\{A_n \\text{ i.o.}\\}=1\\)이다. 이는 \\[\nP\\{|X_n|\\geq n \\text{ i.o.}\\} = P \\{ \\Big\\vert\\frac{X_n}{n}\\Big\\vert \\geq \\text{ i.o.} \\} = P\\{\\lim_{n\\rightarrow\\infty}\\frac{S_n}{n} \\neq 0 \\} =1\n\\] 이다. 그러므로 \\(\\{X_n\\}_{n=2}^{\\infty}\\)는 큰 수의 강법칙을 만족하지 않는다.\n\\(\\text{Var}\\{X_ k\\} = \\frac{k}{\\log k}\\)이므로 \\[\n\\begin{align*}\n\\frac{1}{n^2}\\sum_{k=2}^n \\text{Var}\\{X_k\\} &\\leq \\frac{1}{n^2} \\Big( \\frac{2}{\\log 2} + \\int_3^{n+1}\\frac{x}{\\log x} dx \\Big)\\\\\n&\\leq \\frac{2}{n^2 \\log 2} + \\frac{(n-2)(n+1)}{n^2 \\log n}\\\\\n&\\rightarrow 0\n\\end{align*}\n\\] 이고 마르코프 조건 Theorem 7.2 을 생각해 보면 \\(\\{X_n \\}_{n=2}^{\\infty}\\)는 큰 수의 약법칙을 만족한다.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lil.html",
    "href": "lil.html",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "",
    "text": "9.1 The Law of the iterated logarithm (LIL)",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "lil.html#the-law-of-the-iterated-logarithm-lil",
    "href": "lil.html#the-law-of-the-iterated-logarithm-lil",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "",
    "text": "Definition 9.1 (Hartman and Wintner LIL)  \n\n\n\\(X, X_1, X_2, \\ldots\\)가 mean 0, variance \\(\\sigma^2 &lt;0\\)을 갖는 i.i.d. 확률변수들이라고 하고 \\(S_n = \\sum_{k=1}^n X_k, n\\geq 1\\)이라고 하면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} (\\lim\\inf_{n\\rightarrow\\infty}) \\frac{S_n}{\\sqrt{2\\sigma^2 n \\log \\log n}} = +1 (-1) \\quad{} \\text{a.s.}\n\\tag{9.1}\\]\n이를 간단히 쓰면 \\[\n\\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{\\sqrt{2\\sigma^2 n \\log \\log n}} = 1 \\quad{} \\text{a.s.}\n\\]\n역으로 만약 \\[\nP\\Big( \\lim\\sup_{n\\rightarrow\\infty} \\frac{|S_n|}{\\sqrt{n \\log \\log n}} &lt; \\infty \\Big) &gt;0\n\\] 이면 \\(E(X^2)&lt;\\infty\\), \\(E(X)=0\\), (Equation 9.1) 이 성립",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "lil.html#r-코드",
    "href": "lil.html#r-코드",
    "title": "9  The Law of the Iterated Logarithm",
    "section": "9.2 R 코드",
    "text": "9.2 R 코드\nHaigh (2013) 의 Example 6.21\nQ. Long-run behaviour of sums\nQ. \\(n\\)이 증가함에 따라 \\(S_n /\\sqrt{n}\\)의 fluctuations의 size는?\n\n9.2.1 Simulation setting\n\n\\(Y_n \\stackrel{\\text{indep}}{\\sim} U(0,1)\\)\n\\(X_n = Y_n \\sqrt{12} - \\sqrt{3}\\), so that \\(X_n \\stackrel{\\text{i.i.d.}}{\\sim} U(-\\sqrt{3}, \\sqrt{3})\\): 이렇게 하면 \\(E(X_n)=0, \\text{Var}(X_n)=1\\)이 됨\n\\(S_n = X_1 + \\cdots X_n\\)\n\n\n\n\n\n\n\nFigure: (a) Random sums. (b) CLT. (c) LIL. (d) LLN.\n\n\n\n\n\n\n9.2.2 Results\n\n그림에 대한 추가 설명(참고로 모든 그림의 x축은 log-스케일이다):\n\n\n\\(n\\)이 커짐에 따라 random sums \\(S_n\\)이 어떻게 되는지 보여줌, 점선은 \\(\\pm \\sqrt{2 n \\log \\log n}\\)\n\n\n(CLT) \\(n\\)이 커짐에 따라 \\(S_n/\\sqrt{n}\\)은 standard Gaussian으로 분포수렴, 점선은 \\(\\pm \\mathcal{N}^{-1}(0.01)\\) (분위수)\n\n\n(LIL) \\(n\\)이 커짐에 따라 \\(S_n/\\sqrt{n\\log \\log n}\\)은 \\([-\\sqrt{2}, \\sqrt{2}]\\) 사이에 존재, 점선은 \\(\\pm \\sqrt{2}\\)\n\n\n(SLLN) \\(n\\)이 커짐에 따라 \\(S_n/n \\rightarrow 0\\), 점선은 \\(\\pm \\sqrt{ \\frac{2 \\log \\log n}{n}}\\)\n\n\nSLLN: \\(S_n / n \\stackrel{n\\rightarrow \\infty}{\\rightarrow} 0\\) 임을 말하는데, 이는 어떤 \\(\\varepsilon&gt;0\\)이 주어졌을 때, \\(\\forall n \\geq N\\)에 대해 \\(S_n/n\\)이 구간 \\((-\\varepsilon, \\varepsilon)\\) 안에 있도록 하는 \\(N\\)이 존재\nCLT: \\(S_n /\\sqrt{n} \\stackrel{d}{\\rightarrow} \\mathcal{N}(0,1)\\) 임을 말하는데, 이는 \\(n\\)이 클때 \\(P(-1&lt; S_n /\\sqrt{n} &lt; 1) \\approx 0.68\\), \\(P(|S_n /\\sqrt{n}|&gt;2)\\approx 0.05\\)임 등을 추론할 수 있음을 의미함\n\n그러나 CLT가 boundedness를 말하는 것은 아니기 때문에 \\(n\\)이 매울 클 때에도 매우 크거나 작은 \\(S_n/\\sqrt{n}\\)이 나올 수 있음\n\nLIL: \\(U_n = S_n / \\sqrt{n \\log (\\log (n))}\\)에 대해 말하는데, \\(\\sqrt{\\log (\\log (n))}\\)은 unbounded지만 매우 천천히 증가하는 함수임, \\(n=10^6\\)일 때 비로소 \\(\\sqrt{\\log (\\log (n))}\\approx 1.62\\)가 됨\n\n\\(S_n\\) 또한 \\(n\\)이 커질수록 천천히 변하기 때문에 \\(U_n\\)은 매우 천천히 변할 것이라 생각할 수 있음\n그러나, \\(\\sqrt{\\log (\\log (n))}\\)은 \\(\\mathcal{N}(0,1)\\)의 변화를 잡아줄 수 있을 정도로 큰 값이기는 함\n\n정리해보자면, LIL은 언젠가는 \\(U_n\\)이 \\((-\\sqrt{2},\\sqrt{2})\\)에 있을 것임을 의미함\n\n\n\n\n\nHaigh, John. 2013. Probability Models. 2nd ed. 2013. SpringerLink. Dordrecht: Springer.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>The Law of the Iterated Logarithm</span>"
    ]
  },
  {
    "objectID": "limext.html",
    "href": "limext.html",
    "title": "10  Limit Theorems: Extensions and Generalizations",
    "section": "",
    "text": "10.1 Stable distributions",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Limit Theorems: Extensions and Generalizations</span>"
    ]
  },
  {
    "objectID": "limext.html#stable-distributions",
    "href": "limext.html#stable-distributions",
    "title": "10  Limit Theorems: Extensions and Generalizations",
    "section": "",
    "text": "Stable distribution의 정의에는 몇 가지가 있는 듯 (Nolan 2020)\n\n\nDefinition 10.1 (Stable distributions)  \n\n\n\\(X_1, X_2, \\ldots\\)가 확률변수 \\(X\\)의 i.i.d. copy라 하고 \\(S_n, n\\geq 1\\)을 partial sum이라 하자. 만약 어떤 상수 \\(c_n &gt; 0, d_n \\in \\mathbb{R}, n\\geq 1\\)이 존재해 \\[\nS_n \\stackrel{d}{=}c_n X + d_n, \\quad{} \\forall n\n\\] 이라 하면 확률변수 \\(X\\)의 분포를 stable in the broad sense라고 함\n만약 \\(\\forall n\\)에 대해 \\(d_n = 0\\)이라고 하면 분포를 strictly stable이라고 함\n\n\n\n\n\n\n\n\nRemark\n\n\n\n(Nolan (2020) 의 내용)\n\nStable distribution은 skeness, heavy-tail 등을 다룰 수 있는 probability distn의 큰 클래스이며 좋은 수학적 성질도 가지고 있다고 함\n문제점: Gaussian, Cauchy, Levy 등을 제외하면 density와 distn에 대한 closed formula가 부족하다는 단점 존재\n그러나 컴퓨터 프로그램의 도움을 받아 stable distn의 density나 distn 등을 계산할 수 있음\n\n\n\n\n\n\n\nNolan, John P. 2020. Univariate Stable Distributions: Models for Heavy Tailed Data. Springer Series in Operations Research and Financial Engineering. Cham, Switzerland: Springer.",
    "crumbs": [
      "Probability",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Limit Theorems: Extensions and Generalizations</span>"
    ]
  },
  {
    "objectID": "mev.html",
    "href": "mev.html",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "",
    "text": "12.1 Pseudo-Polar Transforms\nKiriliouk et al. (2016) describe a pseudo-polar representation of bivariate data as a means to explore right-tail extremal dependency between the variables.\nLet \\((X_i, Y_i)\\) (real values) or \\((U_i, V_i)\\) (as probabilities) for \\(i=1,\\ldots, n\\) be a bivariate sample of size \\(n\\). When such data are transformed into a unit-Pareto scale by \\[\n\\hat{X}_i^{*} = \\frac{n}{n+1-R_{X,i}}, \\quad{} \\hat{Y}_i^{*} = \\frac{n}{n+1-R_{Y,i}},\n\\] where \\(R\\) is rank(), then letting each component sum or pseudo-polar radius be defined as \\[\n\\hat{S}_i = \\hat{X}_i^{*} + \\hat{Y}_i^{*},\n\\] and each respective pseudo-polar angle be defined as \\[\n\\hat{W}_i = \\frac{\\hat{X}_i^{*}}{\\hat{X}_i^{*} + \\hat{Y}_i^{*}} = \\frac{\\hat{X}_i^{*}}{\\hat{S}_i}\n\\] a pseudo-polar representation is available for study.\nA scatter plot of \\(\\hat{W}_i\\) (horizontal) versus \\(\\hat{S}_i\\) (vertical) will depict a pseudo-polar plot of the data.\nA density plot of the \\(\\hat{W}_i\\) is a representation of extremal dependence.\nFigure: Extremal dependence.",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#clustering-methods-in-extremes",
    "href": "mev.html#clustering-methods-in-extremes",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.2 Clustering Methods in Extremes",
    "text": "12.2 Clustering Methods in Extremes\n\n\nHandbook on Statistics of Extremes 책 발간 예정\nVector quantization\n\n\n12.2.1 K-means clustering\n\nGiven obs \\(\\pmb{x}_1, \\ldots, \\pmb{x}_n\\), find \\(K\\) cluster centroids \\(\\pmb{c}_1, \\ldots, \\pmb{c}_K\\) s.t. the avg data-point-to-centroid dist is minimized: \\[\n(\\pmb{c}_1, \\ldots, \\pmb{c}_K) := \\arg\\min_{\\pmb{c}_1, \\ldots, \\pmb{c}_K} \\sum_{k=1}^K\n\\]\nEstimate the centroids \\(\\pmb{c}_k\\) and the cluster membership of each \\(\\pmb{x}_i\\) in turns.\n\nGiven \\(\\hat{\\pmb{c}}_1, \\ldots, \\hat{\\pmb{c}}_K\\), assign \\(\\pmb{x}_i\\) to the cluster \\(k\\) with the closest centroid \\(\\hat{\\pmb{c}}_k\\). \\[\ni \\in C_k \\Longleftrightarrow d(\\pmb{x}_i, c_k) = \\min_{k'}d(\\pmb{x}_i, \\pmb{c}_{k'})\n\\]\nGiven all \\(\\pmb{x}_i\\)’s in cluster \\(k\\), update each \\(\\hat{\\pmb{c}}_k\\)\n\n\nQ. Choice of \\(d(\\cdot, \\cdot)\\): + Euclidean \\(d(\\pmb{x}, \\pmb{y}) = (\\pmb{x}- \\pmb{y})^T(\\pmb{x}- \\pmb{y})\\) + Then the centroids can be calculated as \\[\n  \\hat{\\pmb{c}}_k = \\arg\\min_{\\pmb{c}} \\sum_{i\\in C_k}(\\pmb{x}_i - \\pmb{c})^T(\\pmb{x}_i - \\pmb{c}) = \\frac{1}{|C_k|} \\sum_{i\\in C_k}\n  \\]\nQ. Choice of \\(K\\): + Prespecified + Use a scree plot where the obj fct \\[\n  \\min_{\\pmb{c}_1, \\ldots, \\pmb{c}_K} \\sum_{k=1}^K \\sum_{i \\in C_k} d(\\pmb{x}_i , \\pmb{c}_k)\n  \\]\n이러한 \\(K\\)-mean 같이 Euclidean dist를 쓰는 방법은 extreme value에서 통하기 어려움",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#spectral-clustering",
    "href": "mev.html#spectral-clustering",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.3 Spectral Clustering",
    "text": "12.3 Spectral Clustering\n\nCan detect nonlinear cluster patterns\nCan identify noise clusters",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#clustering-the-angluar-components",
    "href": "mev.html#clustering-the-angluar-components",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.4 Clustering the Angluar Components",
    "text": "12.4 Clustering the Angluar Components\n\n\\(\\pmb{Y}\\) be multivariate regularly varying with standardized margin (Frechet 등이 해당) Then \\[\n\\frac{\\pmb{Y}}{\\|\\pmb{Y}\\|}_{\\| \\pmb{Y}\\|&gt;t}\\stackrel{d}{\\rightarrow} \\Theta, \\quad{} t \\rightarrow \\infty.\n\\]\nClustering for extremes:\n\nObtain angular compts \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\) from \\(\\pmb{Y}_1, \\ldots , \\pmb{Y}_n\\)\nCluster \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\) instead.\n\n\n여기서 \\(\\Theta\\)는 unit sphere \\(\\{ \\pmb{x} \\| \\pmb{x} \\| = 1\\}\\)이라는 매우 좋은 space에 놓여 있다. (이때 \\(\\| \\cdot \\|\\)은 any norm이나 되지만 \\(L2\\) norm을 쓰기로 한다)",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "mev.html#max-linear-models",
    "href": "mev.html#max-linear-models",
    "title": "12  Multivariate Extreme Value Theory",
    "section": "12.5 Max-Linear Models",
    "text": "12.5 Max-Linear Models\n\nMax-linear random vector: \\[\n\\pmb{X} = (X_1, \\ldots, X_d) = \\vee_{i=1, \\ldots, K}\\pmb{b}_i Z_i\n\\]\nFactors \\(\\pmb{b}_1, \\ldots, \\pmb{b}_{K} \\in [ 0, \\infty )^{d}\\)\n\\(Z_1, \\ldots, Z_k\\): i.i.d. Frechet\n\nThen the angular measure \\(\\Theta\\) consists of point masses at \\[\n\\frac{\\pmb{b}_1}{\\|\\pmb{b}_1\\|}, \\ldots\n\\]\n\n12.5.1 Spherical \\(K\\)-means\n\nApply to \\(\\Theta_1, \\ldots, \\Theta_{k_n}\\): \\(K\\)-means clustering with choice of distance \\[\nd(\\pmb{x}, \\pmb{y}) = 1- \\cos (\\pmb{x}, \\pmb{y})\n\\]\n\nOn the unit sphere \\(\\mathbb{S}_{+}^{d-1}\\),\n\n\\(d(\\pmb{x}, \\pmb{y})= 1-\\pmb{x}^T\\pmb{y}\\)\n\\(d\\) is equiv to the Euclidean dist\n\n\n\n12.5.2 Spherical \\(K\\)-PCs clustering for extremes\n\n앞선 방법과 달리 \\(d(\\pmb{x}, \\pmb{y}) = 1-(\\pmb{x}^T\\pmb{y})^2\\)을 쓰는 것이 차이점(제곱이 들어감)\nhttps://academic.oup.com/biomet/article-abstract/110/1/135/6551983?redirectedFrom=PDF\n\\(\\arg\\max_{\\|\\pmb{c}\\|_2=1} \\pmb{c}^T\\Sigma_k \\pmb{c}\\) 형태가 나옴\nFor any spectral measure that can be decomposed into two sub-faces \\(l_1\\) and \\(l_2\\), we would like the optimal centroids to satisfy \\[\n\\pmb{c}_1 \\in \\mathbb{F}_{l_1}, \\quad{} \\pmb{c}_2 \\in \\mathbb{F}_{l_2}\n\\]\nThis holds for spheical \\(K\\)-means iff \\[\n\\|l_1 | - | l_2 \\| \\leq 1\n\\]\nThis holds for spherical \\(K\\)-PCs always.\nIf angular components \\(\\pmb{x}\\) and \\(\\pmb{y}\\) belongs to different sub-faces, then \\(\\pmb{x}^T\\pmb{y}\\) close to \\(0\\).\n\n\n\n12.5.3 Spectral clustering for extremes\n\nLinear factor model with noise: \\[\n\\pmb{X} = (X_1, \\ldots, X_d) = \\sum_{i=1}^K\n\\]",
    "crumbs": [
      "Extremes",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multivariate Extreme Value Theory</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "13  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Intro",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Durrett, Rick. 2019. Probability: Theory and Examples. 5th ed.\nCambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed.\nSpringer New York.\n\n\nHaigh, John. 2013. Probability Models. 2nd ed. 2013.\nSpringerLink. Dordrecht: Springer.\n\n\nNolan, John P. 2020. Univariate Stable Distributions: Models for\nHeavy Tailed Data. Springer Series in Operations Research and\nFinancial Engineering. Cham, Switzerland: Springer.\n\n\nPolansky, Alan M. 2011. Introduction to Statistical Limit\nTheory. CRC Press.\n\n\nProschan, Michael A. 2016. Essentials of Probability Theory for\nStatisticians. CRC Press.",
    "crumbs": [
      "Intro",
      "References"
    ]
  }
]