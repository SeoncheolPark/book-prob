[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Biggner’s Guide to Probability Theory",
    "section": "",
    "text": "Preface\n확률론은 통계학을 공부하는 데 있어 굉장히 중요한 과목\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "2  The Elements of Proability Theory",
    "section": "",
    "text": "3 Data and models",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "prob.html#probability",
    "href": "prob.html#probability",
    "title": "2  The Elements of Proability Theory",
    "section": "5.1 Probability",
    "text": "5.1 Probability\n\nLet \\(\\Omega\\) be any set and \\(\\mathcal{A}\\) be a field of its subsets. We say that \\(P\\) is a probability on the measurable space \\((\\Omega, \\mathcal{A})\\) if \\(P\\) is defined for all events \\(A\\in\\mathcal{A}\\) and satisfies the following axioms.\n\n\n\\(P(A)\\geq 0\\) for each \\(A\\in \\mathcal{A}\\); \\(P(\\Omega)=1\\)\n\\(P\\) is finitely additive. That is, for any finite number of pairwise disjoint events \\(A_1, \\ldots, A_n \\in \\mathcal{A}\\) we have \\[\nP\\Big( \\cup_{i=1}^n A_i \\Big) = \\sum_{i=1}^n P(A_i).\n\\]\n\\(P\\) is continuous at \\(\\emptyset\\). That is, for any events \\(A_1, A_2, \\ldots, \\mathcal{A}\\) such that \\(A_{n+1} \\subset A_n\\) and \\(\\cap_{n=1}^{\\infty}A_n = \\emptyset\\), it is true that \\[\n\\lim_{n\\rightarrow \\infty}P(A_n) = 0.\n\\]\n\nNote that conditions 2 and 3 are equivalent to the next one 4.\n\n\\(P\\) is \\(\\sigma\\)-additive (countably additive), that is \\[\nP\\Big( \\cup_{n=1}^{\\infty} A_n\\Big) = \\sum_{n=1}^{\\infty}P(A_n)\n\\] for any events \\(A_1, A_2, \\ldots \\in \\mathcal{A}\\) which are pairwise disjoint.\n\n\nExample 5.1 (A probability measure which is additive but not \\(\\sigma\\)-additive) Let \\(\\Omega\\) be the set of all rational numbers \\(r\\) of the unit interval \\([0,1]\\) and \\(\\mathcal{F}_1\\) the class of the subsets of \\(\\Omega\\) of the form \\([a,b]\\), \\((a,b]\\), \\((a,b)\\) or \\([a,b)\\) where \\(a\\) and \\(b\\) are rational numbers. Denote by \\(\\mathcal{F}_2\\) the class of all finite sums of disjoint sets of \\(\\mathcal{F}_1\\). Then \\(\\mathcal{F}_2\\) is a field. Let us define the probability measure \\(P\\) as follows: \\[\\begin{align*}\nP(A) &= b-a, \\quad{} \\text{if } A \\in \\mathcal{F}_1,\\\\\nP(B) &= \\sum_{i=1}^n P(A_i), \\quad{} \\text{if } B\\in \\mathcal{F}_2, \\text{ that is, } B=\\sum_{i=1}^n A_i, A_i \\in \\mathcal{F}_1.\n\\end{align*}\\]\nConsider two disjoint sets of \\(\\mathcal{F}_2\\) say \\[\nB=\\sum_{i=1}^n A_i \\quad{} \\text{ and } B' = \\sum_{j=1}^m A_j',\n\\] where \\(A_i, A_j' \\in \\mathcal{F}_1\\) and all \\(A_i, A_j'\\) are disjoint. Then \\(B+B' = \\sum_{k=1}^{m+n}C_k\\) where either \\(C_k = A_i\\) for some \\(i=1, \\ldots, n\\), or \\(C_k = A_j'\\) for some \\(j=1, \\ldots, m\\). Moreover, \\[\\begin{align*}\nP(B+B')&= P\\Big( \\sum_k C_k \\Big) = \\sum_k P(C_k) = \\sum_{i,j}(P(A_i) + P(A_j'))\\\\\n&= P(A_i) + \\sum_{j} P(A_j') = P(B) + P(B').\n\\end{align*}\\]\nand hence \\(P\\) is an additive measure.\nObviously every one-point set \\(\\{r\\}\\in\\mathcal{F}_2\\) and \\(P(\\{r\\}) = 0\\). Since \\(\\Omega\\) is a countable set and \\(\\Omega = \\sum_{i=1}^{\\infty}\\{r_i\\}\\), we get \\[\nP(\\Omega) = 1\\neq 0 = \\sum_{i=1}^{\\infty} P(\\{r_i\\}).\n\\] This contradiction shows that \\(P\\) is not \\(\\sigma\\)-additive.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Elements of Proability Theory</span>"
    ]
  },
  {
    "objectID": "rvs.html",
    "href": "rvs.html",
    "title": "3  Random Variables",
    "section": "",
    "text": "3.1 Radon-nikodym derivative\nChange of measures.\n확률측도는 volume element의 일반화라고 볼 수 있다.\nThe reference measure \\(\\lambda (x)\\) is essentially just a meter-stick that allows us to express the probability measure as a simple function \\(f(x)\\). That is, we represent the probability measure \\(\\mu(x)\\) as \\(f(x)\\) by comparing the probability measure to some specified reference measure \\(\\lambda (x)\\). This is essentially the intuition that is given by the Radon-Nikodym derivative \\[\nf(x) = \\frac{d\\mu (x)}{d\\lambda (x)}\n\\] or equivalently \\[\n\\text{height = area / width.}\n\\] Note that we can also represent the same idea by \\[\n\\mu (A) = \\int_{A\\in X} f(x) d\\lambda (x),\n\\] where \\(\\mu(A)\\) is the sum of the probability of events in the set \\(A\\) which is itself a subset of the entire sample space \\(X\\). Note that when \\(A=X\\) then the integral must equal \\(1\\) by definition of probability.\n라돈-니코딤 정리는 조건부 확률에 응용된다고 함.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#radon-nikodym-derivative",
    "href": "rvs.html#radon-nikodym-derivative",
    "title": "3  Random Variables",
    "section": "",
    "text": "\\(\\mu(x)\\): probability measure, interval이나 set of points들을 인풋으로 받고 area/volume에 해당하는 확률(양수)을 아웃풋으로 주는 함수다.\n\\(\\lambda (x)\\): reference measure. We often take \\(\\lambda (x)\\) as the Lebesgue measure which is essentially just a uniform function over the sample space.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#integration",
    "href": "rvs.html#integration",
    "title": "3  Random Variables",
    "section": "3.2 Integration",
    "text": "3.2 Integration",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#리만-스틸체스-적분",
    "href": "rvs.html#리만-스틸체스-적분",
    "title": "3  Random Variables",
    "section": "3.3 리만-스틸체스 적분",
    "text": "3.3 리만-스틸체스 적분\n종종 헷갈리는 표현이 기댓값을 다음과 같이 분포함수를 이용해 표현하는 경우가 있다.\n\\[\nE(X) = \\int x dF(x).\n\\]\n우리가 알고 있는 정적분은 \\(x\\)축을 따라가며 함수값 f(x)가 만드는 면적을 계산한다.\n\\[\n\\int_a^b f(x) dx.\n\\]\n위 식을 더 확장하면 \\(x\\) 대신 임의의 곡선 \\(g(x)\\)를 적분 변수로 두고 \\(f(x)\\) 를 단순하게 정적분 할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x).\n\\]\n여기서 \\(dg(x)\\)는 \\(g(x)\\)의 미분소(differential)로, \\(g(x)\\)의 움직임을 결정하는 \\(x\\)는 단조 증가하거나 감소한다. 위와 같이 리만 적분을 일반화한 정적분을 리만-스틸체스 적분(Riemann-Stieltjes Integral)이라 한다. 리만 적분의 정의를 이용해 리만-스틸체스의 적분을 표현할 수도 있다.\n\\[\n\\int_{x=a}^b f(x) dg(x) = \\lim_{N\\rightarrow \\infty} \\sum_{n=0}^{N-1} f(t_n) [g(x_{n+1}) - g(x_n)].\n\\]\n여기서 \\(x_n\\)은 정적분을 위해 구간 \\([a,b]\\)를 나눈 점, \\(t_n\\)은 닫힌 세부공간 \\([x_n, x_{n+1} ]\\)사이에 있는 임의점이다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs.html#리만-적분과-르베그-적분",
    "href": "rvs.html#리만-적분과-르베그-적분",
    "title": "3  Random Variables",
    "section": "3.4 리만 적분과 르베그 적분",
    "text": "3.4 리만 적분과 르베그 적분\n여기는 Confused when changing from Lebesgue Integral to Riemann Integral 에 올라왔던 내용을 살펴보기로 한다. 여기서 질문자는 리만 적분을 어떻게 르베그 적분으로 바꾸는지에 대해 관심이 있다.\n다음과 같이 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)에서 정의된 음이 아닌 확률변수 \\(X\\)가 지수분포를 따른다고 하자. \\[\nP(X&lt;x) = 1-e^{-\\lambda x}.\n\\] 한편, 르베그 적분으로 \\(X\\)의 기댓값을 쓰면 다음과 같다. \\[\nE[X] = \\int_{\\{\\omega | X(\\omega) \\geq 0 \\}} X(\\omega) dP(\\omega).\n\\] 여기서 질문자는 이것을 리만 적분으로 어떻게 바꾸냐 \\[\nE[X] = \\int_0^\\infty x \\lambda e^{-\\lambda x}dx\n\\] 를 물어보고 있다.\n답변은 이것이 적분의 문제가 아닌 변수변환의 문제라고 한다.\nBy definition, given \\(X: \\Omega \\rightarrow \\mathbb{R}\\) a random variable, \\(E[X] = \\int_{\\Omega} X\\). \\(X\\) defines a measure \\(\\tilde{m}\\) in \\(\\mathbb{R}\\), called the push-forward, by \\(\\tilde{m}(A) = P(X^{-1}(A))\\). By definition, this measure is invariant under \\(X\\), and hence \\[\n\\int_{\\mathbb{R}} f d\\tilde{m} = \\int_{\\Omega} f \\circ X dP.\n\\] The equality follows from the usual arguments (prove for characteristics, simple functions, then use convergence. Recall that \\(1_A \\circ X = 1_{X^{-1}(A)}\\)).\nLet \\(h\\) be the density of \\(X\\). We then have, by definition of density, that \\(\\tilde{m}(A) = P(X^{-1}(A)) = \\int_A h dm\\) for any \\(A \\in \\mathcal{B}(\\mathbb{R})\\), where \\(m\\) is the Lebesgue measure. By change of variables, we have \\[\n\\int_{\\mathbb{R}}f d\\tilde{m} = \\int_{\\mathbb{R}} f\\cdot h dm.\n\\] Combining these equations, \\[\n\\int_{\\mathbb{R}} f \\cdot h dm =\\int_{\\Omega} f \\circ X dP.\n\\] Taking \\(f=\\text{Id}\\) yields \\[\n\\int_{\\mathbb{R}}xh(x)dx = \\int_{\\Omega} X dP = E[X].\n\\] Taking \\(f = \\text{Id} \\cdot \\mathbf{1}_{I}\\), where \\(I\\) is some interval (for example, \\((0, +\\infty)\\) as in your case), we have \\[\n\\int_{I}xh(x)dx = \\int_{X^{-1}}XdP,\n\\] recalling again that \\(\\mathbf{1}_A \\circ X = \\mathbf{1}_{X^{-1}(A)}\\). Since \\(P(X&lt;0)\\) in your case is \\(0\\), this last integral is actually equal to the integral over the whole space, and hence to \\(E[X]\\), which gives your equality.\n\nDefinition 3.1 (Integrable Random Variable) Gut (2014) 의 53쪽에 따르면, \\(E|X|&lt;\\infty\\)인 경우 random varible \\(X\\)가 integrable 하다고 부른다.\n\n\nDefinition 3.2 (\\(\\mathcal{L}^p\\)) 다음과 같은 확률공간 \\((\\Omega, \\mathcal{F}, P)\\)를 생각하자. \\(p&gt;1\\)에 대해, 확률변수 \\(X\\)가 \\(E|X|^p &lt; \\infty\\)이면 \\(X\\in \\mathcal{L}^p\\)라고 하며 다음과 같은 놈 \\(\\|X_p\\| = (E|X|^p)^{\\frac{1}{p}}\\)를 정의할 수 있다.\n\n\n\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "conv.html",
    "href": "conv.html",
    "title": "4  Convergence",
    "section": "",
    "text": "4.1 Definitions\n다음의 정의들은 확률론에서 많이 등장하는 정의들이다. \\(X_1,X_2,\\ldots\\)를 확률변수열이라 하자.\n때때로 \\(X_n \\stackrel{\\text{d}}{\\rightarrow} \\mathcal{N}(0,1)\\)처럼 쓰기도 한다.\nDistributional convergence is often called weak convergence in these more general settings. (Gut 2014)\n다음은 Gut (2014) 의 5.8.1에 나오는 vague convergence이다. Vague convergence의 limiting random variable이 proper하지 않아도 된다는 점이 distributional convergence와의 차이점이다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#definitions",
    "href": "conv.html#definitions",
    "title": "4  Convergence",
    "section": "",
    "text": "Definition 4.1 (Almost sure convergence) 확률변수열 \\(X_n\\)은 \\[\nP\\{ \\omega: X_n (\\omega)\\rightarrow X(\\omega) \\text{ as } n\\rightarrow \\infty\\})=1\n\\] 을 만족하면 \\(X_n\\) converges almost surely (a.s.) to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{a.s.}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.2 (Converge in Probability) 확률변수열 \\(X_n\\)이 임의의 \\(\\varepsilon&gt;0\\)에 대해 \\[\nP\\{ |X_n-X| &gt;\\varepsilon) \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in probability to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{p}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.3 (Converge in \\(r\\)-mean) 확률변수열 \\(X_n\\)가 \\[\nE|X_n - X|^r \\rightarrow 0 \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in \\(r-\\)mean to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{r}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n\n\nDefinition 4.4 (Converge in Distribution) \\(C(F_X)=\\{x : F_X(x) \\text{ is continuous at }x\\}=\\text{the continuity set of }F_X\\)라 하자. 확률변수열 \\(X_n\\)가 \\[\nF_{X_n}(x) \\rightarrow F_X(x) \\text{as} \\quad{} n\\rightarrow \\infty, \\quad{} \\forall x \\in C(F_X).\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 하고, \\(X_n \\stackrel{\\text{d}}{\\rightarrow}X\\) as \\(n\\rightarrow \\infty\\)라 쓴다.\n다음과 같이 정의할 수도 있다고 한다. 확률변수열 \\(X_n\\)가 모든 \\(h\\in C_{B}\\)에 대해 \\[\nE h(X_n) \\rightarrow E h(X) \\quad{} \\text{as} \\quad{} n\\rightarrow \\infty.\n\\] 을 만족하면 \\(X_n\\) converges in distribution to the random variable \\(X\\) as \\(n\\rightarrow \\infty\\)라 한다.\n이 두개의 정의가 동치라는 증명이 Gut (2014) 의 Theorem 5.6.1에 있다.\n\n\n\n\nDefinition 4.5 (Converge Weakly) 이는 (Durrett 2019) 의 3.2에 나온다. A sequence of distribution functions is said to converge weakly to a limit \\(F\\) (written \\(F_n \\Rightarrow F\\)) if \\(F_n(y) \\rightarrow F(y)\\) for all \\(y\\) that are continuity points of \\(F\\). A sequence of random variables \\(X_n\\) is said to converge weakly or converge in distribution to a limit \\(X_{\\infty}\\) (written \\(X_n \\Rightarrow X_{\\infty})\\) if their distribution functions \\(F_n (x) = P(X_n \\leq x)\\) converges weakly.\n\n\n\nDefinition 4.6 (Converge Vaguely) A sequence of distribution functions \\(\\{F_n, n\\geq 1\\}\\) converges vaguely to the pseudo-distribution function \\(H\\) if, for every finite interval \\(I=(a,b] \\subset \\mathbb{R}\\), where \\(a,b\\in C(H)\\), \\[\nF_n(I) \\rightarrow H(I) \\quad{} \\text{as} \\quad{} n \\rightarrow \\infty.\n\\] Notation: \\(F_n \\stackrel{\\text{v}}{\\rightarrow}H\\) as \\(n\\rightarrow \\infty\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#almost-sure-convergence-1",
    "href": "conv.html#almost-sure-convergence-1",
    "title": "4  Convergence",
    "section": "6.1 Almost Sure Convergence",
    "text": "6.1 Almost Sure Convergence",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-probability",
    "href": "conv.html#convergence-in-probability",
    "title": "4  Convergence",
    "section": "6.2 Convergence in Probability",
    "text": "6.2 Convergence in Probability\n\nSNU, 2020 Winter, Problem 1Solution\n\n\nLet \\(0 &lt; r &lt; \\infty\\), \\(X_n \\in \\mathcal{L}^r\\), and \\(X_n \\rightarrow X\\) in probability. Then, show the following three propositions are equivalent.\n\n\\(\\{|X_n|^r\\}\\) is uniformly integrable.\n\\(X_n \\rightarrow X\\) in \\(\\mathcal{L}^r\\).\n\\(E(|X_n|^r) \\rightarrow E(|X|^r) &lt; \\infty\\).\n\n\n\nGut (2014) 책에는 almost sure convergence에만 초점을 맞추어 서술하였다. (Theorem 5.5.2) 실제 converge in probability에서도 성립함이 알려져 있다. (Theorem 5.5.4) 이 증명을 하기 위해서는 Fatou’s lemma가 필요하다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "conv.html#convergence-in-distribution",
    "href": "conv.html#convergence-in-distribution",
    "title": "4  Convergence",
    "section": "6.3 Convergence in Distribution",
    "text": "6.3 Convergence in Distribution\n\nSNU, 2019 Summer, Problem 3Solution\n\n\nShow that, if \\(X_n\\) converges weakly to \\(X\\) and \\(\\{X_n, n\\geq 1\\}\\) is uniformly integrable, then \\(X\\) is integrable and \\(EX_n \\rightarrow EX\\) as \\(n\\rightarrow \\infty\\).\n\n\n일단 integrable random variable에 대해 모르면 Definition 3.1 를 참고하자.\nGut (2014) 책의 Theorem 5.5.9 참고\n\n\n\n\n\n\n\nDurrett, Rick. 2019. Probability: Theory and Examples. 5th ed. Cambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed. Springer New York.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Convergence</span>"
    ]
  },
  {
    "objectID": "lln.html",
    "href": "lln.html",
    "title": "5  The Law of Large Numbers",
    "section": "",
    "text": "6 Preliminaries\n제일 많이 쓰이는 기술은 truncation이라고 하는 것으로, 이 방법의 특징은 원래 확률변수열과 asymptotically equivalent 하면서 좀 더 다루기 쉬운 수열을 생각하는 것이다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "lln.html#moments-and-tails",
    "href": "lln.html#moments-and-tails",
    "title": "5  The Law of Large Numbers",
    "section": "6.1 Moments and Tails",
    "text": "6.1 Moments and Tails\n\nProposition 6.1 (Moments and Tails)  \n\nLet \\(r&gt;0\\). Suppose that \\(X\\) is a non-negative random variable. Then \\[\nEX^r &lt; \\infty \\quad{}\\Longrightarrow \\quad{} x^r P(X&gt;x) \\rightarrow 0 \\quad{} \\text{as }x \\rightarrow \\infty,\n\\] but not necessarily conversely.\nSuppose that \\(X, X_1, X_2, \\ldots\\) are i.i.d. random variables with mean \\(0\\). Then, for any \\(a &gt;0\\), \\[\nEXI\\{ |X| \\leq a\\}= - EXI\\{ |X|&gt;a\\},\n\\] and \\[\n\\Big| E \\sum_{k=1}^n X_k I\\{ |X_k| \\leq a\\} \\Big|\\leq n E|X| I\\{|X|&gt;a\\}.\n\\]\nLet \\(a &gt;0\\). If \\(X\\) is a random variable with mean \\(0\\), then \\(Y=XI\\{|X|\\leq a\\}\\) does not in general havemean \\(0\\). However, if \\(X\\) is symmetric, then \\(EY=0\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Law of Large Numbers</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Durrett, Rick. 2019. Probability: Theory and Examples. 5th ed.\nCambridge University Press. https://www.ebook.de/de/product/34699864/rick_duke_university_north_carolina_durrett_probability.html.\n\n\nGut, Allan. 2014. Probability: A Graduate Course. 2nd ed.\nSpringer New York.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]